{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declarations and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import gensim\n",
    "import math\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from keras import preprocessing\n",
    "from keras.preprocessing import sequence\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "from keras.models import load_model\n",
    "import statistics\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "homePath = str(Path.home()) + \"/MLClassificationData\"\n",
    "#homePath = \"c:/BERT/rtanews/docs/\"\n",
    "LabeledSentence = gensim.models.doc2vec.TaggedDocument\n",
    "# Count of categories (labels).\n",
    "n_cats = 0\n",
    "# This id is included into the names of models, created by this notebook.\n",
    "modelId = 5\n",
    "# Path to original corpus for training\n",
    "trainRoot = homePath + '/train/rtanews/source'\n",
    "# Path to original corpus for testing\n",
    "testRoot = homePath + '/test/rtanews/source'\n",
    "# Input for BERT\n",
    "bertDataPath = homePath + \"/PytorchBERT/textdir/\"\n",
    "# Output of BERT\n",
    "outDataPath = homePath + \"/PytorchBERT/outdir/\"\n",
    "# Path to model info\n",
    "modelInfoPath = homePath + '/models/rtanews/modelinfo/'\n",
    "max_bert_seq_length = 512\n",
    "numpy.random.seed(1)\n",
    "cnt = 0\n",
    "nCats = 0\n",
    "categories = dict()\n",
    "\n",
    "LabeledDocument = namedtuple('LabeledDocument', 'line words labels qLabs name')\n",
    "\n",
    "def getCategories(path):\n",
    "    cats = dict()\n",
    "    nCats = 0\n",
    "    os.chdir(path)\n",
    "    for f in glob.glob(\"*\"):\n",
    "        if os.path.isdir(f):\n",
    "            cats[f] = nCats\n",
    "            nCats += 1\n",
    "    return cats\n",
    "\n",
    "def prepareDocsData(path, cats):\n",
    "    files = dict()\n",
    "    fInCats = [0] * len(cats)\n",
    "    nFiles = 0\n",
    "    actFiles = 0\n",
    "    curCategory = 0\n",
    "    docs = []\n",
    "    os.chdir(path)\n",
    "    rootDir = os.getcwd()\n",
    "    for f in glob.glob(\"*\"):\n",
    "        curCategory = cats[f]\n",
    "        catPath = path + \"/\" + f\n",
    "        os.chdir(catPath)\n",
    "        for fc in glob.glob(\"*\"):\n",
    "            actFiles += 1\n",
    "            if fc not in files:\n",
    "                nFiles += 1\n",
    "                fPath = catPath + \"/\" + fc\n",
    "                docCont = ''\n",
    "                with open(fc, 'r', encoding='UTF-8') as tc:\n",
    "                    for line in tc:\n",
    "                        docCont += line.strip() + \" \"\n",
    "                tc.close()\n",
    "                line = docCont.strip() + \"\\n\"\n",
    "                words = docCont.strip().split()\n",
    "                labels = [0] * len(cats)\n",
    "                labels[curCategory] = 1\n",
    "                files[fc] = LabeledDocument(line, words, labels, [1], fc)\n",
    "            else:\n",
    "                files[fc].labels[curCategory] = 1\n",
    "                files[fc].qLabs[0] += 1\n",
    "            fInCats[curCategory] += 1\n",
    "    for k, val in files.items():\n",
    "        docs.append(val)\n",
    "    return docs, fInCats\n",
    "\n",
    "def getLabelSets(docs):\n",
    "    labels = [x[2] for x in docs]\n",
    "    results = [labels[0]]\n",
    "    qLabs = 0\n",
    "    for i in range(len(labels)):        \n",
    "        if i%1000 == 0:\n",
    "            print (str(i), end='\\r')\n",
    "        qLabs += sum(labels[i])\n",
    "        count = 0\n",
    "        for j in range(len(results)):\n",
    "            for k in range(len(categories)):\n",
    "                if labels[i][k] != results[j][k]:\n",
    "                    count += 1\n",
    "                    break\n",
    "        if count == len(results):\n",
    "            results.append(labels[i])\n",
    "    return len(results), qLabs\n",
    "    \n",
    "def showTime(ds,de):\n",
    "    result = ''\n",
    "    seconds = (de-ds).total_seconds()\n",
    "    if seconds < 1:\n",
    "        return \"less than 1 sec\"\n",
    "    hh = int(seconds/(60*60));\n",
    "    if hh > 0:\n",
    "        result = \"%d h:\"%(hh);\n",
    "    seconds -= hh*60*60\n",
    "    mm = int(seconds/60);\n",
    "    if mm > 0:\n",
    "        result += \"%d min:\"%(mm)\n",
    "    ss = seconds - mm*60;\n",
    "    result += \"%d sec\"%(ss)\n",
    "    return result\n",
    "\n",
    "def showDocsByLength(plt):\n",
    "    fig, (plot1, plot2) = plt.subplots(1, 2, figsize=(10,6))    \n",
    "    dictLens = dict()\n",
    "    dictLens1 = dict()\n",
    "    for i in range(len(trainDocs)):\n",
    "        lend = \"%5d\"%(len(trainDocs[i].words))\n",
    "        if not lend in dictLens:\n",
    "            dictLens[lend] = 1\n",
    "        else:\n",
    "            dictLens[lend] += 1\n",
    "    lens = sorted(list(dictLens.items()))\n",
    "    lvars = [int(x[0]) for x in lens]\n",
    "    locc = [x[1] for x in lens]\n",
    "    plot1.set_title (\"Documents by length in training set\")\n",
    "    plot1.set_ylabel(\"Documents\")\n",
    "    plot1.set_xlabel(\"Length\")\n",
    "    plot1.plot(lvars, locc, \"b.-\") \n",
    "    for i in range(len(testDocs)):\n",
    "        lend = \"%5d\"%(len(testDocs[i].words))\n",
    "        if not lend in dictLens1:\n",
    "            dictLens1[lend] = 1\n",
    "        else:\n",
    "            dictLens1[lend] += 1\n",
    "    lens1 = sorted(list(dictLens1.items()))\n",
    "    lvars1 = [int(x[0]) for x in lens1]\n",
    "    locc1 = [x[1] for x in lens1]\n",
    "    plot2.set_title (\"Documents by length in testing set\")\n",
    "    plot2.set_xlabel(\"Length\")\n",
    "    plot2.yaxis.tick_right()\n",
    "    plot2.plot(lvars1, locc1, \"b.-\") \n",
    "    plt.show()\n",
    "    \n",
    "def showDocsByLabs(plt):\n",
    "    fig, (plot1, plot2) = plt.subplots(1, 2, figsize=(10,6))\n",
    "    dictLabs = dict()\n",
    "    dictLabs1 = dict()\n",
    "    for i in range(len(trainDocs)):\n",
    "        lab = \"%5d\"%(trainDocs[i].qLabs[0])\n",
    "        if not lab in dictLabs:\n",
    "            dictLabs[lab] = 1\n",
    "        else:\n",
    "            dictLabs[lab] += 1\n",
    "    labs = sorted(list(dictLabs.items()))\n",
    "    lvars1 = [int(x[0]) for x in labs]\n",
    "    locc1 = [x[1] for x in labs]\n",
    "    plot1.set_title (\"Documents by labels in training set\")\n",
    "    plot1.set_ylabel(\"Documents\")\n",
    "    plot1.set_xlabel(\"Labels\")\n",
    "    plot1.set_xticks(numpy.arange(0, len(categories), step=1))\n",
    "    plot1.plot(lvars1, locc1, \"bo-\")\n",
    "    for i in range(len(testDocs)):\n",
    "        lab = \"%5d\"%(testDocs[i].qLabs[0])\n",
    "        if not lab in dictLabs1:\n",
    "            dictLabs1[lab] = 1\n",
    "        else:\n",
    "            dictLabs1[lab] += 1\n",
    "    labs1 = sorted(list(dictLabs1.items()))\n",
    "    lvars2 = [int(x[0]) for x in labs1]\n",
    "    locc2 = [x[1] for x in labs1]\n",
    "    plot2.set_title (\"Documents by labels in testing set\")\n",
    "    #plot2.set_ylabel(\"Documents\")\n",
    "    plot2.set_xlabel(\"Labels\")\n",
    "    plot2.set_xticks(numpy.arange(0, len(categories), step=1))\n",
    "    plot2.yaxis.tick_right()\n",
    "    plot2.plot(lvars2, locc2, \"bo-\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load input data in 3 sec\n"
     ]
    }
   ],
   "source": [
    "ds = datetime.datetime.now()\n",
    "categories = getCategories(trainRoot)\n",
    "#print (categories)\n",
    "trainAllDocs, fInCats1 = prepareDocsData(trainRoot, categories)\n",
    "trainAllDocs = random.sample(trainAllDocs, len(trainAllDocs))\n",
    "#trainDocs = trainAllDocs[:int(len(trainAllDocs) * (1 - valPart))]\n",
    "#valDocs = trainAllDocs[int(len(trainAllDocs) * (1 - valPart)):]\n",
    "trainDocs = trainAllDocs\n",
    "testDocs, fInCats2 = prepareDocsData(testRoot, categories)\n",
    "#testDocs = random.sample(testDocs, len(testDocs))\n",
    "de = datetime.datetime.now()\n",
    "\n",
    "print (\"Load input data in %s\"%(showTime(ds, de))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset properties:\n",
      "Loaded 23837 documents: 15001 for training, 8836 for test\n",
      "Length of documents: maximum: 1502, minimum: 47, average: 188, median: 174\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of 90.0% documents from training set is less then 300. Longer documents will be truncated.\n",
      "\n",
      "Categories (labels): 40\n",
      "Documents for training in category : maximum: 2800, minimum: 93, avegare: 415\n",
      "Documents for testing  in category : maximum: 1501, minimum: 65, avegare: 276\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Label Set: 290\n",
      "Proportion of Distinct Label Set: 0.0193\n",
      "Label Cardinality: 1.1073\n",
      "Label Density: 0.0277\n"
     ]
    }
   ],
   "source": [
    "print (\"Dataset properties:\")\n",
    "maxDocLen = max(len(x.words) for x in trainAllDocs)\n",
    "minDocLen = min(len(x.words) for x in trainAllDocs)\n",
    "avrgDocLen = round(statistics.mean(len(x.words) for x in trainAllDocs), 2)\n",
    "medianDocLen = round(statistics.median(len(x.words) for x in trainAllDocs), 2)\n",
    "dls, qLabs = getLabelSets(trainAllDocs)\n",
    "\n",
    "print ('Loaded %d documents: %d for training, %d for test' % (len(trainAllDocs) + len(testDocs), len(trainDocs), len(testDocs)))\n",
    "print (\"Length of documents: maximum: %d, minimum: %d, average: %d, median: %d\"%(maxDocLen, minDocLen, avrgDocLen, medianDocLen))\n",
    "showDocsByLength(plt);\n",
    "\n",
    "top_bound=0.9\n",
    "maxLen = math.ceil(maxDocLen/100)*100 + 100\n",
    "input_length_list=[]\n",
    "for i in range(100, maxLen, 100):\n",
    "    input_length_list.append(i)\n",
    "input_length_dict={x:0 for x in input_length_list }\n",
    "for i in range(len(trainAllDocs)):\n",
    "    curLen = len(trainAllDocs[i].words)\n",
    "    dictLen = maxLen\n",
    "    for ln in input_length_dict:\n",
    "        if curLen < ln:\n",
    "            dicLen = ln\n",
    "            break\n",
    "    input_length_dict[dicLen] = input_length_dict[dicLen] + 1\n",
    "input_length_dict_percentage={}\n",
    "for k,v in input_length_dict.items():\n",
    "    v=v/len(trainAllDocs)\n",
    "    input_length_dict_percentage[k]=v\n",
    "maxSeqLength=0\n",
    "accumulate_percentage=0\n",
    "for length,percentage in input_length_dict_percentage.items():\n",
    "    accumulate_percentage+=percentage\n",
    "    if accumulate_percentage>0.9:\n",
    "        maxSeqLength=length\n",
    "        break\n",
    "print (\"Length of %.1f%% documents from training set is less then %d. Longer documents will be truncated.\"%(top_bound*100, maxSeqLength))        \n",
    "\n",
    "print ()\n",
    "print (\"Categories (labels): %d\"%(len(categories)))\n",
    "print (\"Documents for training in category : maximum: %d, minimum: %d, avegare: %d\"%(max(fInCats1), min(fInCats1), round(statistics.mean(fInCats1), 2)))\n",
    "print (\"Documents for testing  in category : maximum: %d, minimum: %d, avegare: %d\"%(max(fInCats2), min(fInCats2), round(statistics.mean(fInCats2), 2)))\n",
    "showDocsByLabs(plt)\n",
    "print (\"Distinct Label Set: %d\"%(dls))\n",
    "print (\"Proportion of Distinct Label Set: %.4f\"%(dls/len(trainAllDocs)))\n",
    "print (\"Label Cardinality: %.4f\"%(qLabs/len(trainAllDocs)))\n",
    "print (\"Label Density: %.4f\"%(qLabs/len(trainAllDocs)/len(categories)))\n",
    "\n",
    "#del trainAllDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare input for training and testing BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved\n",
      "Test data saved\n"
     ]
    }
   ],
   "source": [
    "cNames = [''] * len(categories)\n",
    "for k,v in categories.items():\n",
    "    cNames[v] = k\n",
    "    \n",
    "def saveData(type):\n",
    "    global bertDataPath\n",
    "    if type == \"train\":\n",
    "        bertPath = bertDataPath + \"train.tsv\"\n",
    "        data = trainDocs        \n",
    "    else:\n",
    "        bertPath = bertDataPath + \"dev.tsv\"\n",
    "        data = testDocs        \n",
    "    target = open(bertPath, \"w\", encoding=\"utf-8\")\n",
    "    for i in range(len(data)):\n",
    "        conts = data[i].line.replace('\\r','').replace('\\n','.')\n",
    "        labs = []\n",
    "        for j in range(len(data[i].labels)):\n",
    "            if data[i].labels[j] == 1:\n",
    "                #labs.append(cNames[j].replace(\".\",\"\"))\n",
    "                labs.append(cNames[j])\n",
    "        nl = '\\n'\n",
    "        if i == 0:\n",
    "            nl = ''\n",
    "        string = nl + \",\".join(labs) + \"\\t\" + conts\n",
    "        target.write(string)\n",
    "    target.close()    \n",
    "    \n",
    "saveData(\"train\")\n",
    "print (\"Train data saved\")\n",
    "saveData(\"test\")\n",
    "print (\"Test data saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert.modeling import BertModel\n",
    "from pytorch_pretrained_bert.modeling import PreTrainedBertModel\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "class BertForMultiLabelSequenceClassification(PreTrainedBertModel):\n",
    "    \"\"\"BERT model for classification.\n",
    "    This module is composed of the BERT model with a linear layer on top of\n",
    "    the pooled output.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, num_labels=2):\n",
    "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits\n",
    "        \n",
    "    def freeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create, train, save and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2019 01:16:31 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/user/.pytorch_pretrained_bert/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "02/13/2019 01:16:31 - INFO - __main__ -   LOOKING AT /home/user/MLClassificationData/PytorchBERT/textdir/train.tsv\n",
      "02/13/2019 01:16:32 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz from cache at /home/user/.pytorch_pretrained_bert/distributed_-1/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9\n",
      "02/13/2019 01:16:32 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/user/.pytorch_pretrained_bert/distributed_-1/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9 to temp dir /tmp/tmpsrryzfts\n",
      "02/13/2019 01:16:41 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "02/13/2019 01:17:21 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "02/13/2019 01:17:21 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "02/13/2019 01:18:51 - INFO - __main__ -   ***** Running training *****\n",
      "02/13/2019 01:18:51 - INFO - __main__ -     Num examples = 15001\n",
      "02/13/2019 01:18:51 - INFO - __main__ -     Batch size = 32\n",
      "02/13/2019 01:18:51 - INFO - __main__ -     Num steps = 1404\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/469 [00:38<4:56:25, 38.00s/it]\u001b[A\n",
      "Iteration:   0%|          | 2/469 [01:12<4:47:15, 36.91s/it]\u001b[A\n",
      "Iteration:   1%|          | 3/469 [01:47<4:41:33, 36.25s/it]\u001b[A\n",
      "Iteration:   1%|          | 4/469 [02:19<4:31:58, 35.09s/it]\u001b[A\n",
      "Iteration:   1%|          | 5/469 [02:51<4:25:13, 34.30s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 6/469 [03:24<4:21:25, 33.88s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 7/469 [03:57<4:18:01, 33.51s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 8/469 [04:29<4:13:17, 32.97s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 9/469 [05:00<4:09:56, 32.60s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 10/469 [05:33<4:08:43, 32.51s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 11/469 [06:06<4:09:18, 32.66s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 12/469 [06:38<4:07:00, 32.43s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 13/469 [07:10<4:06:05, 32.38s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 14/469 [07:41<4:03:39, 32.13s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 15/469 [08:14<4:03:54, 32.23s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 16/469 [08:45<4:00:23, 31.84s/it]\u001b[A\n",
      "Iteration:   4%|▎         | 17/469 [09:17<4:00:31, 31.93s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 18/469 [09:48<3:57:38, 31.62s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 19/469 [10:20<3:58:39, 31.82s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 20/469 [10:51<3:56:11, 31.56s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 21/469 [11:24<3:58:22, 31.92s/it]\u001b[A\n",
      "Iteration:   5%|▍         | 22/469 [11:58<4:03:39, 32.71s/it]\u001b[A\n",
      "Iteration:   5%|▍         | 23/469 [12:39<4:20:21, 35.03s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 24/469 [13:15<4:23:01, 35.47s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 25/469 [13:52<4:26:08, 35.97s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 26/469 [14:30<4:28:32, 36.37s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 27/469 [15:07<4:29:46, 36.62s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 28/469 [15:39<4:20:04, 35.38s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 29/469 [16:11<4:10:52, 34.21s/it]\u001b[A\n",
      "Iteration:   6%|▋         | 30/469 [16:43<4:04:50, 33.46s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 31/469 [17:15<4:00:42, 32.97s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 32/469 [17:45<3:55:40, 32.36s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 33/469 [18:18<3:55:15, 32.37s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 34/469 [18:49<3:52:48, 32.11s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 35/469 [19:21<3:50:43, 31.90s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 36/469 [19:52<3:48:22, 31.64s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 37/469 [20:25<3:50:31, 32.02s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 38/469 [20:56<3:48:37, 31.83s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 39/469 [21:27<3:46:58, 31.67s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 40/469 [22:00<3:49:21, 32.08s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 41/469 [22:32<3:48:14, 32.00s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 42/469 [23:03<3:44:54, 31.60s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 43/469 [23:34<3:44:11, 31.58s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 44/469 [24:06<3:44:17, 31.67s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 45/469 [24:39<3:45:10, 31.87s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 46/469 [25:10<3:44:36, 31.86s/it]\u001b[A\n",
      "Iteration:  10%|█         | 47/469 [25:41<3:41:37, 31.51s/it]\u001b[A\n",
      "Iteration:  10%|█         | 48/469 [26:11<3:38:33, 31.15s/it]\u001b[A\n",
      "Iteration:  10%|█         | 49/469 [26:43<3:39:36, 31.37s/it]\u001b[A\n",
      "Iteration:  11%|█         | 50/469 [27:15<3:39:54, 31.49s/it]\u001b[A\n",
      "Iteration:  11%|█         | 51/469 [27:46<3:37:39, 31.24s/it]\u001b[A\n",
      "Iteration:  11%|█         | 52/469 [28:19<3:40:49, 31.77s/it]\u001b[A\n",
      "Iteration:  11%|█▏        | 53/469 [28:51<3:40:27, 31.80s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 54/469 [29:22<3:38:51, 31.64s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 55/469 [29:53<3:36:25, 31.37s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 56/469 [30:24<3:35:39, 31.33s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 57/469 [30:55<3:34:29, 31.24s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 58/469 [31:27<3:35:45, 31.50s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 59/469 [31:58<3:33:42, 31.27s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 60/469 [32:30<3:34:18, 31.44s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 61/469 [33:01<3:33:32, 31.40s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 62/469 [33:32<3:33:16, 31.44s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 63/469 [34:04<3:32:20, 31.38s/it]\u001b[A\n",
      "Iteration:  14%|█▎        | 64/469 [34:36<3:34:43, 31.81s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 65/469 [35:08<3:33:38, 31.73s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 66/469 [35:39<3:31:36, 31.51s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 67/469 [36:10<3:29:50, 31.32s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 68/469 [36:43<3:32:17, 31.77s/it]\u001b[A\n",
      "Iteration:  15%|█▍        | 69/469 [37:14<3:31:31, 31.73s/it]\u001b[A\n",
      "Iteration:  15%|█▍        | 70/469 [37:45<3:28:42, 31.39s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 71/469 [38:16<3:27:29, 31.28s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 72/469 [38:48<3:28:14, 31.47s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 73/469 [39:20<3:29:50, 31.80s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 74/469 [39:52<3:28:14, 31.63s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 75/469 [40:24<3:28:49, 31.80s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 76/469 [40:56<3:28:10, 31.78s/it]\u001b[A\n",
      "Iteration:  16%|█▋        | 77/469 [41:27<3:26:49, 31.66s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 78/469 [41:58<3:24:35, 31.40s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 79/469 [42:29<3:24:23, 31.44s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 80/469 [43:01<3:23:50, 31.44s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 81/469 [43:33<3:24:18, 31.59s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 82/469 [44:04<3:22:45, 31.43s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 83/469 [44:35<3:21:44, 31.36s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 84/469 [45:10<3:28:35, 32.51s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  18%|█▊        | 85/469 [45:44<3:31:20, 33.02s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 86/469 [46:19<3:33:49, 33.50s/it]\u001b[A\n",
      "Iteration:  19%|█▊        | 87/469 [46:55<3:38:57, 34.39s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 88/469 [47:30<3:39:12, 34.52s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 89/469 [48:05<3:38:38, 34.52s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 90/469 [48:40<3:38:54, 34.66s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 91/469 [49:17<3:43:26, 35.47s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 92/469 [49:52<3:42:22, 35.39s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 93/469 [50:28<3:42:50, 35.56s/it]\u001b[A\n",
      "Iteration:  20%|██        | 94/469 [51:03<3:40:33, 35.29s/it]\u001b[A\n",
      "Iteration:  20%|██        | 95/469 [51:39<3:41:07, 35.47s/it]\u001b[A\n",
      "Iteration:  20%|██        | 96/469 [52:14<3:39:48, 35.36s/it]\u001b[A\n",
      "Iteration:  21%|██        | 97/469 [52:49<3:37:59, 35.16s/it]\u001b[A\n",
      "Iteration:  21%|██        | 98/469 [53:25<3:38:49, 35.39s/it]\u001b[A\n",
      "Iteration:  21%|██        | 99/469 [54:00<3:37:31, 35.27s/it]\u001b[A\n",
      "Iteration:  21%|██▏       | 100/469 [54:36<3:39:52, 35.75s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 101/469 [55:12<3:39:01, 35.71s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 102/469 [55:47<3:36:06, 35.33s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 103/469 [56:21<3:34:36, 35.18s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 104/469 [56:57<3:35:24, 35.41s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 105/469 [57:32<3:34:03, 35.28s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 106/469 [58:07<3:31:46, 35.00s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 107/469 [58:41<3:30:18, 34.86s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 108/469 [59:16<3:29:43, 34.86s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 109/469 [59:47<3:22:45, 33.79s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 110/469 [1:00:19<3:17:55, 33.08s/it]\u001b[A\n",
      "Iteration:  24%|██▎       | 111/469 [1:00:50<3:14:42, 32.63s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 112/469 [1:01:23<3:13:43, 32.56s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 113/469 [1:01:54<3:10:53, 32.17s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 114/469 [1:02:26<3:09:56, 32.10s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 115/469 [1:02:57<3:07:02, 31.70s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 116/469 [1:03:30<3:09:12, 32.16s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 117/469 [1:04:01<3:06:36, 31.81s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 118/469 [1:04:34<3:07:56, 32.13s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 119/469 [1:05:05<3:06:19, 31.94s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 120/469 [1:05:38<3:06:37, 32.08s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 121/469 [1:06:10<3:06:37, 32.18s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 122/469 [1:06:42<3:05:09, 32.01s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 123/469 [1:07:13<3:03:17, 31.79s/it]\u001b[A\n",
      "Iteration:  26%|██▋       | 124/469 [1:07:50<3:11:44, 33.35s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 125/469 [1:08:26<3:16:04, 34.20s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 126/469 [1:09:03<3:19:51, 34.96s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 127/469 [1:09:40<3:23:27, 35.69s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 128/469 [1:10:16<3:23:17, 35.77s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 129/469 [1:10:52<3:22:10, 35.68s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 130/469 [1:11:27<3:20:28, 35.48s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 131/469 [1:12:03<3:20:52, 35.66s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 132/469 [1:12:37<3:17:12, 35.11s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 133/469 [1:13:12<3:17:00, 35.18s/it]\u001b[A\n",
      "Iteration:  29%|██▊       | 134/469 [1:13:44<3:11:53, 34.37s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 135/469 [1:14:18<3:09:09, 33.98s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 136/469 [1:14:49<3:05:15, 33.38s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 137/469 [1:15:22<3:02:40, 33.01s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 138/469 [1:15:56<3:03:38, 33.29s/it]\u001b[A\n",
      "Iteration:  30%|██▉       | 139/469 [1:16:30<3:04:45, 33.59s/it]\u001b[A\n",
      "Iteration:  30%|██▉       | 140/469 [1:17:03<3:03:20, 33.44s/it]\u001b[A\n",
      "Iteration:  30%|███       | 141/469 [1:17:38<3:05:38, 33.96s/it]\u001b[A\n",
      "Iteration:  30%|███       | 142/469 [1:18:11<3:03:32, 33.68s/it]\u001b[A\n",
      "Iteration:  30%|███       | 143/469 [1:18:45<3:03:09, 33.71s/it]\u001b[A\n",
      "Iteration:  31%|███       | 144/469 [1:19:19<3:03:53, 33.95s/it]\u001b[A\n",
      "Iteration:  31%|███       | 145/469 [1:19:55<3:05:34, 34.36s/it]\u001b[A\n",
      "Iteration:  31%|███       | 146/469 [1:20:29<3:04:49, 34.33s/it]\u001b[A\n",
      "Iteration:  31%|███▏      | 147/469 [1:21:04<3:04:39, 34.41s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 148/469 [1:21:40<3:06:46, 34.91s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 149/469 [1:22:15<3:07:02, 35.07s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 150/469 [1:22:47<3:00:48, 34.01s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 151/469 [1:23:19<2:57:01, 33.40s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 152/469 [1:23:51<2:54:45, 33.08s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 153/469 [1:24:23<2:52:21, 32.73s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 154/469 [1:24:55<2:50:12, 32.42s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 155/469 [1:25:27<2:49:21, 32.36s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 156/469 [1:26:01<2:51:01, 32.79s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 157/469 [1:26:35<2:52:57, 33.26s/it]\u001b[A\n",
      "Iteration:  34%|███▎      | 158/469 [1:27:09<2:53:40, 33.51s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 159/469 [1:27:43<2:53:06, 33.51s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 160/469 [1:28:17<2:53:41, 33.73s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 161/469 [1:28:50<2:52:55, 33.69s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 162/469 [1:29:24<2:51:44, 33.57s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 163/469 [1:29:58<2:52:23, 33.80s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 164/469 [1:30:32<2:52:12, 33.88s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 165/469 [1:31:05<2:50:41, 33.69s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 166/469 [1:31:40<2:51:37, 33.99s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 167/469 [1:32:16<2:53:47, 34.53s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 168/469 [1:32:50<2:53:27, 34.58s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 169/469 [1:33:25<2:52:37, 34.52s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 170/469 [1:34:00<2:53:00, 34.72s/it]\u001b[A\n",
      "Iteration:  36%|███▋      | 171/469 [1:34:33<2:49:42, 34.17s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 172/469 [1:35:08<2:50:15, 34.40s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 173/469 [1:35:41<2:47:40, 33.99s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 174/469 [1:36:17<2:49:50, 34.54s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 175/469 [1:36:50<2:46:58, 34.08s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 176/469 [1:37:25<2:47:37, 34.32s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 177/469 [1:37:58<2:46:02, 34.12s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 178/469 [1:38:33<2:46:25, 34.32s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 179/469 [1:39:07<2:45:12, 34.18s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 180/469 [1:39:41<2:44:37, 34.18s/it]\u001b[A\n",
      "Iteration:  39%|███▊      | 181/469 [1:40:16<2:44:55, 34.36s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 182/469 [1:40:50<2:43:43, 34.23s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 183/469 [1:41:25<2:44:11, 34.44s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 184/469 [1:41:59<2:42:59, 34.31s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 185/469 [1:42:34<2:43:22, 34.52s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 186/469 [1:43:09<2:43:26, 34.65s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 187/469 [1:43:43<2:42:51, 34.65s/it]\u001b[A\n",
      "Iteration:  40%|████      | 188/469 [1:44:18<2:42:40, 34.73s/it]\u001b[A\n",
      "Iteration:  40%|████      | 189/469 [1:44:52<2:40:57, 34.49s/it]\u001b[A\n",
      "Iteration:  41%|████      | 190/469 [1:45:28<2:42:24, 34.93s/it]\u001b[A\n",
      "Iteration:  41%|████      | 191/469 [1:46:03<2:41:30, 34.86s/it]\u001b[A\n",
      "Iteration:  41%|████      | 192/469 [1:46:39<2:42:22, 35.17s/it]\u001b[A\n",
      "Iteration:  41%|████      | 193/469 [1:47:14<2:41:44, 35.16s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 194/469 [1:47:48<2:39:16, 34.75s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 195/469 [1:48:22<2:38:44, 34.76s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 196/469 [1:48:54<2:34:11, 33.89s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 197/469 [1:49:28<2:33:37, 33.89s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 198/469 [1:49:59<2:29:29, 33.10s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 199/469 [1:50:33<2:29:28, 33.22s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 200/469 [1:51:05<2:26:58, 32.78s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 201/469 [1:51:38<2:26:40, 32.84s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 202/469 [1:52:10<2:25:19, 32.66s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 203/469 [1:52:44<2:27:09, 33.19s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 204/469 [1:53:18<2:26:59, 33.28s/it]\u001b[A\n",
      "Iteration:  44%|████▎     | 205/469 [1:53:51<2:26:00, 33.18s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  44%|████▍     | 206/469 [1:54:26<2:27:39, 33.69s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 207/469 [1:54:59<2:26:26, 33.53s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 208/469 [1:55:32<2:24:55, 33.32s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 209/469 [1:56:04<2:22:51, 32.97s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 210/469 [1:56:36<2:21:36, 32.81s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 211/469 [1:57:09<2:20:32, 32.68s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 212/469 [1:57:42<2:20:29, 32.80s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 213/469 [1:58:14<2:19:30, 32.70s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 214/469 [1:58:47<2:18:52, 32.68s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 215/469 [1:59:19<2:18:03, 32.61s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 216/469 [1:59:50<2:15:04, 32.03s/it]\u001b[A\n",
      "Iteration:  46%|████▋     | 217/469 [2:00:23<2:15:20, 32.22s/it]\u001b[A\n",
      "Iteration:  46%|████▋     | 218/469 [2:00:55<2:14:32, 32.16s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 219/469 [2:01:27<2:13:57, 32.15s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 220/469 [2:01:58<2:12:35, 31.95s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 221/469 [2:02:30<2:11:44, 31.87s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 222/469 [2:03:02<2:12:00, 32.07s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 223/469 [2:03:35<2:11:40, 32.12s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 224/469 [2:04:07<2:11:07, 32.11s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 225/469 [2:04:39<2:11:09, 32.25s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 226/469 [2:05:14<2:13:36, 32.99s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 227/469 [2:05:49<2:15:20, 33.55s/it]\u001b[A\n",
      "Iteration:  49%|████▊     | 228/469 [2:06:24<2:17:02, 34.12s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 229/469 [2:07:00<2:18:16, 34.57s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 230/469 [2:07:38<2:21:52, 35.62s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 231/469 [2:08:10<2:16:19, 34.37s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 232/469 [2:08:41<2:12:07, 33.45s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 233/469 [2:09:14<2:11:38, 33.47s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 234/469 [2:09:45<2:07:38, 32.59s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 235/469 [2:10:17<2:06:29, 32.43s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 236/469 [2:10:49<2:05:23, 32.29s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 237/469 [2:11:21<2:05:07, 32.36s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 238/469 [2:11:53<2:03:26, 32.06s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 239/469 [2:12:26<2:03:51, 32.31s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 240/469 [2:12:57<2:02:33, 32.11s/it]\u001b[A\n",
      "Iteration:  51%|█████▏    | 241/469 [2:13:29<2:01:05, 31.87s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 242/469 [2:14:00<1:59:44, 31.65s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 243/469 [2:14:32<2:00:19, 31.95s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 244/469 [2:15:09<2:04:45, 33.27s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 245/469 [2:15:48<2:11:19, 35.18s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 246/469 [2:16:29<2:16:43, 36.79s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 247/469 [2:17:09<2:19:38, 37.74s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 248/469 [2:17:47<2:19:21, 37.84s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 249/469 [2:18:26<2:20:30, 38.32s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 250/469 [2:19:00<2:14:22, 36.81s/it]\u001b[A\n",
      "Iteration:  54%|█████▎    | 251/469 [2:19:32<2:09:13, 35.57s/it]\u001b[A\n",
      "Iteration:  54%|█████▎    | 252/469 [2:20:03<2:02:59, 34.01s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 253/469 [2:20:34<1:59:09, 33.10s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 254/469 [2:21:07<1:59:07, 33.25s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 255/469 [2:21:49<2:07:35, 35.77s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 256/469 [2:22:31<2:13:14, 37.53s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 257/469 [2:23:10<2:14:13, 37.99s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 258/469 [2:23:50<2:15:36, 38.56s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 259/469 [2:24:28<2:15:10, 38.62s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 260/469 [2:25:01<2:08:26, 36.88s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 261/469 [2:25:34<2:03:17, 35.57s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 262/469 [2:26:06<1:59:39, 34.69s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 263/469 [2:26:38<1:55:40, 33.69s/it]\u001b[A\n",
      "Iteration:  56%|█████▋    | 264/469 [2:27:11<1:54:50, 33.61s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 265/469 [2:27:43<1:52:09, 32.99s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 266/469 [2:28:14<1:50:27, 32.65s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 267/469 [2:28:46<1:49:07, 32.42s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 268/469 [2:29:20<1:49:43, 32.75s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 269/469 [2:29:52<1:48:12, 32.46s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 270/469 [2:30:24<1:47:29, 32.41s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 271/469 [2:30:56<1:46:33, 32.29s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 272/469 [2:31:31<1:49:13, 33.27s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 273/469 [2:32:07<1:50:40, 33.88s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 274/469 [2:32:42<1:51:01, 34.16s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 275/469 [2:33:18<1:52:31, 34.80s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 276/469 [2:33:55<1:54:18, 35.53s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 277/469 [2:34:32<1:55:18, 36.03s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 278/469 [2:35:09<1:54:52, 36.09s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 279/469 [2:35:46<1:55:52, 36.59s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 280/469 [2:36:23<1:55:18, 36.61s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 281/469 [2:37:01<1:56:06, 37.06s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 282/469 [2:37:39<1:56:31, 37.39s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 283/469 [2:38:14<1:53:01, 36.46s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 284/469 [2:38:47<1:49:29, 35.51s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 285/469 [2:39:22<1:48:12, 35.29s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 286/469 [2:39:56<1:46:29, 34.91s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 287/469 [2:40:28<1:43:32, 34.14s/it]\u001b[A\n",
      "Iteration:  61%|██████▏   | 288/469 [2:41:00<1:40:57, 33.47s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 289/469 [2:41:34<1:41:24, 33.80s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 290/469 [2:42:10<1:42:48, 34.46s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 291/469 [2:42:47<1:43:54, 35.03s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 292/469 [2:43:23<1:44:25, 35.40s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 293/469 [2:44:01<1:45:48, 36.07s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 294/469 [2:44:37<1:45:36, 36.21s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 295/469 [2:45:13<1:44:39, 36.09s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 296/469 [2:45:49<1:43:54, 36.04s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 297/469 [2:46:25<1:43:30, 36.11s/it]\u001b[A\n",
      "Iteration:  64%|██████▎   | 298/469 [2:47:02<1:43:30, 36.32s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 299/469 [2:47:38<1:42:58, 36.34s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 300/469 [2:48:14<1:41:34, 36.06s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 301/469 [2:48:50<1:41:05, 36.10s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 302/469 [2:49:26<1:40:18, 36.04s/it]\u001b[A\n",
      "Iteration:  65%|██████▍   | 303/469 [2:50:02<1:39:40, 36.03s/it]\u001b[A\n",
      "Iteration:  65%|██████▍   | 304/469 [2:50:37<1:38:06, 35.68s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 305/469 [2:51:12<1:37:21, 35.62s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 306/469 [2:51:48<1:37:08, 35.75s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 307/469 [2:52:24<1:36:18, 35.67s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 308/469 [2:52:59<1:34:58, 35.40s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 309/469 [2:53:34<1:34:40, 35.50s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 310/469 [2:54:10<1:34:26, 35.64s/it]\u001b[A\n",
      "Iteration:  66%|██████▋   | 311/469 [2:54:47<1:34:34, 35.91s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 312/469 [2:55:22<1:33:29, 35.73s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 313/469 [2:55:58<1:33:03, 35.79s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 314/469 [2:56:34<1:32:12, 35.70s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 315/469 [2:57:07<1:29:46, 34.98s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 316/469 [2:57:40<1:27:29, 34.31s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 317/469 [2:58:14<1:26:45, 34.24s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 318/469 [2:58:46<1:25:01, 33.78s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 319/469 [2:59:20<1:24:06, 33.64s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 320/469 [2:59:53<1:22:57, 33.41s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 321/469 [3:00:25<1:21:28, 33.03s/it]\u001b[A\n",
      "Iteration:  69%|██████▊   | 322/469 [3:00:57<1:20:21, 32.80s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 323/469 [3:01:30<1:19:54, 32.84s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 324/469 [3:02:03<1:19:23, 32.85s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 325/469 [3:02:35<1:18:17, 32.62s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  70%|██████▉   | 326/469 [3:03:07<1:17:25, 32.48s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 327/469 [3:03:38<1:16:06, 32.16s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 328/469 [3:04:14<1:17:55, 33.16s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 329/469 [3:04:49<1:18:45, 33.76s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 330/469 [3:05:25<1:19:32, 34.33s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 331/469 [3:06:01<1:20:15, 34.89s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 332/469 [3:06:37<1:20:21, 35.20s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 333/469 [3:07:13<1:20:08, 35.36s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 334/469 [3:07:49<1:20:16, 35.68s/it]\u001b[A\n",
      "Iteration:  71%|███████▏  | 335/469 [3:08:26<1:20:38, 36.11s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 336/469 [3:09:02<1:19:48, 36.00s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 337/469 [3:09:39<1:19:46, 36.26s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 338/469 [3:10:16<1:19:43, 36.52s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 339/469 [3:10:51<1:18:14, 36.11s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 340/469 [3:11:27<1:17:23, 36.00s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 341/469 [3:12:04<1:17:21, 36.26s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 342/469 [3:12:40<1:16:40, 36.23s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 343/469 [3:13:18<1:17:10, 36.75s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 344/469 [3:13:54<1:16:02, 36.50s/it]\u001b[A\n",
      "Iteration:  74%|███████▎  | 345/469 [3:14:32<1:16:29, 37.01s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 346/469 [3:15:05<1:13:36, 35.91s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 347/469 [3:15:38<1:10:56, 34.89s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 348/469 [3:16:10<1:08:33, 34.00s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 349/469 [3:16:43<1:07:41, 33.85s/it]\u001b[A\n",
      "Iteration:  75%|███████▍  | 350/469 [3:17:15<1:05:43, 33.14s/it]\u001b[A\n",
      "Iteration:  75%|███████▍  | 351/469 [3:17:47<1:04:30, 32.80s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 352/469 [3:18:20<1:04:12, 32.93s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 353/469 [3:18:52<1:03:04, 32.63s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 354/469 [3:19:24<1:02:09, 32.43s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 355/469 [3:19:56<1:01:24, 32.32s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 356/469 [3:20:29<1:01:36, 32.71s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 357/469 [3:21:02<1:00:46, 32.56s/it]\u001b[A\n",
      "Iteration:  76%|███████▋  | 358/469 [3:21:33<59:30, 32.16s/it]  \u001b[A\n",
      "Iteration:  77%|███████▋  | 359/469 [3:22:08<1:00:44, 33.13s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 360/469 [3:22:43<1:01:04, 33.62s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 361/469 [3:23:19<1:01:53, 34.38s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 362/469 [3:23:55<1:01:57, 34.75s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 363/469 [3:24:33<1:03:26, 35.91s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 364/469 [3:25:09<1:02:45, 35.86s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 365/469 [3:25:44<1:01:47, 35.65s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 366/469 [3:26:22<1:02:16, 36.27s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 367/469 [3:26:59<1:02:05, 36.53s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 368/469 [3:27:36<1:01:47, 36.71s/it]\u001b[A\n",
      "Iteration:  79%|███████▊  | 369/469 [3:28:13<1:01:08, 36.69s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 370/469 [3:28:50<1:00:34, 36.72s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 371/469 [3:29:23<58:06, 35.57s/it]  \u001b[A\n",
      "Iteration:  79%|███████▉  | 372/469 [3:29:55<55:58, 34.62s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 373/469 [3:30:29<54:49, 34.27s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 374/469 [3:31:02<53:44, 33.94s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 375/469 [3:31:34<52:20, 33.41s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 376/469 [3:32:06<51:09, 33.00s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 377/469 [3:32:38<50:06, 32.68s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 378/469 [3:33:11<49:38, 32.73s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 379/469 [3:33:43<48:46, 32.52s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 380/469 [3:34:16<48:26, 32.65s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 381/469 [3:34:48<47:42, 32.53s/it]\u001b[A\n",
      "Iteration:  81%|████████▏ | 382/469 [3:35:21<47:32, 32.79s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 383/469 [3:35:52<46:07, 32.18s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 384/469 [3:36:24<45:36, 32.20s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 385/469 [3:36:56<44:44, 31.96s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 386/469 [3:37:29<44:36, 32.25s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 387/469 [3:38:01<43:57, 32.17s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 388/469 [3:38:33<43:24, 32.15s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 389/469 [3:39:06<43:16, 32.46s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 390/469 [3:39:39<42:58, 32.64s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 391/469 [3:40:11<42:06, 32.39s/it]\u001b[A\n",
      "Iteration:  84%|████████▎ | 392/469 [3:40:44<42:02, 32.76s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 393/469 [3:41:18<41:40, 32.91s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 394/469 [3:41:51<41:15, 33.00s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 395/469 [3:42:24<40:53, 33.15s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 396/469 [3:42:59<40:57, 33.66s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 397/469 [3:43:36<41:23, 34.49s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 398/469 [3:44:13<41:52, 35.38s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 399/469 [3:44:50<41:45, 35.79s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 400/469 [3:45:28<41:52, 36.41s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 401/469 [3:46:04<41:22, 36.50s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 402/469 [3:46:41<40:42, 36.45s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 403/469 [3:47:19<40:40, 36.98s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 404/469 [3:47:56<40:12, 37.11s/it]\u001b[A\n",
      "Iteration:  86%|████████▋ | 405/469 [3:48:33<39:25, 36.97s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 406/469 [3:49:09<38:38, 36.79s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 407/469 [3:49:46<37:55, 36.70s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 408/469 [3:50:21<36:56, 36.34s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 409/469 [3:50:57<36:03, 36.06s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 410/469 [3:51:34<35:42, 36.32s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 411/469 [3:52:09<34:44, 35.95s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 412/469 [3:52:45<34:11, 36.00s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 413/469 [3:53:22<34:00, 36.44s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 414/469 [3:54:00<33:39, 36.72s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 415/469 [3:54:36<32:55, 36.58s/it]\u001b[A\n",
      "Iteration:  89%|████████▊ | 416/469 [3:55:11<31:56, 36.16s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 417/469 [3:55:44<30:31, 35.23s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 418/469 [3:56:17<29:13, 34.38s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 419/469 [3:56:49<28:05, 33.71s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 420/469 [3:57:23<27:35, 33.79s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 421/469 [3:57:55<26:34, 33.22s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 422/469 [3:58:28<25:58, 33.17s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 423/469 [3:59:00<25:08, 32.78s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 424/469 [3:59:34<24:53, 33.19s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 425/469 [4:00:06<24:06, 32.87s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 426/469 [4:00:38<23:25, 32.68s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 427/469 [4:01:11<22:49, 32.60s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 428/469 [4:01:44<22:23, 32.76s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 429/469 [4:02:17<21:53, 32.83s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 430/469 [4:02:50<21:26, 32.98s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 431/469 [4:03:24<21:01, 33.19s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 432/469 [4:04:00<20:57, 33.98s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 433/469 [4:04:37<20:58, 34.97s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 434/469 [4:05:12<20:27, 35.08s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 435/469 [4:05:48<20:00, 35.30s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 436/469 [4:06:24<19:30, 35.48s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 437/469 [4:06:59<18:49, 35.31s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 438/469 [4:07:35<18:22, 35.57s/it]\u001b[A\n",
      "Iteration:  94%|█████████▎| 439/469 [4:08:10<17:42, 35.41s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 440/469 [4:08:44<16:51, 34.89s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 441/469 [4:09:20<16:26, 35.23s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 442/469 [4:09:55<15:54, 35.37s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 443/469 [4:10:30<15:15, 35.19s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 444/469 [4:11:04<14:27, 34.68s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 445/469 [4:11:39<14:00, 35.01s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 446/469 [4:12:14<13:23, 34.95s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 447/469 [4:12:49<12:47, 34.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  96%|█████████▌| 448/469 [4:13:24<12:10, 34.81s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 449/469 [4:13:59<11:40, 35.04s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 450/469 [4:14:35<11:08, 35.21s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 451/469 [4:15:10<10:35, 35.32s/it]\u001b[A\n",
      "Iteration:  96%|█████████▋| 452/469 [4:15:46<10:03, 35.50s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 453/469 [4:16:21<09:22, 35.15s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 454/469 [4:16:56<08:47, 35.17s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 455/469 [4:17:31<08:12, 35.16s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 456/469 [4:18:07<07:39, 35.31s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 457/469 [4:18:41<07:00, 35.03s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 458/469 [4:19:16<06:26, 35.10s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 459/469 [4:19:52<05:52, 35.28s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 460/469 [4:20:27<05:17, 35.25s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 461/469 [4:21:01<04:38, 34.83s/it]\u001b[A\n",
      "Iteration:  99%|█████████▊| 462/469 [4:21:38<04:07, 35.39s/it]\u001b[A\n",
      "Iteration:  99%|█████████▊| 463/469 [4:22:15<03:35, 35.96s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 464/469 [4:22:47<02:54, 34.92s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 465/469 [4:23:22<02:18, 34.74s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 466/469 [4:23:57<01:44, 34.78s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 467/469 [4:24:31<01:09, 34.54s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 468/469 [4:25:04<00:34, 34.16s/it]\u001b[A\n",
      "Epoch:  33%|███▎      | 1/3 [4:25:30<8:51:01, 15930.92s/it]it]\u001b[A\n",
      "Iteration:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/469 [00:33<4:20:16, 33.37s/it]\u001b[A\n",
      "Iteration:   0%|          | 2/469 [01:06<4:18:50, 33.26s/it]\u001b[A\n",
      "Iteration:   1%|          | 3/469 [01:40<4:19:34, 33.42s/it]\u001b[A\n",
      "Iteration:   1%|          | 4/469 [02:13<4:18:27, 33.35s/it]\u001b[A\n",
      "Iteration:   1%|          | 5/469 [02:47<4:20:13, 33.65s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 6/469 [03:21<4:18:55, 33.55s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 7/469 [03:54<4:17:33, 33.45s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 8/469 [04:27<4:16:32, 33.39s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 9/469 [05:00<4:16:05, 33.40s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 10/469 [05:33<4:13:05, 33.08s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 11/469 [06:06<4:12:40, 33.10s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 12/469 [06:42<4:17:51, 33.85s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 13/469 [07:17<4:21:26, 34.40s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 14/469 [07:53<4:23:41, 34.77s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 15/469 [08:28<4:23:21, 34.80s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 16/469 [09:04<4:26:00, 35.23s/it]\u001b[A\n",
      "Iteration:   4%|▎         | 17/469 [09:39<4:25:58, 35.31s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 18/469 [10:14<4:23:19, 35.03s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 19/469 [10:49<4:24:02, 35.21s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 20/469 [11:25<4:23:27, 35.21s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 21/469 [12:00<4:23:15, 35.26s/it]\u001b[A\n",
      "Iteration:   5%|▍         | 22/469 [12:37<4:26:06, 35.72s/it]\u001b[A\n",
      "Iteration:   5%|▍         | 23/469 [13:13<4:25:49, 35.76s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 24/469 [13:49<4:27:14, 36.03s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 25/469 [14:24<4:23:35, 35.62s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 26/469 [15:00<4:23:52, 35.74s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 27/469 [15:36<4:23:56, 35.83s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 28/469 [16:11<4:22:23, 35.70s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 29/469 [16:49<4:24:53, 36.12s/it]\u001b[A\n",
      "Iteration:   6%|▋         | 30/469 [17:24<4:22:31, 35.88s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 31/469 [18:01<4:24:20, 36.21s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 32/469 [18:37<4:23:51, 36.23s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 33/469 [19:14<4:24:36, 36.41s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 34/469 [19:51<4:25:10, 36.58s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 35/469 [20:27<4:23:15, 36.39s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 36/469 [21:04<4:23:37, 36.53s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 37/469 [21:40<4:23:04, 36.54s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 38/469 [22:17<4:22:47, 36.58s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 39/469 [22:55<4:26:05, 37.13s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 40/469 [23:30<4:19:54, 36.35s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 41/469 [24:05<4:16:56, 36.02s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 42/469 [24:41<4:15:26, 35.89s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 43/469 [25:17<4:16:33, 36.14s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 44/469 [25:54<4:17:29, 36.35s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 45/469 [26:29<4:12:52, 35.78s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 46/469 [27:05<4:12:42, 35.85s/it]\u001b[A\n",
      "Iteration:  10%|█         | 47/469 [27:40<4:10:50, 35.66s/it]\u001b[A\n",
      "Iteration:  10%|█         | 48/469 [28:14<4:06:02, 35.06s/it]\u001b[A\n",
      "Iteration:  10%|█         | 49/469 [28:49<4:05:29, 35.07s/it]\u001b[A\n",
      "Iteration:  11%|█         | 50/469 [29:24<4:05:19, 35.13s/it]\u001b[A\n",
      "Iteration:  11%|█         | 51/469 [29:59<4:04:37, 35.11s/it]\u001b[A\n",
      "Iteration:  11%|█         | 52/469 [30:31<3:58:09, 34.27s/it]\u001b[A\n",
      "Iteration:  11%|█▏        | 53/469 [31:05<3:56:22, 34.09s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 54/469 [31:39<3:55:01, 33.98s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 55/469 [32:12<3:52:37, 33.71s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 56/469 [32:46<3:52:18, 33.75s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 57/469 [33:22<3:56:28, 34.44s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 58/469 [33:57<3:57:05, 34.61s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 59/469 [34:30<3:54:07, 34.26s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 60/469 [35:03<3:50:20, 33.79s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 61/469 [35:38<3:52:04, 34.13s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 62/469 [36:10<3:47:13, 33.50s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 63/469 [36:44<3:47:18, 33.59s/it]\u001b[A\n",
      "Iteration:  14%|█▎        | 64/469 [37:16<3:44:50, 33.31s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 65/469 [37:49<3:42:38, 33.07s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 66/469 [38:22<3:42:00, 33.05s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 67/469 [38:56<3:43:30, 33.36s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 68/469 [39:30<3:43:44, 33.48s/it]\u001b[A\n",
      "Iteration:  15%|█▍        | 69/469 [40:05<3:46:11, 33.93s/it]\u001b[A\n",
      "Iteration:  15%|█▍        | 70/469 [40:37<3:41:55, 33.37s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 71/469 [41:10<3:40:36, 33.26s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 72/469 [41:47<3:48:39, 34.56s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 73/469 [42:22<3:48:24, 34.61s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 74/469 [42:58<3:50:12, 34.97s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 75/469 [43:33<3:49:55, 35.01s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 76/469 [44:10<3:53:11, 35.60s/it]\u001b[A\n",
      "Iteration:  16%|█▋        | 77/469 [44:46<3:53:04, 35.67s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 78/469 [45:22<3:53:07, 35.77s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 79/469 [45:58<3:53:06, 35.86s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 80/469 [46:34<3:53:15, 35.98s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 81/469 [47:10<3:52:56, 36.02s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 82/469 [47:48<3:54:53, 36.42s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 83/469 [48:23<3:51:45, 36.02s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 84/469 [48:57<3:47:20, 35.43s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 85/469 [49:31<3:44:08, 35.02s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 86/469 [50:04<3:39:18, 34.36s/it]\u001b[A\n",
      "Iteration:  19%|█▊        | 87/469 [50:38<3:37:59, 34.24s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 88/469 [51:11<3:35:52, 34.00s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 89/469 [51:50<3:44:02, 35.37s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 90/469 [52:28<3:48:42, 36.21s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 91/469 [53:04<3:47:49, 36.16s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 92/469 [53:41<3:48:24, 36.35s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 93/469 [54:18<3:49:22, 36.60s/it]\u001b[A\n",
      "Iteration:  20%|██        | 94/469 [54:53<3:46:43, 36.28s/it]\u001b[A\n",
      "Iteration:  20%|██        | 95/469 [55:29<3:45:29, 36.18s/it]\u001b[A\n",
      "Iteration:  20%|██        | 96/469 [56:06<3:46:09, 36.38s/it]\u001b[A\n",
      "Iteration:  21%|██        | 97/469 [56:46<3:51:39, 37.36s/it]\u001b[A\n",
      "Iteration:  21%|██        | 98/469 [57:22<3:48:10, 36.90s/it]\u001b[A\n",
      "Iteration:  21%|██        | 99/469 [57:59<3:48:17, 37.02s/it]\u001b[A\n",
      "Iteration:  21%|██▏       | 100/469 [58:35<3:45:11, 36.62s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 101/469 [59:11<3:44:29, 36.60s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 102/469 [59:48<3:44:32, 36.71s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  22%|██▏       | 103/469 [1:00:22<3:39:34, 36.00s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 104/469 [1:00:59<3:39:56, 36.15s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 105/469 [1:01:36<3:40:41, 36.38s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 106/469 [1:02:12<3:39:15, 36.24s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 107/469 [1:02:48<3:38:38, 36.24s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 108/469 [1:03:23<3:35:44, 35.86s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 109/469 [1:04:00<3:37:15, 36.21s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 110/469 [1:04:35<3:34:35, 35.86s/it]\u001b[A\n",
      "Iteration:  24%|██▎       | 111/469 [1:05:11<3:33:22, 35.76s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 112/469 [1:05:47<3:33:51, 35.94s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 113/469 [1:06:24<3:35:00, 36.24s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 114/469 [1:06:59<3:32:26, 35.91s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 115/469 [1:07:34<3:31:03, 35.77s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 116/469 [1:08:10<3:30:19, 35.75s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 117/469 [1:08:46<3:29:48, 35.76s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 118/469 [1:09:21<3:28:00, 35.56s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 119/469 [1:09:58<3:29:08, 35.85s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 120/469 [1:10:33<3:27:30, 35.68s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 121/469 [1:11:09<3:27:48, 35.83s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 122/469 [1:11:46<3:28:32, 36.06s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 123/469 [1:12:20<3:25:11, 35.58s/it]\u001b[A\n",
      "Iteration:  26%|██▋       | 124/469 [1:12:53<3:19:33, 34.70s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 125/469 [1:13:26<3:16:03, 34.20s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 126/469 [1:14:02<3:19:01, 34.82s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 127/469 [1:14:35<3:15:34, 34.31s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 128/469 [1:15:08<3:12:15, 33.83s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 129/469 [1:15:41<3:11:17, 33.76s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 130/469 [1:16:16<3:11:54, 33.97s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 131/469 [1:16:49<3:09:43, 33.68s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 132/469 [1:17:23<3:09:23, 33.72s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 133/469 [1:17:55<3:07:15, 33.44s/it]\u001b[A\n",
      "Iteration:  29%|██▊       | 134/469 [1:18:30<3:08:18, 33.73s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 135/469 [1:19:04<3:08:08, 33.80s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 136/469 [1:19:38<3:07:23, 33.76s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 137/469 [1:20:11<3:05:53, 33.59s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 138/469 [1:20:50<3:13:58, 35.16s/it]\u001b[A\n",
      "Iteration:  30%|██▉       | 139/469 [1:21:26<3:16:19, 35.69s/it]\u001b[A\n",
      "Iteration:  30%|██▉       | 140/469 [1:22:05<3:20:24, 36.55s/it]\u001b[A\n",
      "Iteration:  30%|███       | 141/469 [1:22:40<3:17:01, 36.04s/it]\u001b[A\n",
      "Iteration:  30%|███       | 142/469 [1:23:13<3:10:56, 35.03s/it]\u001b[A\n",
      "Iteration:  30%|███       | 143/469 [1:23:47<3:10:05, 34.99s/it]\u001b[A\n",
      "Iteration:  31%|███       | 144/469 [1:24:24<3:11:37, 35.38s/it]\u001b[A\n",
      "Iteration:  31%|███       | 145/469 [1:25:00<3:12:48, 35.71s/it]\u001b[A\n",
      "Iteration:  31%|███       | 146/469 [1:25:38<3:14:53, 36.20s/it]\u001b[A\n",
      "Iteration:  31%|███▏      | 147/469 [1:26:14<3:14:53, 36.31s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 148/469 [1:26:51<3:15:12, 36.49s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 149/469 [1:27:28<3:15:34, 36.67s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 150/469 [1:28:05<3:15:01, 36.68s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 151/469 [1:28:43<3:17:19, 37.23s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 152/469 [1:29:19<3:14:47, 36.87s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 153/469 [1:29:56<3:14:23, 36.91s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 154/469 [1:30:35<3:16:09, 37.36s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 155/469 [1:31:12<3:14:54, 37.24s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 156/469 [1:31:48<3:13:14, 37.04s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 157/469 [1:32:22<3:08:04, 36.17s/it]\u001b[A\n",
      "Iteration:  34%|███▎      | 158/469 [1:32:57<3:04:42, 35.64s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 159/469 [1:33:30<2:59:40, 34.78s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 160/469 [1:34:03<2:56:49, 34.34s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 161/469 [1:34:37<2:55:57, 34.28s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 162/469 [1:35:10<2:53:54, 33.99s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 163/469 [1:35:43<2:51:52, 33.70s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 164/469 [1:36:17<2:50:56, 33.63s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 165/469 [1:36:51<2:50:29, 33.65s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 166/469 [1:37:25<2:50:20, 33.73s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 167/469 [1:37:59<2:50:47, 33.93s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 168/469 [1:38:33<2:50:03, 33.90s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 169/469 [1:39:05<2:47:45, 33.55s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 170/469 [1:39:40<2:48:00, 33.71s/it]\u001b[A\n",
      "Iteration:  36%|███▋      | 171/469 [1:40:12<2:46:17, 33.48s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 172/469 [1:40:47<2:47:05, 33.75s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 173/469 [1:41:20<2:45:26, 33.53s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 174/469 [1:41:53<2:44:03, 33.37s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 175/469 [1:42:26<2:42:45, 33.21s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 176/469 [1:43:01<2:44:29, 33.68s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 177/469 [1:43:34<2:44:04, 33.71s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 178/469 [1:44:08<2:43:06, 33.63s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 179/469 [1:44:43<2:44:26, 34.02s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 180/469 [1:45:19<2:47:09, 34.70s/it]\u001b[A\n",
      "Iteration:  39%|███▊      | 181/469 [1:45:55<2:48:19, 35.07s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 182/469 [1:46:31<2:49:06, 35.35s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 183/469 [1:47:08<2:50:43, 35.82s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 184/469 [1:47:44<2:50:51, 35.97s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 185/469 [1:48:20<2:50:39, 36.06s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 186/469 [1:48:58<2:52:01, 36.47s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 187/469 [1:49:34<2:51:35, 36.51s/it]\u001b[A\n",
      "Iteration:  40%|████      | 188/469 [1:50:11<2:51:15, 36.57s/it]\u001b[A\n",
      "Iteration:  40%|████      | 189/469 [1:50:48<2:50:55, 36.63s/it]\u001b[A\n",
      "Iteration:  41%|████      | 190/469 [1:51:25<2:50:29, 36.67s/it]\u001b[A\n",
      "Iteration:  41%|████      | 191/469 [1:52:01<2:49:59, 36.69s/it]\u001b[A\n",
      "Iteration:  41%|████      | 192/469 [1:52:38<2:49:04, 36.62s/it]\u001b[A\n",
      "Iteration:  41%|████      | 193/469 [1:53:15<2:48:57, 36.73s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 194/469 [1:53:52<2:48:47, 36.83s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 195/469 [1:54:27<2:46:15, 36.41s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 196/469 [1:55:04<2:46:20, 36.56s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 197/469 [1:55:40<2:44:48, 36.35s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 198/469 [1:56:16<2:42:54, 36.07s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 199/469 [1:56:53<2:44:34, 36.57s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 200/469 [1:57:31<2:45:18, 36.87s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 201/469 [1:58:07<2:43:29, 36.60s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 202/469 [1:58:44<2:43:49, 36.81s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 203/469 [1:59:20<2:42:19, 36.61s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 204/469 [1:59:56<2:40:58, 36.45s/it]\u001b[A\n",
      "Iteration:  44%|████▎     | 205/469 [2:00:31<2:38:23, 36.00s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 206/469 [2:01:07<2:37:15, 35.88s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 207/469 [2:01:44<2:38:32, 36.31s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 208/469 [2:02:18<2:34:36, 35.54s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 209/469 [2:02:52<2:31:46, 35.02s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 210/469 [2:03:27<2:30:51, 34.95s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 211/469 [2:04:02<2:30:19, 34.96s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 212/469 [2:04:35<2:27:48, 34.51s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 213/469 [2:05:08<2:25:10, 34.02s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 214/469 [2:05:41<2:23:23, 33.74s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 215/469 [2:06:14<2:21:57, 33.53s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 216/469 [2:06:48<2:21:40, 33.60s/it]\u001b[A\n",
      "Iteration:  46%|████▋     | 217/469 [2:07:23<2:22:53, 34.02s/it]\u001b[A\n",
      "Iteration:  46%|████▋     | 218/469 [2:07:57<2:22:24, 34.04s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 219/469 [2:08:31<2:21:22, 33.93s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 220/469 [2:09:04<2:20:43, 33.91s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 221/469 [2:09:39<2:21:37, 34.26s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 222/469 [2:10:14<2:21:02, 34.26s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  48%|████▊     | 223/469 [2:10:47<2:19:05, 33.92s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 224/469 [2:11:20<2:18:05, 33.82s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 225/469 [2:11:55<2:18:55, 34.16s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 226/469 [2:12:28<2:16:26, 33.69s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 227/469 [2:13:02<2:16:08, 33.76s/it]\u001b[A\n",
      "Iteration:  49%|████▊     | 228/469 [2:13:39<2:19:21, 34.69s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 229/469 [2:14:16<2:22:20, 35.58s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 230/469 [2:14:54<2:24:41, 36.32s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 231/469 [2:15:33<2:26:18, 36.88s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 232/469 [2:16:10<2:26:15, 37.03s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 233/469 [2:16:47<2:26:05, 37.14s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 234/469 [2:17:25<2:26:15, 37.34s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 235/469 [2:18:01<2:24:18, 37.00s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 236/469 [2:18:37<2:21:53, 36.54s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 237/469 [2:19:12<2:19:47, 36.16s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 238/469 [2:19:48<2:18:57, 36.09s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 239/469 [2:20:22<2:15:43, 35.41s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 240/469 [2:20:56<2:13:20, 34.94s/it]\u001b[A\n",
      "Iteration:  51%|█████▏    | 241/469 [2:21:31<2:12:59, 35.00s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 242/469 [2:22:05<2:11:25, 34.74s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 243/469 [2:22:39<2:10:08, 34.55s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 244/469 [2:23:13<2:08:30, 34.27s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 245/469 [2:23:49<2:09:46, 34.76s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 246/469 [2:24:24<2:09:49, 34.93s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 247/469 [2:25:00<2:10:19, 35.22s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 248/469 [2:25:36<2:11:09, 35.61s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 249/469 [2:26:11<2:09:31, 35.33s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 250/469 [2:26:46<2:08:01, 35.07s/it]\u001b[A\n",
      "Iteration:  54%|█████▎    | 251/469 [2:27:21<2:07:46, 35.17s/it]\u001b[A\n",
      "Iteration:  54%|█████▎    | 252/469 [2:27:57<2:08:29, 35.53s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 253/469 [2:28:35<2:09:53, 36.08s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 254/469 [2:29:11<2:09:43, 36.20s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 255/469 [2:29:49<2:11:18, 36.82s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 256/469 [2:30:25<2:09:42, 36.54s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 257/469 [2:31:02<2:09:03, 36.52s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 258/469 [2:31:39<2:09:39, 36.87s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 259/469 [2:32:17<2:09:52, 37.11s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 260/469 [2:32:54<2:08:54, 37.01s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 261/469 [2:33:30<2:07:51, 36.88s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 262/469 [2:34:09<2:08:54, 37.37s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 263/469 [2:34:45<2:07:08, 37.03s/it]\u001b[A\n",
      "Iteration:  56%|█████▋    | 264/469 [2:35:21<2:05:35, 36.76s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 265/469 [2:35:59<2:06:17, 37.14s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 266/469 [2:36:36<2:04:37, 36.84s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 267/469 [2:37:11<2:02:24, 36.36s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 268/469 [2:37:45<2:00:03, 35.84s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 269/469 [2:38:21<1:59:34, 35.87s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 270/469 [2:38:57<1:59:04, 35.90s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 271/469 [2:39:33<1:57:54, 35.73s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 272/469 [2:40:08<1:57:02, 35.65s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 273/469 [2:40:43<1:55:42, 35.42s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 274/469 [2:41:17<1:53:45, 35.00s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 275/469 [2:41:52<1:53:31, 35.11s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 276/469 [2:42:28<1:53:06, 35.17s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 277/469 [2:43:02<1:51:49, 34.95s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 278/469 [2:43:38<1:52:05, 35.21s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 279/469 [2:44:14<1:51:59, 35.36s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 280/469 [2:44:49<1:51:02, 35.25s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 281/469 [2:45:23<1:50:02, 35.12s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 282/469 [2:45:57<1:47:53, 34.62s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 283/469 [2:46:31<1:46:43, 34.43s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 284/469 [2:47:05<1:45:39, 34.27s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 285/469 [2:47:38<1:44:08, 33.96s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 286/469 [2:48:12<1:43:29, 33.93s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 287/469 [2:48:45<1:41:56, 33.61s/it]\u001b[A\n",
      "Iteration:  61%|██████▏   | 288/469 [2:49:18<1:41:29, 33.65s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 289/469 [2:49:53<1:41:27, 33.82s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 290/469 [2:50:27<1:41:07, 33.89s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 291/469 [2:51:01<1:40:53, 34.01s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 292/469 [2:51:34<1:39:45, 33.82s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 293/469 [2:52:07<1:38:03, 33.43s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 294/469 [2:52:45<1:41:57, 34.96s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 295/469 [2:53:25<1:44:57, 36.19s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 296/469 [2:54:04<1:47:18, 37.21s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 297/469 [2:54:43<1:48:11, 37.74s/it]\u001b[A\n",
      "Iteration:  64%|██████▎   | 298/469 [2:55:22<1:48:10, 37.95s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 299/469 [2:55:59<1:47:19, 37.88s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 300/469 [2:56:36<1:45:19, 37.39s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 301/469 [2:57:14<1:45:41, 37.75s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 302/469 [2:57:50<1:43:08, 37.06s/it]\u001b[A\n",
      "Iteration:  65%|██████▍   | 303/469 [2:58:24<1:40:32, 36.34s/it]\u001b[A\n",
      "Iteration:  65%|██████▍   | 304/469 [2:58:58<1:38:11, 35.71s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 305/469 [2:59:34<1:37:32, 35.68s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 306/469 [3:00:08<1:35:30, 35.16s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 307/469 [3:00:43<1:34:27, 34.99s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 308/469 [3:01:17<1:33:48, 34.96s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 309/469 [3:01:51<1:32:24, 34.65s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 310/469 [3:02:26<1:32:09, 34.78s/it]\u001b[A\n",
      "Iteration:  66%|██████▋   | 311/469 [3:03:00<1:30:36, 34.41s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 312/469 [3:03:34<1:29:29, 34.20s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 313/469 [3:04:07<1:27:58, 33.84s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 314/469 [3:04:41<1:28:04, 34.09s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 315/469 [3:05:14<1:26:14, 33.60s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 316/469 [3:05:48<1:25:49, 33.66s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 317/469 [3:06:20<1:24:32, 33.37s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 318/469 [3:06:55<1:24:33, 33.60s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 319/469 [3:07:28<1:23:43, 33.49s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 320/469 [3:08:03<1:24:16, 33.93s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 321/469 [3:08:37<1:23:48, 33.98s/it]\u001b[A\n",
      "Iteration:  69%|██████▊   | 322/469 [3:09:10<1:23:02, 33.89s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 323/469 [3:09:44<1:22:14, 33.80s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 324/469 [3:10:17<1:20:55, 33.49s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 325/469 [3:10:51<1:20:43, 33.64s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 326/469 [3:11:25<1:20:18, 33.70s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 327/469 [3:11:56<1:18:22, 33.12s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 328/469 [3:12:30<1:18:06, 33.24s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 329/469 [3:13:04<1:18:24, 33.60s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 330/469 [3:13:38<1:17:32, 33.47s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 331/469 [3:14:10<1:16:16, 33.17s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 332/469 [3:14:44<1:16:33, 33.53s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 333/469 [3:15:16<1:14:47, 33.00s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 334/469 [3:15:49<1:14:26, 33.08s/it]\u001b[A\n",
      "Iteration:  71%|███████▏  | 335/469 [3:16:22<1:13:17, 32.82s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 336/469 [3:16:56<1:13:39, 33.23s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 337/469 [3:17:28<1:12:14, 32.84s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 338/469 [3:18:02<1:12:26, 33.18s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 339/469 [3:18:35<1:11:46, 33.13s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 340/469 [3:19:08<1:11:38, 33.32s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 341/469 [3:19:42<1:11:17, 33.42s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 342/469 [3:20:15<1:10:28, 33.29s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  73%|███████▎  | 343/469 [3:20:47<1:09:16, 32.99s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 344/469 [3:21:20<1:08:28, 32.87s/it]\u001b[A\n",
      "Iteration:  74%|███████▎  | 345/469 [3:21:53<1:07:53, 32.85s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 346/469 [3:22:25<1:06:54, 32.64s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 347/469 [3:22:57<1:06:14, 32.58s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 348/469 [3:23:30<1:05:30, 32.48s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 349/469 [3:24:02<1:04:42, 32.36s/it]\u001b[A\n",
      "Iteration:  75%|███████▍  | 350/469 [3:24:34<1:04:03, 32.30s/it]\u001b[A\n",
      "Iteration:  75%|███████▍  | 351/469 [3:25:07<1:03:47, 32.44s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 352/469 [3:25:39<1:03:10, 32.40s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 353/469 [3:26:10<1:02:05, 32.12s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 354/469 [3:26:42<1:01:30, 32.09s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 355/469 [3:27:15<1:01:22, 32.30s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 356/469 [3:27:48<1:01:21, 32.58s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 357/469 [3:28:21<1:00:37, 32.48s/it]\u001b[A\n",
      "Iteration:  76%|███████▋  | 358/469 [3:28:56<1:01:30, 33.25s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 359/469 [3:29:29<1:00:57, 33.25s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 360/469 [3:30:03<1:00:42, 33.42s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 361/469 [3:30:35<59:23, 33.00s/it]  \u001b[A\n",
      "Iteration:  77%|███████▋  | 362/469 [3:31:08<59:09, 33.17s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 363/469 [3:31:41<58:14, 32.97s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 364/469 [3:32:13<57:26, 32.82s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 365/469 [3:32:46<57:02, 32.91s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 366/469 [3:33:19<56:31, 32.93s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 367/469 [3:33:54<56:38, 33.31s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 368/469 [3:34:26<55:25, 32.92s/it]\u001b[A\n",
      "Iteration:  79%|███████▊  | 369/469 [3:34:59<54:49, 32.90s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 370/469 [3:35:32<54:32, 33.05s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 371/469 [3:36:05<54:12, 33.19s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 372/469 [3:36:38<53:17, 32.96s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 373/469 [3:37:11<52:41, 32.93s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 374/469 [3:37:44<52:10, 32.95s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 375/469 [3:38:17<51:37, 32.95s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 376/469 [3:38:50<51:11, 33.02s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 377/469 [3:39:23<50:34, 32.98s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 378/469 [3:39:56<50:04, 33.02s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 379/469 [3:40:28<49:05, 32.72s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 380/469 [3:41:01<48:31, 32.71s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 381/469 [3:41:34<48:27, 33.04s/it]\u001b[A\n",
      "Iteration:  81%|████████▏ | 382/469 [3:42:07<47:42, 32.91s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 383/469 [3:42:40<47:00, 32.79s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 384/469 [3:43:13<46:32, 32.85s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 385/469 [3:43:49<47:30, 33.93s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 386/469 [3:44:23<46:51, 33.87s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 387/469 [3:44:57<46:21, 33.92s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 388/469 [3:45:31<45:48, 33.93s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 389/469 [3:46:05<45:12, 33.90s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 390/469 [3:46:39<44:44, 33.99s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 391/469 [3:47:14<44:36, 34.31s/it]\u001b[A\n",
      "Iteration:  84%|████████▎ | 392/469 [3:47:49<44:20, 34.56s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 393/469 [3:48:23<43:27, 34.31s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 394/469 [3:48:57<43:05, 34.47s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 395/469 [3:49:30<41:54, 33.97s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 396/469 [3:50:05<41:26, 34.06s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 397/469 [3:50:37<40:24, 33.67s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 398/469 [3:51:09<39:07, 33.06s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 399/469 [3:51:43<38:48, 33.26s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 400/469 [3:52:16<38:13, 33.24s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 401/469 [3:52:50<37:53, 33.43s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 402/469 [3:53:24<37:29, 33.58s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 403/469 [3:53:59<37:24, 34.00s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 404/469 [3:54:31<36:16, 33.49s/it]\u001b[A\n",
      "Iteration:  86%|████████▋ | 405/469 [3:55:04<35:30, 33.30s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 406/469 [3:55:38<35:20, 33.65s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 407/469 [3:56:11<34:34, 33.46s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 408/469 [3:56:45<33:59, 33.43s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 409/469 [3:57:19<33:36, 33.62s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 410/469 [3:57:54<33:30, 34.08s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 411/469 [3:58:26<32:19, 33.43s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 412/469 [3:59:00<31:50, 33.52s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 413/469 [3:59:33<31:13, 33.45s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 414/469 [4:00:06<30:41, 33.48s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 415/469 [4:00:39<29:52, 33.20s/it]\u001b[A\n",
      "Iteration:  89%|████████▊ | 416/469 [4:01:12<29:18, 33.17s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 417/469 [4:01:45<28:39, 33.06s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 418/469 [4:02:18<28:09, 33.13s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 419/469 [4:02:52<27:47, 33.34s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 420/469 [4:03:25<27:07, 33.22s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 421/469 [4:04:00<27:00, 33.76s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 422/469 [4:04:33<26:13, 33.47s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 423/469 [4:05:06<25:35, 33.37s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 424/469 [4:05:42<25:33, 34.09s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 425/469 [4:06:16<25:02, 34.14s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 426/469 [4:06:50<24:26, 34.12s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 427/469 [4:07:24<23:52, 34.11s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 428/469 [4:07:59<23:28, 34.36s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 429/469 [4:08:33<22:47, 34.18s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 430/469 [4:09:08<22:22, 34.42s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 431/469 [4:09:41<21:32, 34.00s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 432/469 [4:10:16<21:08, 34.29s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 433/469 [4:10:50<20:35, 34.32s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 434/469 [4:11:25<20:06, 34.48s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 435/469 [4:12:00<19:35, 34.58s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 436/469 [4:12:34<18:55, 34.41s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 437/469 [4:13:08<18:15, 34.23s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 438/469 [4:13:42<17:43, 34.31s/it]\u001b[A\n",
      "Iteration:  94%|█████████▎| 439/469 [4:14:17<17:12, 34.42s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 440/469 [4:14:51<16:36, 34.37s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 441/469 [4:15:24<15:49, 33.92s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 442/469 [4:15:59<15:25, 34.28s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 443/469 [4:16:34<14:53, 34.36s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 444/469 [4:17:09<14:24, 34.58s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 445/469 [4:17:43<13:48, 34.53s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 446/469 [4:18:18<13:14, 34.56s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 447/469 [4:18:53<12:48, 34.92s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 448/469 [4:19:28<12:10, 34.77s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 449/469 [4:20:03<11:37, 34.87s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 450/469 [4:20:39<11:10, 35.31s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 451/469 [4:21:13<10:29, 34.98s/it]\u001b[A\n",
      "Iteration:  96%|█████████▋| 452/469 [4:21:48<09:53, 34.89s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 453/469 [4:22:23<09:16, 34.79s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 454/469 [4:22:58<08:42, 34.80s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 455/469 [4:23:32<08:04, 34.61s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 456/469 [4:24:07<07:31, 34.74s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 457/469 [4:24:42<06:58, 34.87s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 458/469 [4:25:16<06:20, 34.55s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 459/469 [4:25:51<05:47, 34.74s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 460/469 [4:26:26<05:12, 34.70s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 461/469 [4:27:00<04:36, 34.55s/it]\u001b[A\n",
      "Iteration:  99%|█████████▊| 462/469 [4:27:35<04:03, 34.81s/it]\u001b[A\n",
      "Iteration:  99%|█████████▊| 463/469 [4:28:10<03:28, 34.80s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 464/469 [4:28:46<02:55, 35.11s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 465/469 [4:29:20<02:19, 34.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  99%|█████████▉| 466/469 [4:29:55<01:44, 34.81s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 467/469 [4:30:30<01:10, 35.07s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 468/469 [4:31:05<00:34, 34.86s/it]\u001b[A\n",
      "Epoch:  67%|██████▋   | 2/3 [8:57:03<4:27:19, 16039.46s/it]it]\u001b[A\n",
      "Iteration:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/469 [00:34<4:31:20, 34.79s/it]\u001b[A\n",
      "Iteration:   0%|          | 2/469 [01:10<4:32:33, 35.02s/it]\u001b[A\n",
      "Iteration:   1%|          | 3/469 [01:44<4:30:02, 34.77s/it]\u001b[A\n",
      "Iteration:   1%|          | 4/469 [02:20<4:32:24, 35.15s/it]\u001b[A\n",
      "Iteration:   1%|          | 5/469 [02:55<4:31:33, 35.11s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 6/469 [03:31<4:33:00, 35.38s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 7/469 [04:07<4:33:00, 35.45s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 8/469 [04:42<4:32:07, 35.42s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 9/469 [05:17<4:31:01, 35.35s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 10/469 [05:51<4:26:35, 34.85s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 11/469 [06:27<4:28:23, 35.16s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 12/469 [07:00<4:24:16, 34.70s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 13/469 [07:36<4:25:40, 34.96s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 14/469 [08:10<4:22:43, 34.65s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 15/469 [08:43<4:19:09, 34.25s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 16/469 [09:18<4:20:49, 34.55s/it]\u001b[A\n",
      "Iteration:   4%|▎         | 17/469 [09:52<4:18:20, 34.29s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 18/469 [10:26<4:17:09, 34.21s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 19/469 [11:00<4:15:17, 34.04s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 20/469 [11:34<4:14:29, 34.01s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 21/469 [12:07<4:12:10, 33.77s/it]\u001b[A\n",
      "Iteration:   5%|▍         | 22/469 [12:40<4:09:34, 33.50s/it]\u001b[A\n",
      "Iteration:   5%|▍         | 23/469 [13:14<4:10:05, 33.65s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 24/469 [13:47<4:09:02, 33.58s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 25/469 [14:21<4:09:13, 33.68s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 26/469 [14:54<4:07:30, 33.52s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 27/469 [15:28<4:07:28, 33.59s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 28/469 [16:02<4:07:53, 33.73s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 29/469 [16:36<4:07:17, 33.72s/it]\u001b[A\n",
      "Iteration:   6%|▋         | 30/469 [17:10<4:07:14, 33.79s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 31/469 [17:43<4:06:07, 33.71s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 32/469 [18:17<4:04:51, 33.62s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 33/469 [18:49<4:01:51, 33.28s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 34/469 [19:24<4:04:26, 33.72s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 35/469 [19:58<4:05:14, 33.90s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 36/469 [20:33<4:06:29, 34.16s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 37/469 [21:06<4:02:47, 33.72s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 38/469 [21:38<3:59:32, 33.35s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 39/469 [22:12<3:59:59, 33.49s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 40/469 [22:44<3:57:08, 33.17s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 41/469 [23:18<3:57:10, 33.25s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 42/469 [23:51<3:56:59, 33.30s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 43/469 [24:25<3:58:07, 33.54s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 44/469 [24:58<3:54:42, 33.13s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 45/469 [25:33<3:59:22, 33.87s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 46/469 [26:07<3:58:15, 33.79s/it]\u001b[A\n",
      "Iteration:  10%|█         | 47/469 [26:40<3:56:22, 33.61s/it]\u001b[A\n",
      "Iteration:  10%|█         | 48/469 [27:14<3:56:09, 33.66s/it]\u001b[A\n",
      "Iteration:  10%|█         | 49/469 [27:48<3:56:17, 33.76s/it]\u001b[A\n",
      "Iteration:  11%|█         | 50/469 [28:21<3:55:08, 33.67s/it]\u001b[A\n",
      "Iteration:  11%|█         | 51/469 [28:53<3:51:07, 33.18s/it]\u001b[A\n",
      "Iteration:  11%|█         | 52/469 [29:26<3:50:03, 33.10s/it]\u001b[A\n",
      "Iteration:  11%|█▏        | 53/469 [30:01<3:53:30, 33.68s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 54/469 [30:34<3:51:06, 33.41s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 55/469 [31:07<3:50:12, 33.36s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 56/469 [31:41<3:50:29, 33.48s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 57/469 [32:15<3:51:36, 33.73s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 58/469 [32:49<3:51:33, 33.80s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 59/469 [33:23<3:51:09, 33.83s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 60/469 [33:58<3:52:03, 34.04s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 61/469 [34:33<3:54:08, 34.43s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 62/469 [35:07<3:52:42, 34.31s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 63/469 [35:41<3:51:38, 34.23s/it]\u001b[A\n",
      "Iteration:  14%|█▎        | 64/469 [36:15<3:50:51, 34.20s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 65/469 [36:49<3:49:30, 34.09s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 66/469 [37:24<3:50:39, 34.34s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 67/469 [37:59<3:50:28, 34.40s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 68/469 [38:33<3:49:34, 34.35s/it]\u001b[A\n",
      "Iteration:  15%|█▍        | 69/469 [39:07<3:48:53, 34.33s/it]\u001b[A\n",
      "Iteration:  15%|█▍        | 70/469 [39:41<3:48:08, 34.31s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 71/469 [40:17<3:50:39, 34.77s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 72/469 [40:52<3:49:53, 34.74s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 73/469 [41:26<3:48:16, 34.59s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 74/469 [42:02<3:50:33, 35.02s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 75/469 [42:36<3:48:22, 34.78s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 76/469 [43:11<3:47:39, 34.76s/it]\u001b[A\n",
      "Iteration:  16%|█▋        | 77/469 [43:46<3:47:58, 34.89s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 78/469 [44:22<3:49:20, 35.19s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 79/469 [44:56<3:45:41, 34.72s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 80/469 [45:31<3:46:30, 34.94s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 81/469 [46:06<3:46:30, 35.03s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 82/469 [46:40<3:43:45, 34.69s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 83/469 [47:16<3:45:13, 35.01s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 84/469 [47:50<3:43:04, 34.77s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 85/469 [48:26<3:44:49, 35.13s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 86/469 [49:01<3:42:46, 34.90s/it]\u001b[A\n",
      "Iteration:  19%|█▊        | 87/469 [49:34<3:39:44, 34.51s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 88/469 [50:08<3:38:32, 34.42s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 89/469 [50:42<3:36:25, 34.17s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 90/469 [51:16<3:35:42, 34.15s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 91/469 [51:50<3:33:57, 33.96s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 92/469 [52:25<3:35:41, 34.33s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 93/469 [52:59<3:34:31, 34.23s/it]\u001b[A\n",
      "Iteration:  20%|██        | 94/469 [53:33<3:33:26, 34.15s/it]\u001b[A\n",
      "Iteration:  20%|██        | 95/469 [54:07<3:33:16, 34.22s/it]\u001b[A\n",
      "Iteration:  20%|██        | 96/469 [54:41<3:32:26, 34.17s/it]\u001b[A\n",
      "Iteration:  21%|██        | 97/469 [55:15<3:31:33, 34.12s/it]\u001b[A\n",
      "Iteration:  21%|██        | 98/469 [55:49<3:30:39, 34.07s/it]\u001b[A\n",
      "Iteration:  21%|██        | 99/469 [56:24<3:31:59, 34.38s/it]\u001b[A\n",
      "Iteration:  21%|██▏       | 100/469 [56:58<3:29:51, 34.12s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 101/469 [57:33<3:30:52, 34.38s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 102/469 [58:07<3:29:24, 34.23s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 103/469 [58:41<3:28:59, 34.26s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 104/469 [59:15<3:27:22, 34.09s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 105/469 [59:48<3:25:39, 33.90s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 106/469 [1:00:22<3:25:51, 34.03s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 107/469 [1:00:56<3:24:41, 33.93s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 108/469 [1:01:30<3:23:56, 33.90s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 109/469 [1:02:05<3:25:35, 34.26s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 110/469 [1:02:39<3:24:49, 34.23s/it]\u001b[A\n",
      "Iteration:  24%|██▎       | 111/469 [1:03:14<3:25:10, 34.39s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 112/469 [1:03:48<3:23:56, 34.27s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 113/469 [1:04:23<3:24:53, 34.53s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 114/469 [1:04:57<3:23:34, 34.41s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 115/469 [1:05:32<3:23:45, 34.53s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 116/469 [1:06:07<3:24:11, 34.71s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 117/469 [1:06:42<3:24:25, 34.85s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 118/469 [1:07:17<3:23:50, 34.85s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 119/469 [1:07:51<3:21:29, 34.54s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 120/469 [1:08:26<3:21:38, 34.67s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  26%|██▌       | 121/469 [1:09:00<3:19:52, 34.46s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 122/469 [1:09:34<3:18:52, 34.39s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 123/469 [1:10:08<3:17:45, 34.29s/it]\u001b[A\n",
      "Iteration:  26%|██▋       | 124/469 [1:10:42<3:16:25, 34.16s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 125/469 [1:11:16<3:15:28, 34.10s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 126/469 [1:11:51<3:15:53, 34.27s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 127/469 [1:12:26<3:17:04, 34.58s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 128/469 [1:13:01<3:17:41, 34.79s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 129/469 [1:13:36<3:16:20, 34.65s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 130/469 [1:14:11<3:16:53, 34.85s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 131/469 [1:14:46<3:16:17, 34.85s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 132/469 [1:15:21<3:16:18, 34.95s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 133/469 [1:15:55<3:14:09, 34.67s/it]\u001b[A\n",
      "Iteration:  29%|██▊       | 134/469 [1:16:29<3:12:52, 34.55s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 135/469 [1:17:05<3:13:30, 34.76s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 136/469 [1:17:38<3:11:18, 34.47s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 137/469 [1:18:12<3:08:56, 34.15s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 138/469 [1:18:47<3:09:45, 34.40s/it]\u001b[A\n",
      "Iteration:  30%|██▉       | 139/469 [1:19:20<3:07:56, 34.17s/it]\u001b[A\n",
      "Iteration:  30%|██▉       | 140/469 [1:19:55<3:07:39, 34.22s/it]\u001b[A\n",
      "Iteration:  30%|███       | 141/469 [1:20:29<3:07:04, 34.22s/it]\u001b[A\n",
      "Iteration:  30%|███       | 142/469 [1:21:05<3:09:25, 34.76s/it]\u001b[A\n",
      "Iteration:  30%|███       | 143/469 [1:21:39<3:08:27, 34.69s/it]\u001b[A\n",
      "Iteration:  31%|███       | 144/469 [1:22:14<3:08:20, 34.77s/it]\u001b[A\n",
      "Iteration:  31%|███       | 145/469 [1:22:49<3:07:34, 34.74s/it]\u001b[A\n",
      "Iteration:  31%|███       | 146/469 [1:23:24<3:07:35, 34.85s/it]\u001b[A\n",
      "Iteration:  31%|███▏      | 147/469 [1:23:58<3:06:03, 34.67s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 148/469 [1:24:34<3:06:53, 34.93s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 149/469 [1:25:10<3:08:35, 35.36s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 150/469 [1:25:47<3:10:07, 35.76s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 151/469 [1:26:22<3:08:24, 35.55s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 152/469 [1:26:56<3:04:52, 34.99s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 153/469 [1:27:30<3:03:20, 34.81s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 154/469 [1:28:04<3:00:30, 34.38s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 155/469 [1:28:37<2:58:29, 34.11s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 156/469 [1:29:12<2:59:00, 34.31s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 157/469 [1:29:46<2:58:29, 34.32s/it]\u001b[A\n",
      "Iteration:  34%|███▎      | 158/469 [1:30:20<2:56:55, 34.13s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 159/469 [1:30:54<2:56:12, 34.10s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 160/469 [1:31:28<2:55:42, 34.12s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 161/469 [1:32:04<2:57:28, 34.57s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 162/469 [1:32:37<2:55:00, 34.20s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 163/469 [1:33:13<2:57:03, 34.72s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 164/469 [1:33:46<2:54:19, 34.29s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 165/469 [1:34:21<2:53:52, 34.32s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 166/469 [1:34:54<2:52:10, 34.09s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 167/469 [1:35:29<2:52:17, 34.23s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 168/469 [1:36:03<2:51:33, 34.20s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 169/469 [1:36:37<2:50:42, 34.14s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 170/469 [1:37:12<2:50:58, 34.31s/it]\u001b[A\n",
      "Iteration:  36%|███▋      | 171/469 [1:37:45<2:49:44, 34.18s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 172/469 [1:38:20<2:49:34, 34.26s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 173/469 [1:38:54<2:49:10, 34.29s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 174/469 [1:39:30<2:50:31, 34.68s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 175/469 [1:40:04<2:49:49, 34.66s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 176/469 [1:40:38<2:47:57, 34.40s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 177/469 [1:41:13<2:47:43, 34.47s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 178/469 [1:41:48<2:48:11, 34.68s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 179/469 [1:42:23<2:48:06, 34.78s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 180/469 [1:42:57<2:46:16, 34.52s/it]\u001b[A\n",
      "Iteration:  39%|███▊      | 181/469 [1:43:32<2:46:28, 34.68s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 182/469 [1:44:06<2:45:29, 34.60s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 183/469 [1:44:40<2:43:29, 34.30s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 184/469 [1:45:14<2:42:06, 34.13s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 185/469 [1:45:49<2:42:55, 34.42s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 186/469 [1:46:24<2:43:26, 34.65s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 187/469 [1:46:58<2:41:54, 34.45s/it]\u001b[A\n",
      "Iteration:  40%|████      | 188/469 [1:47:34<2:43:31, 34.92s/it]\u001b[A\n",
      "Iteration:  40%|████      | 189/469 [1:48:08<2:41:59, 34.71s/it]\u001b[A\n",
      "Iteration:  41%|████      | 190/469 [1:48:43<2:41:36, 34.75s/it]\u001b[A\n",
      "Iteration:  41%|████      | 191/469 [1:49:17<2:40:15, 34.59s/it]\u001b[A\n",
      "Iteration:  41%|████      | 192/469 [1:49:52<2:40:05, 34.68s/it]\u001b[A\n",
      "Iteration:  41%|████      | 193/469 [1:50:26<2:38:43, 34.50s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 194/469 [1:51:00<2:37:28, 34.36s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 195/469 [1:51:35<2:37:41, 34.53s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 196/469 [1:52:10<2:37:47, 34.68s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 197/469 [1:52:45<2:37:01, 34.64s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 198/469 [1:53:19<2:36:23, 34.63s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 199/469 [1:53:55<2:37:07, 34.92s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 200/469 [1:54:31<2:37:27, 35.12s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 201/469 [1:55:05<2:35:33, 34.83s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 202/469 [1:55:40<2:35:02, 34.84s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 203/469 [1:56:14<2:34:06, 34.76s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 204/469 [1:56:48<2:32:35, 34.55s/it]\u001b[A\n",
      "Iteration:  44%|████▎     | 205/469 [1:57:23<2:32:27, 34.65s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 206/469 [1:57:57<2:31:08, 34.48s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 207/469 [1:58:33<2:32:27, 34.91s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 208/469 [1:59:07<2:30:35, 34.62s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 209/469 [1:59:42<2:29:51, 34.58s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 210/469 [2:00:15<2:28:18, 34.36s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 211/469 [2:00:48<2:25:48, 33.91s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 212/469 [2:01:21<2:24:11, 33.66s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 213/469 [2:01:56<2:24:37, 33.89s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 214/469 [2:02:30<2:24:27, 33.99s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 215/469 [2:03:04<2:24:09, 34.05s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 216/469 [2:03:38<2:23:34, 34.05s/it]\u001b[A\n",
      "Iteration:  46%|████▋     | 217/469 [2:04:14<2:25:30, 34.64s/it]\u001b[A\n",
      "Iteration:  46%|████▋     | 218/469 [2:04:48<2:24:14, 34.48s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 219/469 [2:05:24<2:25:11, 34.84s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 220/469 [2:06:00<2:25:56, 35.17s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 221/469 [2:06:35<2:25:05, 35.10s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 222/469 [2:07:11<2:25:44, 35.40s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 223/469 [2:07:45<2:23:42, 35.05s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 224/469 [2:08:21<2:23:19, 35.10s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 225/469 [2:08:54<2:21:07, 34.70s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 226/469 [2:09:29<2:20:18, 34.64s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 227/469 [2:10:04<2:20:41, 34.88s/it]\u001b[A\n",
      "Iteration:  49%|████▊     | 228/469 [2:10:38<2:19:08, 34.64s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 229/469 [2:11:13<2:18:07, 34.53s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 230/469 [2:11:46<2:16:28, 34.26s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 231/469 [2:12:24<2:19:30, 35.17s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 232/469 [2:12:58<2:18:27, 35.05s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 233/469 [2:13:33<2:17:52, 35.05s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 234/469 [2:14:09<2:17:49, 35.19s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 235/469 [2:14:43<2:16:26, 34.98s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 236/469 [2:15:18<2:15:58, 35.02s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 237/469 [2:15:52<2:14:05, 34.68s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 238/469 [2:16:28<2:14:45, 35.00s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 239/469 [2:17:03<2:14:30, 35.09s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 240/469 [2:17:38<2:13:46, 35.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  51%|█████▏    | 241/469 [2:18:14<2:14:14, 35.33s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 242/469 [2:18:49<2:13:17, 35.23s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 243/469 [2:19:25<2:13:14, 35.37s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 244/469 [2:20:00<2:12:29, 35.33s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 245/469 [2:20:35<2:11:28, 35.22s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 246/469 [2:21:10<2:10:27, 35.10s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 247/469 [2:21:45<2:09:58, 35.13s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 248/469 [2:22:21<2:10:24, 35.40s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 249/469 [2:22:56<2:08:46, 35.12s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 250/469 [2:23:30<2:07:26, 34.92s/it]\u001b[A\n",
      "Iteration:  54%|█████▎    | 251/469 [2:24:05<2:06:55, 34.93s/it]\u001b[A\n",
      "Iteration:  54%|█████▎    | 252/469 [2:24:40<2:06:14, 34.90s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 253/469 [2:25:15<2:05:29, 34.86s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 254/469 [2:25:51<2:06:28, 35.30s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 255/469 [2:26:26<2:05:32, 35.20s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 256/469 [2:27:00<2:04:06, 34.96s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 257/469 [2:27:36<2:04:18, 35.18s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 258/469 [2:28:12<2:04:19, 35.35s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 259/469 [2:28:46<2:02:43, 35.06s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 260/469 [2:29:21<2:02:02, 35.03s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 261/469 [2:29:56<2:01:05, 34.93s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 262/469 [2:30:31<2:00:56, 35.05s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 263/469 [2:31:06<1:59:34, 34.83s/it]\u001b[A\n",
      "Iteration:  56%|█████▋    | 264/469 [2:31:39<1:57:53, 34.51s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 265/469 [2:32:14<1:57:43, 34.62s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 266/469 [2:32:49<1:57:33, 34.75s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 267/469 [2:33:23<1:55:59, 34.45s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 268/469 [2:33:57<1:55:05, 34.35s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 269/469 [2:34:34<1:56:44, 35.02s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 270/469 [2:35:09<1:56:29, 35.12s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 271/469 [2:35:44<1:55:36, 35.04s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 272/469 [2:36:20<1:55:50, 35.28s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 273/469 [2:36:55<1:55:13, 35.27s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 274/469 [2:37:30<1:54:24, 35.20s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 275/469 [2:38:05<1:53:39, 35.15s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 276/469 [2:38:41<1:53:30, 35.29s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 277/469 [2:39:15<1:52:11, 35.06s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 278/469 [2:39:50<1:51:26, 35.01s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 279/469 [2:40:25<1:50:59, 35.05s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 280/469 [2:41:01<1:51:25, 35.38s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 281/469 [2:41:36<1:50:20, 35.22s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 282/469 [2:42:12<1:50:24, 35.43s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 283/469 [2:42:48<1:50:27, 35.63s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 284/469 [2:43:23<1:49:03, 35.37s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 285/469 [2:43:57<1:47:32, 35.07s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 286/469 [2:44:33<1:47:43, 35.32s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 287/469 [2:45:09<1:47:43, 35.51s/it]\u001b[A\n",
      "Iteration:  61%|██████▏   | 288/469 [2:45:44<1:46:17, 35.23s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 289/469 [2:46:20<1:46:30, 35.50s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 290/469 [2:46:55<1:45:25, 35.34s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 291/469 [2:47:30<1:44:43, 35.30s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 292/469 [2:48:05<1:43:50, 35.20s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 293/469 [2:48:40<1:43:19, 35.22s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 294/469 [2:49:16<1:43:16, 35.41s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 295/469 [2:49:51<1:41:47, 35.10s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 296/469 [2:50:25<1:40:49, 34.97s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 297/469 [2:51:01<1:40:35, 35.09s/it]\u001b[A\n",
      "Iteration:  64%|██████▎   | 298/469 [2:51:34<1:38:44, 34.65s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 299/469 [2:52:09<1:38:19, 34.70s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 300/469 [2:52:43<1:37:05, 34.47s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 301/469 [2:53:18<1:36:54, 34.61s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 302/469 [2:53:52<1:35:53, 34.45s/it]\u001b[A\n",
      "Iteration:  65%|██████▍   | 303/469 [2:54:26<1:34:48, 34.27s/it]\u001b[A\n",
      "Iteration:  65%|██████▍   | 304/469 [2:55:00<1:34:20, 34.31s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 305/469 [2:55:34<1:33:28, 34.20s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 306/469 [2:56:09<1:33:13, 34.31s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 307/469 [2:56:43<1:32:21, 34.21s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 308/469 [2:57:18<1:32:31, 34.48s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 309/469 [2:57:52<1:31:46, 34.42s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 310/469 [2:58:26<1:30:45, 34.25s/it]\u001b[A\n",
      "Iteration:  66%|██████▋   | 311/469 [2:59:00<1:29:49, 34.11s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 312/469 [2:59:35<1:30:22, 34.54s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 313/469 [3:00:10<1:29:56, 34.60s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 314/469 [3:00:44<1:29:01, 34.46s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 315/469 [3:01:20<1:29:29, 34.87s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 316/469 [3:01:54<1:28:25, 34.68s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 317/469 [3:02:29<1:27:44, 34.64s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 318/469 [3:03:04<1:27:39, 34.83s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 319/469 [3:03:39<1:27:22, 34.95s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 320/469 [3:04:14<1:26:42, 34.92s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 321/469 [3:04:48<1:25:32, 34.68s/it]\u001b[A\n",
      "Iteration:  69%|██████▊   | 322/469 [3:05:24<1:25:58, 35.09s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 323/469 [3:05:58<1:24:32, 34.75s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 324/469 [3:06:33<1:24:00, 34.76s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 325/469 [3:07:08<1:23:34, 34.82s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 326/469 [3:07:43<1:23:08, 34.89s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 327/469 [3:08:18<1:22:35, 34.90s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 328/469 [3:08:52<1:21:16, 34.58s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 329/469 [3:09:26<1:20:36, 34.54s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 330/469 [3:10:01<1:20:20, 34.68s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 331/469 [3:10:36<1:19:49, 34.71s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 332/469 [3:11:10<1:18:58, 34.59s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 333/469 [3:11:45<1:18:28, 34.62s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 334/469 [3:12:20<1:18:03, 34.69s/it]\u001b[A\n",
      "Iteration:  71%|███████▏  | 335/469 [3:12:53<1:16:36, 34.30s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 336/469 [3:13:28<1:16:31, 34.52s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 337/469 [3:14:03<1:16:10, 34.62s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 338/469 [3:14:37<1:15:02, 34.37s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 339/469 [3:15:12<1:15:09, 34.69s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 340/469 [3:15:48<1:15:12, 34.98s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 341/469 [3:16:23<1:14:52, 35.10s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 342/469 [3:16:57<1:13:32, 34.74s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 343/469 [3:17:33<1:13:41, 35.09s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 344/469 [3:18:09<1:13:29, 35.28s/it]\u001b[A\n",
      "Iteration:  74%|███████▎  | 345/469 [3:18:44<1:12:46, 35.21s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 346/469 [3:19:18<1:11:36, 34.93s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 347/469 [3:19:54<1:11:30, 35.17s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 348/469 [3:20:30<1:11:19, 35.37s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 349/469 [3:21:04<1:10:13, 35.12s/it]\u001b[A\n",
      "Iteration:  75%|███████▍  | 350/469 [3:21:40<1:09:54, 35.24s/it]\u001b[A\n",
      "Iteration:  75%|███████▍  | 351/469 [3:22:15<1:09:27, 35.32s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 352/469 [3:22:50<1:08:26, 35.10s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 353/469 [3:23:25<1:07:48, 35.08s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 354/469 [3:24:00<1:07:11, 35.05s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 355/469 [3:24:35<1:06:35, 35.05s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 356/469 [3:25:11<1:06:25, 35.27s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 357/469 [3:25:48<1:07:04, 35.93s/it]\u001b[A\n",
      "Iteration:  76%|███████▋  | 358/469 [3:26:24<1:06:28, 35.93s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 359/469 [3:26:59<1:05:19, 35.63s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 360/469 [3:27:34<1:04:30, 35.51s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  77%|███████▋  | 361/469 [3:28:10<1:03:59, 35.55s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 362/469 [3:28:45<1:03:08, 35.41s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 363/469 [3:29:20<1:02:18, 35.27s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 364/469 [3:29:56<1:02:01, 35.44s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 365/469 [3:30:30<1:00:52, 35.12s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 366/469 [3:31:04<59:36, 34.73s/it]  \u001b[A\n",
      "Iteration:  78%|███████▊  | 367/469 [3:31:38<58:43, 34.55s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 368/469 [3:32:14<58:47, 34.92s/it]\u001b[A\n",
      "Iteration:  79%|███████▊  | 369/469 [3:32:48<57:35, 34.55s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 370/469 [3:33:22<57:03, 34.58s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 371/469 [3:33:57<56:36, 34.65s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 372/469 [3:34:31<55:37, 34.40s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 373/469 [3:35:05<54:55, 34.33s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 374/469 [3:35:39<54:16, 34.28s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 375/469 [3:36:14<54:01, 34.48s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 376/469 [3:36:48<53:07, 34.27s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 377/469 [3:37:24<53:11, 34.69s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 378/469 [3:37:58<52:16, 34.47s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 379/469 [3:38:32<51:45, 34.50s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 380/469 [3:39:07<51:12, 34.52s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 381/469 [3:39:42<50:56, 34.73s/it]\u001b[A\n",
      "Iteration:  81%|████████▏ | 382/469 [3:40:17<50:34, 34.87s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 383/469 [3:40:52<49:53, 34.81s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 384/469 [3:41:26<49:06, 34.66s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 385/469 [3:42:01<48:45, 34.82s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 386/469 [3:42:36<48:10, 34.83s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 387/469 [3:43:11<47:40, 34.89s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 388/469 [3:43:45<46:47, 34.65s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 389/469 [3:44:21<46:42, 35.04s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 390/469 [3:44:56<46:04, 35.00s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 391/469 [3:45:31<45:20, 34.88s/it]\u001b[A\n",
      "Iteration:  84%|████████▎ | 392/469 [3:46:06<44:45, 34.88s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 393/469 [3:46:40<44:02, 34.77s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 394/469 [3:47:15<43:28, 34.78s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 395/469 [3:47:50<42:52, 34.76s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 396/469 [3:48:25<42:27, 34.89s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 397/469 [3:48:59<41:27, 34.55s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 398/469 [3:49:33<40:42, 34.40s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 399/469 [3:50:07<40:10, 34.43s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 400/469 [3:50:41<39:27, 34.31s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 401/469 [3:51:15<38:46, 34.22s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 402/469 [3:51:50<38:12, 34.22s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 403/469 [3:52:24<37:51, 34.42s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 404/469 [3:52:58<37:07, 34.27s/it]\u001b[A\n",
      "Iteration:  86%|████████▋ | 405/469 [3:53:32<36:22, 34.10s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 406/469 [3:54:08<36:16, 34.55s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 407/469 [3:54:42<35:37, 34.48s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 408/469 [3:55:17<35:16, 34.70s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 409/469 [3:55:50<34:16, 34.27s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 410/469 [3:56:26<34:00, 34.58s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 411/469 [3:56:59<33:10, 34.32s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 412/469 [3:57:34<32:48, 34.53s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 413/469 [3:58:09<32:13, 34.53s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 414/469 [3:58:44<31:53, 34.80s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 415/469 [3:59:19<31:16, 34.75s/it]\u001b[A\n",
      "Iteration:  89%|████████▊ | 416/469 [3:59:54<30:42, 34.77s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 417/469 [4:00:29<30:12, 34.86s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 418/469 [4:01:04<29:44, 34.98s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 419/469 [4:01:38<28:52, 34.64s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 420/469 [4:02:13<28:25, 34.81s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 421/469 [4:02:48<27:54, 34.89s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 422/469 [4:03:23<27:19, 34.89s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 423/469 [4:03:58<26:43, 34.87s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 424/469 [4:04:35<26:35, 35.46s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 425/469 [4:05:09<25:46, 35.14s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 426/469 [4:05:44<25:06, 35.03s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 427/469 [4:06:20<24:40, 35.25s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 428/469 [4:06:55<24:00, 35.14s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 429/469 [4:07:30<23:25, 35.15s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 430/469 [4:08:05<22:47, 35.08s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 431/469 [4:08:40<22:14, 35.13s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 432/469 [4:09:15<21:36, 35.05s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 433/469 [4:09:49<20:54, 34.83s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 434/469 [4:10:24<20:17, 34.80s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 435/469 [4:10:59<19:49, 34.99s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 436/469 [4:11:34<19:13, 34.95s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 437/469 [4:12:11<18:52, 35.38s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 438/469 [4:12:46<18:13, 35.27s/it]\u001b[A\n",
      "Iteration:  94%|█████████▎| 439/469 [4:13:20<17:30, 35.02s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 440/469 [4:13:54<16:48, 34.76s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 441/469 [4:14:29<16:14, 34.80s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 442/469 [4:15:04<15:40, 34.84s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 443/469 [4:15:39<15:05, 34.82s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 444/469 [4:16:14<14:35, 35.03s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 445/469 [4:16:49<13:58, 34.94s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 446/469 [4:17:25<13:30, 35.26s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 447/469 [4:17:59<12:49, 34.96s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 448/469 [4:18:33<12:08, 34.68s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 449/469 [4:19:08<11:35, 34.78s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 450/469 [4:19:42<10:56, 34.57s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 451/469 [4:20:17<10:21, 34.53s/it]\u001b[A\n",
      "Iteration:  96%|█████████▋| 452/469 [4:20:51<09:45, 34.42s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 453/469 [4:21:27<09:16, 34.80s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 454/469 [4:22:00<08:36, 34.42s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 455/469 [4:22:35<08:03, 34.53s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 456/469 [4:23:10<07:30, 34.66s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 457/469 [4:23:43<06:49, 34.13s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 458/469 [4:24:17<06:15, 34.17s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 459/469 [4:24:51<05:39, 33.98s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 460/469 [4:25:24<05:04, 33.86s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 461/469 [4:25:59<04:32, 34.02s/it]\u001b[A\n",
      "Iteration:  99%|█████████▊| 462/469 [4:26:32<03:56, 33.74s/it]\u001b[A\n",
      "Iteration:  99%|█████████▊| 463/469 [4:27:06<03:23, 33.90s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 464/469 [4:27:41<02:50, 34.15s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 465/469 [4:28:16<02:17, 34.41s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 466/469 [4:28:49<01:42, 34.16s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 467/469 [4:29:24<01:08, 34.30s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 468/469 [4:29:58<00:34, 34.32s/it]\u001b[A\n",
      "Epoch: 100%|██████████| 3/3 [13:27:29<00:00, 16095.34s/it] it]\u001b[A\n",
      "02/13/2019 14:46:23 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz from cache at /home/user/.pytorch_pretrained_bert/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9\n",
      "02/13/2019 14:46:23 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/user/.pytorch_pretrained_bert/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9 to temp dir /tmp/tmph0jt7mnt\n",
      "02/13/2019 14:46:32 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2019 14:48:06 - INFO - __main__ -   ***** Running evaluation *****\n",
      "02/13/2019 14:48:06 - INFO - __main__ -     Num examples = 8836\n",
      "02/13/2019 14:48:06 - INFO - __main__ -     Batch size = 8\n",
      "Evaluating: 100%|██████████| 1105/1105 [1:14:02<00:00,  3.50s/it]\n",
      "02/13/2019 16:02:09 - INFO - __main__ -   ***** Eval results *****\n",
      "02/13/2019 16:02:09 - INFO - __main__ -     eval_accuracy = 0.9823987112697189\n",
      "02/13/2019 16:02:09 - INFO - __main__ -     eval_loss = 0.049779869736555744\n",
      "02/13/2019 16:02:09 - INFO - __main__ -     global_step = 1407\n",
      "02/13/2019 16:02:09 - INFO - __main__ -     loss = 0.04205471432920712\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, warmup_linear\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            label: (Optional) [string]. The labels of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "\n",
    "class DataProcessor(object):\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\", encoding='utf-8') as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                lines.append(line)\n",
    "            return lines\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train.tsv\")))\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        labels_list = []\n",
    "        cNames = [''] * len(categories)\n",
    "        for k,v in categories.items():\n",
    "            labels_list.append(k)\n",
    "        return labels_list\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[1]\n",
    "            text_b = None\n",
    "            label = line[0]\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "    label_map = {label : i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "        # Account for [CLS] and [SEP] with \"- 2\"\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids: 0   0   0   0  0     0 0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "        segment_ids = [0] * len(tokens)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = [0] * len(categories)\n",
    "        exLabels = example.label.split(\",\")\n",
    "        for i in range(len(exLabels)):\n",
    "            label_id[label_map[exLabels[i]]] = 1\n",
    "            \n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id))\n",
    "    return features\n",
    "\n",
    "def accuracy(y_pred, y_true, thresh:float=0.5):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    y_pred = y_pred.sigmoid()\n",
    "    return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
    "\n",
    "max_bert_seq_length = 512\n",
    "class Args(object):\n",
    "    def __init__(self, bert_model):\n",
    "        self.bert_model = bert_model\n",
    "    \n",
    "\n",
    "args = Args(\"bert-base-multilingual-cased\")\n",
    "args.data_dir = bertDataPath\n",
    "args.bert_model = \"bert-base-multilingual-cased\"\n",
    "args.output_dir = outDataPath\n",
    "args.max_seq_length = min(max_bert_seq_length, maxSeqLength)\n",
    "args.do_train = True\n",
    "args.do_eval = True\n",
    "args.do_lower_case = False\n",
    "args.train_batch_size = 32\n",
    "args.eval_batch_size = 8\n",
    "args.learning_rate = 5e-5\n",
    "args.num_train_epochs = 3\n",
    "args.warmup_proportion = 0.1\n",
    "args.no_cuda = True\n",
    "args.local_rank = -1\n",
    "args.seed = 42\n",
    "args.gradient_accumulation_steps = 1\n",
    "\n",
    "device = 'cpu'\n",
    "n_gpu = torch.cuda.device_count()\n",
    "args.train_batch_size = args.train_batch_size // args.gradient_accumulation_steps\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if not args.do_train and not args.do_eval:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train:\n",
    "    raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "processor = DataProcessor()\n",
    "num_labels = len(categories)\n",
    "label_list = processor.get_labels()\n",
    "tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=args.do_lower_case)\n",
    "train_examples = None\n",
    "num_train_optimization_steps = None    \n",
    "if args.do_train:\n",
    "    train_examples = processor.get_train_examples(args.data_dir)\n",
    "    num_train_optimization_steps = int(\n",
    "        len(train_examples) / args.train_batch_size / args.gradient_accumulation_steps) * args.num_train_epochs\n",
    "model = BertForMultiLabelSequenceClassification.from_pretrained(args.bert_model,\n",
    "    cache_dir=PYTORCH_PRETRAINED_BERT_CACHE / 'distributed_{}'.format(args.local_rank),\n",
    "    num_labels = num_labels)\n",
    "model.to(device)\n",
    "\n",
    "#namedParams = [p for p in model.named_parameters()]\n",
    "#print (\"!!! model.named_parameters():\")\n",
    "#print (namedParams)\n",
    "#param_optimizer = list(model.named_parameters())\n",
    "param_optimizer = [p for p in model.named_parameters()]\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "    lr=args.learning_rate,\n",
    "    warmup=args.warmup_proportion,\n",
    "    t_total=num_train_optimization_steps)\n",
    "\n",
    "global_step = 0\n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0\n",
    "\n",
    "if args.do_train:\n",
    "    train_features = convert_examples_to_features(\n",
    "        train_examples, label_list, args.max_seq_length, tokenizer)\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "    logger.info(\"  Batch size = %d\", args.train_batch_size)\n",
    "    logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.float)\n",
    "    train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "    model.train()\n",
    "    for _ in trange(int(args.num_train_epochs), desc=\"Epoch\"):\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids = batch\n",
    "            loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            if n_gpu > 1:\n",
    "                loss = loss.mean() # mean() to average on multi-gpu.\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "# Save a trained model\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "output_model_file = os.path.join(args.output_dir, \"pytorch_model.bin\")\n",
    "if args.do_train:\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)\n",
    "\n",
    "# Load a trained model that you have fine-tuned\n",
    "model_state_dict = torch.load(output_model_file)\n",
    "model = BertForMultiLabelSequenceClassification.from_pretrained(args.bert_model, state_dict=model_state_dict, num_labels=num_labels)\n",
    "model.to(device)\n",
    "\n",
    "if args.do_eval and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
    "    eval_examples = processor.get_dev_examples(args.data_dir)\n",
    "    eval_features = convert_examples_to_features(\n",
    "        eval_examples, label_list, args.max_seq_length, tokenizer)\n",
    "    logger.info(\"***** Running evaluation *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.float)\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    \n",
    "    # Run prediction for full data\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    allLabs = None\n",
    "    res = None\n",
    "    initRes = True\n",
    "    for input_ids, input_mask, segment_ids, label_ids in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            logits = model(input_ids, segment_ids, input_mask)\n",
    "        preds = logits.sigmoid().to('cpu').numpy()\n",
    "        labs = label_ids.to('cpu').numpy()\n",
    "        if initRes == True:\n",
    "            res = preds\n",
    "            allLabs = labs\n",
    "            initRes = False\n",
    "        else:\n",
    "            res = numpy.concatenate((res, preds))\n",
    "            allLabs = numpy.concatenate((allLabs, labs))\n",
    "\n",
    "        tmp_eval_accuracy = accuracy(logits, label_ids)\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_examples += input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
    "    loss = tr_loss/nb_tr_steps if args.do_train else None\n",
    "    result = {'eval_loss': eval_loss,\n",
    "        'eval_accuracy': eval_accuracy,\n",
    "        'global_step': global_step,\n",
    "        'loss': loss}\n",
    "    \n",
    "    output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "    writer.close()\n",
    "\n",
    "    output_pred_file = os.path.join(args.output_dir, \"predictions.txt\")\n",
    "    with open(output_pred_file, \"w\") as writer:\n",
    "        for i in range(len(res)):\n",
    "            line = \"\"\n",
    "            for j in range(len(allLabs[i])):\n",
    "                if allLabs[i][j] == 1:\n",
    "                    if line != '':\n",
    "                        line = line + \",\"\n",
    "                    line = line + str(j)\n",
    "            for j in range(len(res[i])):\n",
    "                line = line + \"\\t\"\n",
    "                line = line + str(res[i][j])\n",
    "            line = line + \"\\n\"\n",
    "            writer.write(line)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate metrics.\n",
      "Len of test_labels: 8836, results: 8836\n",
      "Labels actual: 11060, predicted: 10298, correctly: 7931, incorrectly: 2367, not predicted: 3129\n",
      "Exact Match Ratio:  60.02%\n",
      "Accuracy:  71.01%\n",
      "Precision:  75.99%\n",
      "Recall:  77.12%\n",
      "F1-Measure:  76.55%\n",
      "Hamming Loss:  1.56%\n",
      "Macro-Averaged Precision:  59.36%\n",
      "Macro-Averaged Recall:  69.42%\n",
      "Macro-Averaged F1-Measure:  62.08%\n",
      "Micro-Averaged Precision:  71.71%\n",
      "Micro-Averaged Recall:  77.01%\n",
      "Micro-Averaged F1-Measure:  74.27%\n",
      "One Error: 20.11%\n",
      "Coverage: 1.03\n",
      "Ranking Loss: 0.81\n"
     ]
    }
   ],
   "source": [
    "print (\"Calculate metrics.\")\n",
    "rankThreshold = 0.3\n",
    "test_labels = allLabs\n",
    "\n",
    "print(\"Len of test_labels: %d, results: %d\"%(len(test_labels), len(res)))\n",
    "\n",
    "def rankIndicator(labels, predictions, index):\n",
    "    global rankThreshold\n",
    "    #print(len(labels), len(predictions), index)\n",
    "    return (labels[index] == 1), (predictions[index] >= rankThreshold)\n",
    "    \n",
    "def getPrediction(entry):\n",
    "    return entry[1]\n",
    "\n",
    "# General results   \n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "qTags = 0\n",
    "qPreds = 0\n",
    "for i in range(len(test_labels)):\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if predicted:\n",
    "            qPreds += 1\n",
    "            if actual:\n",
    "                qTags += 1\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if actual:\n",
    "                qTags += 1\n",
    "                fn += 1\n",
    "print (\"Labels actual: %d, predicted: %d, correctly: %d, incorrectly: %d, not predicted: %d\"%(qTags, qPreds, tp, fp, fn))\n",
    "\n",
    "#Exact Match Ratio\n",
    "wrongPreds = 0\n",
    "for i in range(len(test_labels)):\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if (actual and not predicted) or (predicted and not actual):\n",
    "            wrongPreds += 1\n",
    "            break;\n",
    "emr = (len(test_labels) - wrongPreds)/len(test_labels)           \n",
    "print (\"Exact Match Ratio:  %.2f%%\" % ((len(test_labels) - wrongPreds)/len(test_labels) * 100))\n",
    "\n",
    "#Accuracy\n",
    "accuracy = 0.\n",
    "for i in range(len(test_labels)):\n",
    "    labels = sum(test_labels[i])\n",
    "    tp = 0\n",
    "    tfp = 0\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if actual and predicted:\n",
    "            tp += 1\n",
    "        if predicted and not actual:\n",
    "            tfp += 1\n",
    "    accuracy += tp / (labels + tfp)\n",
    "modelAccuracy = accuracy / len(test_labels)\n",
    "print (\"Accuracy:  %.2f%%\" % (accuracy / len(test_labels) * 100))  \n",
    "\n",
    "#Precision\n",
    "precision = 0.\n",
    "for i in range(len(test_labels)):\n",
    "    labels = sum(test_labels[i])\n",
    "    tp = 0\n",
    "    tfp = 0\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if actual and predicted:\n",
    "            tp += 1\n",
    "    precision += tp / labels\n",
    "modelPrecision = precision / len(test_labels)\n",
    "print (\"Precision:  %.2f%%\" % (precision / len(test_labels) * 100))  \n",
    "\n",
    "#Recall\n",
    "recall = 0.\n",
    "for i in range(len(test_labels)):\n",
    "    labels = sum(test_labels[i])\n",
    "    tp = 0\n",
    "    tfp = 0\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if actual and predicted:\n",
    "            tp += 1\n",
    "        if predicted:\n",
    "            tfp += 1\n",
    "    if tfp > 0:\n",
    "        recall += tp / tfp\n",
    "modelRecall = recall / len(test_labels)      \n",
    "print (\"Recall:  %.2f%%\" % (recall / len(test_labels) * 100))  \n",
    "\n",
    "#F1-Measure\n",
    "modelF1 = 2 * (modelPrecision * modelRecall / (modelPrecision + modelRecall))\n",
    "print (\"F1-Measure:  %.2f%%\" % (2 * (modelPrecision * modelRecall / (modelPrecision + modelRecall)) * 100))\n",
    "\n",
    "#Hamming Loss\n",
    "hl = 0.\n",
    "for i in range(len(test_labels)):\n",
    "    labels = sum(test_labels[i])\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if (actual and not predicted) or (predicted and not actual):\n",
    "            hl += 1\n",
    "modelHl = hl / (len(test_labels) * len(categories))           \n",
    "print (\"Hamming Loss:  %.2f%%\" % (hl * 100 / (len(test_labels) * len(categories)))) \n",
    "\n",
    "#Macro-Averaged Precision\n",
    "precision = 0\n",
    "for i in range(len(categories)):\n",
    "    tp = 0\n",
    "    tact = 0\n",
    "    for j in range(len(test_labels)):\n",
    "        actual, predicted = rankIndicator(test_labels[j], res[j], i) \n",
    "        if not actual:\n",
    "            continue\n",
    "        tact += 1\n",
    "        if predicted:\n",
    "            tp += 1\n",
    "    precision += tp / tact\n",
    "modelMacroPrecision = precision / len(categories) \n",
    "print (\"Macro-Averaged Precision:  %.2f%%\" % (precision / len(categories) * 100))  \n",
    "\n",
    "#Macro-Averaged Recall\n",
    "recall = 0\n",
    "for i in range(len(categories)):\n",
    "    tp = 0\n",
    "    tact = 0\n",
    "    for j in range(len(test_labels)):\n",
    "        actual, predicted = rankIndicator(test_labels[j], res[j], i)\n",
    "        if predicted:\n",
    "            tact += 1\n",
    "            if actual:\n",
    "                tp += 1\n",
    "    if tact > 0:                \n",
    "        recall += tp / tact\n",
    "    #else:\n",
    "    #    print (\"Macro-Recall: category %d isn't predicted\"%(i))\n",
    "modelMacroRecall = recall / len(categories)\n",
    "print (\"Macro-Averaged Recall:  %.2f%%\" % (recall / len(categories) * 100))  \n",
    "\n",
    "#Macro-Averaged F1-Measure\n",
    "f1 = 0\n",
    "for i in range(len(categories)):\n",
    "    tp = 0\n",
    "    tact = 0\n",
    "    labs = 0\n",
    "    for j in range(len(test_labels)):\n",
    "        actual, predicted = rankIndicator(test_labels[j], res[j], i)\n",
    "        if actual:\n",
    "            labs += 1\n",
    "        if predicted:\n",
    "            tact += 1\n",
    "            if actual:\n",
    "                tp += 1\n",
    "    f1 += 2 * tp / (tact + labs)\n",
    "modelMacroF1 = f1 / len(categories)\n",
    "print (\"Macro-Averaged F1-Measure:  %.2f%%\" % (f1 / len(categories) * 100))  \n",
    "\n",
    "#Micro-Averaged Precision\n",
    "precision = 0\n",
    "tp = 0\n",
    "tact = 0\n",
    "for i in range(len(categories)):\n",
    "    for j in range(len(test_labels)):\n",
    "        actual, predicted = rankIndicator(test_labels[j], res[j], i) \n",
    "        if not actual:\n",
    "            continue\n",
    "        tact += 1\n",
    "        if predicted:\n",
    "            tp += 1\n",
    "precision += tp / tact\n",
    "modelMicroPrecision = precision\n",
    "print (\"Micro-Averaged Precision:  %.2f%%\" % (precision * 100))  \n",
    "\n",
    "#Micro-Averaged Recall\n",
    "recall = 0\n",
    "tp = 0\n",
    "tact = 0\n",
    "for i in range(len(categories)):\n",
    "    for j in range(len(test_labels)):\n",
    "        actual, predicted = rankIndicator(test_labels[j], res[j], i)\n",
    "        if predicted:\n",
    "            tact += 1\n",
    "            if actual:\n",
    "                tp += 1\n",
    "recall += tp / tact\n",
    "modelMicroRecall = recall\n",
    "print (\"Micro-Averaged Recall:  %.2f%%\" % (recall * 100))  \n",
    "\n",
    "#Micro-Averaged F1-Measure\n",
    "f1 = 0\n",
    "tp = 0\n",
    "tact = 0\n",
    "labs = 0\n",
    "for i in range(len(categories)):\n",
    "    for j in range(len(test_labels)):\n",
    "        actual, predicted = rankIndicator(test_labels[j], res[j], i)\n",
    "        if actual:\n",
    "            labs += 1\n",
    "        if predicted:\n",
    "            tact += 1\n",
    "            if actual:\n",
    "                tp += 1\n",
    "f1 += 2 * tp / (tact + labs)\n",
    "modelMicroF1 = f1\n",
    "print (\"Micro-Averaged F1-Measure:  %.2f%%\" % (f1 * 100))  \n",
    "\n",
    "#One error\n",
    "o_err = 0\n",
    "for i in range(len(test_labels)):\n",
    "    list = [(0,0) for i in range(len(categories))]\n",
    "    for j in range(len(categories)):\n",
    "        list[j] = (test_labels[i][j], res[i][j])\n",
    "    list.sort(key=getPrediction, reverse=True)\n",
    "    if list[0][0] == 0:\n",
    "        o_err += 1\n",
    "print (\"One Error: %.2f%%\" % (o_err / len(test_labels) * 100))\n",
    "\n",
    "#Coverage\n",
    "stepsDown = 0\n",
    "for i in range(len(test_labels)):\n",
    "    bound = sum(test_labels[i]) - 1\n",
    "    list = [(0,0,0) for i in range(len(categories))]\n",
    "    for j in range(len(categories)):\n",
    "        list[j] = (test_labels[i][j], res[i][j], j)\n",
    "    list.sort(key=getPrediction, reverse=True)\n",
    "    eSteps = 0\n",
    "    for j in range(len(categories)):\n",
    "        if test_labels[i][j] == 0:\n",
    "            continue\n",
    "        for k in range(len(list)):\n",
    "            if list[k][2] == j:\n",
    "                eSteps = max(eSteps, k)\n",
    "    stepsDown += max(0, eSteps - bound)\n",
    "print (\"Coverage: %.2f\" % (stepsDown / len(test_labels))) \n",
    "\n",
    "#Ranking Loss\n",
    "rl = 0\n",
    "for i in range(len(test_labels)):\n",
    "    mult = sum(test_labels[i])\n",
    "    list = [(0,0) for i in range(len(categories))]\n",
    "    wrongOrder = 0\n",
    "    for j in range(len(categories)):\n",
    "        list[j] = (test_labels[i][j], res[i][j])\n",
    "    list.sort(key=getPrediction, reverse=True)\n",
    "    for j in range(len(list)):\n",
    "        if list[j][0] == 1:\n",
    "            mult -= 1\n",
    "            if mult == 0:\n",
    "                break\n",
    "            continue\n",
    "        wrongOrder += mult\n",
    "    rl += wrongOrder / sum(test_labels[i])\n",
    "print (\"Ranking Loss: %.2f\" % (rl / len(test_labels)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model info saved.\n",
      "Name: BERT-PYTORCH-2019-Feb-13-161459, data set: /home/user/MLClassificationData/test/rtanews/source, documents: 8836, categories: 40, actual labels: 11060\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "modelName = \"BERT-PYTORCH-%s\"%(datetime.datetime.now().strftime(\"%Y-%b-%d-%H%M%S\"))\n",
    "DocInfo = namedtuple('DocInfo', 'name actLabs predLabs dtype')\n",
    "CategoryInfo = namedtuple('CategoryInfo', 'name actLabs predLabs wrongLabs notPredLabs qtyDocs qtyPredDocs precision recall f1')\n",
    "ModelInfo = namedtuple('ModelInfo', 'name dataSet cats qtyDocs qtyPredDocs qtyPartDocs qtyWrongDocs actLabs predLabs wrongLabs notPredLabs emr accuracy precision recall f1 hl macroPrecision macroRecall macroF1 microPrecision microRecall microF1 catagories docs')\n",
    "\n",
    "cNames = [''] * len(categories)\n",
    "for k,v in categories.items():\n",
    "    cNames[v] = k\n",
    "mCorrDocs = 0\n",
    "mPartDocs = 0\n",
    "mWrongDocs = 0\n",
    "cqTags = [0] * len(categories)\n",
    "cqPreds = [0] * len(categories)\n",
    "ctp = [0] * len(categories)\n",
    "cfp = [0] * len(categories)\n",
    "cfn = [0] * len(categories)\n",
    "cDocs = [0] * len(categories)\n",
    "cpDocs = [0] * len(categories)\n",
    "\n",
    "docsInfo = []\n",
    "\n",
    "for i in range(len(res)):\n",
    "    qTags = 0\n",
    "    qPreds = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    dtype = 0\n",
    "    actLabs = []\n",
    "    predLabs = []\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if actual:\n",
    "            cDocs[j] += 1\n",
    "            actLabs.append(cNames[j])\n",
    "        if predicted:\n",
    "            qPreds += 1\n",
    "            cqPreds[j] += 1\n",
    "            predLabs.append(cNames[j])\n",
    "            if actual:\n",
    "                qTags += 1\n",
    "                tp += 1\n",
    "                cqTags[j] += 1\n",
    "                ctp[j] += 1\n",
    "                cpDocs[j] += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "                cfp[j] += 1\n",
    "        else:\n",
    "            if actual:\n",
    "                qTags += 1\n",
    "                fn += 1\n",
    "                cqTags[j] += 1\n",
    "                cfn[j] += 1\n",
    "    if tp == qTags:\n",
    "        if qPreds == tp:\n",
    "            dtype = 2\n",
    "        else:\n",
    "            dtype = 3\n",
    "        mCorrDocs += 1\n",
    "    elif tp > 0:\n",
    "        dtype = 1\n",
    "        mPartDocs += 1\n",
    "    else:\n",
    "        mWrongDocs += 1\n",
    "    docInfo = DocInfo(testDocs[i].name, actLabs, predLabs, dtype)\n",
    "    docsInfo.append(docInfo)\n",
    "\n",
    "categoriesInfo = []\n",
    "for i in range(len(categories)):\n",
    "    cPrec = ctp[i] / cqTags[i]\n",
    "    cRec = 0\n",
    "    if (ctp[i] + cfp[i]) > 0:\n",
    "        cRec = ctp[i] / (ctp[i] + cfp[i])\n",
    "    cF1 = 2 * ctp[i] / (ctp[i] + cfp[i] + cqTags[i])\n",
    "    catInfo = CategoryInfo(cNames[i], cqTags[i], ctp[i], cfp[i], cfn[i], cDocs[i], cpDocs[i], cPrec, cRec, cF1)\n",
    "    categoriesInfo.append(catInfo);\n",
    "\n",
    "sourceRoot = testRoot\n",
    "modelInfo = ModelInfo(modelName,sourceRoot,len(categories),len(res), mCorrDocs, mPartDocs, mWrongDocs, \n",
    "                      sum(cqTags),sum(ctp),sum(cfp),sum(cfn),emr,modelAccuracy,\n",
    "                      modelPrecision,modelRecall,modelF1,modelHl,modelMacroPrecision,modelMacroRecall,\n",
    "                      modelMacroF1,modelMicroPrecision,modelMicroRecall,modelMicroF1,categoriesInfo,docsInfo)\n",
    "with open(modelInfoPath + modelName, 'wb') as f:\n",
    "    pickle.dump(modelInfo, f)\n",
    "print (\"Model info saved.\");\n",
    "print (\"Name: %s, data set: %s, documents: %d, categories: %d, actual labels: %d\"%(modelInfo.name, modelInfo.dataSet, modelInfo.qtyDocs, modelInfo.cats, modelInfo.actLabs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
