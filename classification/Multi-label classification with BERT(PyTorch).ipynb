{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declarations and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import gensim\n",
    "import math\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from keras import preprocessing\n",
    "from keras.preprocessing import sequence\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "from keras.models import load_model\n",
    "import statistics\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "homePath = str(Path.home()) + \"/MLClassificationData\"\n",
    "#homePath = \"c:/BERT/rtanews/docs/\"\n",
    "LabeledSentence = gensim.models.doc2vec.TaggedDocument\n",
    "# Count of categories (labels).\n",
    "n_cats = 0\n",
    "# This id is included into the names of models, created by this notebook.\n",
    "modelId = 5\n",
    "# Path to original corpus for training\n",
    "trainRoot = homePath + '/train/rtanews/source'\n",
    "# Path to original corpus for testing\n",
    "testRoot = homePath + '/test/rtanews/source'\n",
    "# Input for BERT\n",
    "bertDataPath = homePath + \"/PytorchBERT/textdir/\"\n",
    "# Output of BERT\n",
    "outDataPath = homePath + \"/PytorchBERT/outdir/\"\n",
    "# Path to model info\n",
    "modelInfoPath = homePath + '/models/rtanews/modelinfo/'\n",
    "max_bert_seq_length = 512\n",
    "numpy.random.seed(1)\n",
    "cnt = 0\n",
    "nCats = 0\n",
    "categories = dict()\n",
    "\n",
    "LabeledDocument = namedtuple('LabeledDocument', 'line words labels qLabs name')\n",
    "\n",
    "def getCategories(path):\n",
    "    cats = dict()\n",
    "    nCats = 0\n",
    "    os.chdir(path)\n",
    "    for f in glob.glob(\"*\"):\n",
    "        if os.path.isdir(f):\n",
    "            cats[f] = nCats\n",
    "            nCats += 1\n",
    "    return cats\n",
    "\n",
    "def prepareDocsData(path, cats):\n",
    "    files = dict()\n",
    "    fInCats = [0] * len(cats)\n",
    "    nFiles = 0\n",
    "    actFiles = 0\n",
    "    curCategory = 0\n",
    "    docs = []\n",
    "    os.chdir(path)\n",
    "    rootDir = os.getcwd()\n",
    "    for f in glob.glob(\"*\"):\n",
    "        curCategory = cats[f]\n",
    "        catPath = path + \"/\" + f\n",
    "        os.chdir(catPath)\n",
    "        for fc in glob.glob(\"*\"):\n",
    "            actFiles += 1\n",
    "            if fc not in files:\n",
    "                nFiles += 1\n",
    "                fPath = catPath + \"/\" + fc\n",
    "                docCont = ''\n",
    "                with open(fc, 'r', encoding='UTF-8') as tc:\n",
    "                    for line in tc:\n",
    "                        docCont += line.strip() + \" \"\n",
    "                tc.close()\n",
    "                line = docCont.strip() + \"\\n\"\n",
    "                words = docCont.strip().split()\n",
    "                labels = [0] * len(cats)\n",
    "                labels[curCategory] = 1\n",
    "                files[fc] = LabeledDocument(line, words, labels, [1], fc)\n",
    "            else:\n",
    "                files[fc].labels[curCategory] = 1\n",
    "                files[fc].qLabs[0] += 1\n",
    "            fInCats[curCategory] += 1\n",
    "    for k, val in files.items():\n",
    "        docs.append(val)\n",
    "    return docs, fInCats\n",
    "\n",
    "def getLabelSets(docs):\n",
    "    labels = [x[2] for x in docs]\n",
    "    results = [labels[0]]\n",
    "    qLabs = 0\n",
    "    for i in range(len(labels)):        \n",
    "        if i%1000 == 0:\n",
    "            print (str(i), end='\\r')\n",
    "        qLabs += sum(labels[i])\n",
    "        count = 0\n",
    "        for j in range(len(results)):\n",
    "            for k in range(len(categories)):\n",
    "                if labels[i][k] != results[j][k]:\n",
    "                    count += 1\n",
    "                    break\n",
    "        if count == len(results):\n",
    "            results.append(labels[i])\n",
    "    return len(results), qLabs\n",
    "    \n",
    "def showTime(ds,de):\n",
    "    result = ''\n",
    "    seconds = (de-ds).total_seconds()\n",
    "    if seconds < 1:\n",
    "        return \"less than 1 sec\"\n",
    "    hh = int(seconds/(60*60));\n",
    "    if hh > 0:\n",
    "        result = \"%d h:\"%(hh);\n",
    "    seconds -= hh*60*60\n",
    "    mm = int(seconds/60);\n",
    "    if mm > 0:\n",
    "        result += \"%d min:\"%(mm)\n",
    "    ss = seconds - mm*60;\n",
    "    result += \"%d sec\"%(ss)\n",
    "    return result\n",
    "\n",
    "def showDocsByLength(plt):\n",
    "    fig, (plot1, plot2) = plt.subplots(1, 2, figsize=(10,6))    \n",
    "    dictLens = dict()\n",
    "    dictLens1 = dict()\n",
    "    for i in range(len(trainDocs)):\n",
    "        lend = \"%5d\"%(len(trainDocs[i].words))\n",
    "        if not lend in dictLens:\n",
    "            dictLens[lend] = 1\n",
    "        else:\n",
    "            dictLens[lend] += 1\n",
    "    lens = sorted(list(dictLens.items()))\n",
    "    lvars = [int(x[0]) for x in lens]\n",
    "    locc = [x[1] for x in lens]\n",
    "    plot1.set_title (\"Documents by length in training set\")\n",
    "    plot1.set_ylabel(\"Documents\")\n",
    "    plot1.set_xlabel(\"Length\")\n",
    "    plot1.plot(lvars, locc, \"b.-\") \n",
    "    for i in range(len(testDocs)):\n",
    "        lend = \"%5d\"%(len(testDocs[i].words))\n",
    "        if not lend in dictLens1:\n",
    "            dictLens1[lend] = 1\n",
    "        else:\n",
    "            dictLens1[lend] += 1\n",
    "    lens1 = sorted(list(dictLens1.items()))\n",
    "    lvars1 = [int(x[0]) for x in lens1]\n",
    "    locc1 = [x[1] for x in lens1]\n",
    "    plot2.set_title (\"Documents by length in testing set\")\n",
    "    plot2.set_xlabel(\"Length\")\n",
    "    plot2.yaxis.tick_right()\n",
    "    plot2.plot(lvars1, locc1, \"b.-\") \n",
    "    plt.show()\n",
    "    \n",
    "def showDocsByLabs(plt):\n",
    "    fig, (plot1, plot2) = plt.subplots(1, 2, figsize=(10,6))\n",
    "    dictLabs = dict()\n",
    "    dictLabs1 = dict()\n",
    "    for i in range(len(trainDocs)):\n",
    "        lab = \"%5d\"%(trainDocs[i].qLabs[0])\n",
    "        if not lab in dictLabs:\n",
    "            dictLabs[lab] = 1\n",
    "        else:\n",
    "            dictLabs[lab] += 1\n",
    "    labs = sorted(list(dictLabs.items()))\n",
    "    lvars1 = [int(x[0]) for x in labs]\n",
    "    locc1 = [x[1] for x in labs]\n",
    "    plot1.set_title (\"Documents by labels in training set\")\n",
    "    plot1.set_ylabel(\"Documents\")\n",
    "    plot1.set_xlabel(\"Labels\")\n",
    "    plot1.set_xticks(numpy.arange(0, len(categories), step=1))\n",
    "    plot1.plot(lvars1, locc1, \"bo-\")\n",
    "    for i in range(len(testDocs)):\n",
    "        lab = \"%5d\"%(testDocs[i].qLabs[0])\n",
    "        if not lab in dictLabs1:\n",
    "            dictLabs1[lab] = 1\n",
    "        else:\n",
    "            dictLabs1[lab] += 1\n",
    "    labs1 = sorted(list(dictLabs1.items()))\n",
    "    lvars2 = [int(x[0]) for x in labs1]\n",
    "    locc2 = [x[1] for x in labs1]\n",
    "    plot2.set_title (\"Documents by labels in testing set\")\n",
    "    #plot2.set_ylabel(\"Documents\")\n",
    "    plot2.set_xlabel(\"Labels\")\n",
    "    plot2.set_xticks(numpy.arange(0, len(categories), step=1))\n",
    "    plot2.yaxis.tick_right()\n",
    "    plot2.plot(lvars2, locc2, \"bo-\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load input data in 4 sec\n"
     ]
    }
   ],
   "source": [
    "ds = datetime.datetime.now()\n",
    "categories = getCategories(trainRoot)\n",
    "#print (categories)\n",
    "trainAllDocs, fInCats1 = prepareDocsData(trainRoot, categories)\n",
    "trainAllDocs = random.sample(trainAllDocs, len(trainAllDocs))\n",
    "#trainDocs = trainAllDocs[:int(len(trainAllDocs) * (1 - valPart))]\n",
    "#valDocs = trainAllDocs[int(len(trainAllDocs) * (1 - valPart)):]\n",
    "trainDocs = trainAllDocs\n",
    "testDocs, fInCats2 = prepareDocsData(testRoot, categories)\n",
    "#testDocs = random.sample(testDocs, len(testDocs))\n",
    "de = datetime.datetime.now()\n",
    "\n",
    "print (\"Load input data in %s\"%(showTime(ds, de))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset properties:\n",
      "Loaded 23837 documents: 15001 for training, 8836 for test\n",
      "Length of documents: maximum: 1502, minimum: 47, average: 188, median: 174\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of 90.0% documents from training set is less then 300. Longer documents will be truncated.\n",
      "\n",
      "Categories (labels): 40\n",
      "Documents for training in category : maximum: 2800, minimum: 93, avegare: 415\n",
      "Documents for testing  in category : maximum: 1501, minimum: 65, avegare: 276\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Label Set: 290\n",
      "Proportion of Distinct Label Set: 0.0193\n",
      "Label Cardinality: 1.1073\n",
      "Label Density: 0.0277\n"
     ]
    }
   ],
   "source": [
    "print (\"Dataset properties:\")\n",
    "maxDocLen = max(len(x.words) for x in trainAllDocs)\n",
    "minDocLen = min(len(x.words) for x in trainAllDocs)\n",
    "avrgDocLen = round(statistics.mean(len(x.words) for x in trainAllDocs), 2)\n",
    "medianDocLen = round(statistics.median(len(x.words) for x in trainAllDocs), 2)\n",
    "dls, qLabs = getLabelSets(trainAllDocs)\n",
    "\n",
    "print ('Loaded %d documents: %d for training, %d for test' % (len(trainAllDocs) + len(testDocs), len(trainDocs), len(testDocs)))\n",
    "print (\"Length of documents: maximum: %d, minimum: %d, average: %d, median: %d\"%(maxDocLen, minDocLen, avrgDocLen, medianDocLen))\n",
    "showDocsByLength(plt);\n",
    "\n",
    "top_bound=0.9\n",
    "maxLen = math.ceil(maxDocLen/100)*100 + 100\n",
    "input_length_list=[]\n",
    "for i in range(100, maxLen, 100):\n",
    "    input_length_list.append(i)\n",
    "input_length_dict={x:0 for x in input_length_list }\n",
    "for i in range(len(trainAllDocs)):\n",
    "    curLen = len(trainAllDocs[i].words)\n",
    "    dictLen = maxLen\n",
    "    for ln in input_length_dict:\n",
    "        if curLen < ln:\n",
    "            dicLen = ln\n",
    "            break\n",
    "    input_length_dict[dicLen] = input_length_dict[dicLen] + 1\n",
    "input_length_dict_percentage={}\n",
    "for k,v in input_length_dict.items():\n",
    "    v=v/len(trainAllDocs)\n",
    "    input_length_dict_percentage[k]=v\n",
    "maxSeqLength=0\n",
    "accumulate_percentage=0\n",
    "for length,percentage in input_length_dict_percentage.items():\n",
    "    accumulate_percentage+=percentage\n",
    "    if accumulate_percentage>0.9:\n",
    "        maxSeqLength=length\n",
    "        break\n",
    "print (\"Length of %.1f%% documents from training set is less then %d. Longer documents will be truncated.\"%(top_bound*100, maxSeqLength))        \n",
    "\n",
    "print ()\n",
    "print (\"Categories (labels): %d\"%(len(categories)))\n",
    "print (\"Documents for training in category : maximum: %d, minimum: %d, avegare: %d\"%(max(fInCats1), min(fInCats1), round(statistics.mean(fInCats1), 2)))\n",
    "print (\"Documents for testing  in category : maximum: %d, minimum: %d, avegare: %d\"%(max(fInCats2), min(fInCats2), round(statistics.mean(fInCats2), 2)))\n",
    "showDocsByLabs(plt)\n",
    "print (\"Distinct Label Set: %d\"%(dls))\n",
    "print (\"Proportion of Distinct Label Set: %.4f\"%(dls/len(trainAllDocs)))\n",
    "print (\"Label Cardinality: %.4f\"%(qLabs/len(trainAllDocs)))\n",
    "print (\"Label Density: %.4f\"%(qLabs/len(trainAllDocs)/len(categories)))\n",
    "\n",
    "#del trainAllDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare input for training and testing BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved\n",
      "Test data saved\n"
     ]
    }
   ],
   "source": [
    "cNames = [''] * len(categories)\n",
    "for k,v in categories.items():\n",
    "    cNames[v] = k\n",
    "    \n",
    "def saveData(type):\n",
    "    global bertDataPath\n",
    "    if type == \"train\":\n",
    "        bertPath = bertDataPath + \"train.tsv\"\n",
    "        data = trainDocs        \n",
    "    else:\n",
    "        bertPath = bertDataPath + \"dev.tsv\"\n",
    "        data = testDocs        \n",
    "    target = open(bertPath, \"w\", encoding=\"utf-8\")\n",
    "    for i in range(len(data)):\n",
    "        conts = data[i].line.replace('\\r','').replace('\\n','.')\n",
    "        labs = []\n",
    "        for j in range(len(data[i].labels)):\n",
    "            if data[i].labels[j] == 1:\n",
    "                #labs.append(cNames[j].replace(\".\",\"\"))\n",
    "                labs.append(cNames[j])\n",
    "        nl = '\\n'\n",
    "        if i == 0:\n",
    "            nl = ''\n",
    "        string = nl + \",\".join(labs) + \"\\t\" + conts\n",
    "        target.write(string)\n",
    "    target.close()    \n",
    "    \n",
    "saveData(\"train\")\n",
    "print (\"Train data saved\")\n",
    "saveData(\"test\")\n",
    "print (\"Test data saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert.modeling import BertModel\n",
    "from pytorch_pretrained_bert.modeling import PreTrainedBertModel\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "class BertForMultiLabelSequenceClassification(PreTrainedBertModel):\n",
    "    \"\"\"BERT model for classification.\n",
    "    This module is composed of the BERT model with a linear layer on top of\n",
    "    the pooled output.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, num_labels=2):\n",
    "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits\n",
    "        \n",
    "    def freeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create, train, save and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/18/2019 16:27:48 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/user/.pytorch_pretrained_bert/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "02/18/2019 16:27:48 - INFO - __main__ -   LOOKING AT /home/user/MLClassificationData/PytorchBERT/textdir/train.tsv\n",
      "02/18/2019 16:27:50 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz from cache at /home/user/.pytorch_pretrained_bert/distributed_-1/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9\n",
      "02/18/2019 16:27:50 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/user/.pytorch_pretrained_bert/distributed_-1/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9 to temp dir /tmp/tmpln3gf8bm\n",
      "02/18/2019 16:27:59 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "02/18/2019 16:28:39 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "02/18/2019 16:28:39 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "02/18/2019 16:30:12 - INFO - __main__ -   ***** Running training *****\n",
      "02/18/2019 16:30:12 - INFO - __main__ -     Num examples = 15001\n",
      "02/18/2019 16:30:12 - INFO - __main__ -     Batch size = 32\n",
      "02/18/2019 16:30:12 - INFO - __main__ -     Num steps = 1404\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/469 [01:11<9:16:50, 71.39s/it]\u001b[A\n",
      "Iteration:   0%|          | 2/469 [01:54<8:08:27, 62.76s/it]\u001b[A\n",
      "Iteration:   1%|          | 3/469 [02:30<7:07:19, 55.02s/it]\u001b[A\n",
      "Iteration:   1%|          | 4/469 [03:07<6:22:26, 49.35s/it]\u001b[A\n",
      "Iteration:   1%|          | 5/469 [03:46<5:59:26, 46.48s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 6/469 [04:24<5:39:08, 43.95s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 7/469 [04:59<5:17:50, 41.28s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 8/469 [05:34<5:01:12, 39.20s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 9/469 [06:09<4:52:17, 38.13s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 10/469 [06:44<4:44:27, 37.18s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 11/469 [07:20<4:39:21, 36.60s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 12/469 [07:54<4:33:15, 35.88s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 13/469 [08:27<4:27:19, 35.17s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 14/469 [09:02<4:26:03, 35.09s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 15/469 [09:39<4:28:48, 35.52s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 16/469 [10:13<4:24:25, 35.02s/it]\u001b[A\n",
      "Iteration:   4%|▎         | 17/469 [10:47<4:21:29, 34.71s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 18/469 [11:24<4:25:51, 35.37s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 19/469 [11:59<4:24:28, 35.26s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 20/469 [12:33<4:21:10, 34.90s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 21/469 [13:07<4:19:04, 34.70s/it]\u001b[A\n",
      "Iteration:   5%|▍         | 22/469 [13:42<4:18:25, 34.69s/it]\u001b[A\n",
      "Iteration:   5%|▍         | 23/469 [14:15<4:14:15, 34.21s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 24/469 [14:49<4:13:10, 34.14s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 25/469 [15:24<4:15:53, 34.58s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 26/469 [15:57<4:12:23, 34.18s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 27/469 [16:32<4:13:02, 34.35s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 28/469 [17:07<4:12:53, 34.41s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 29/469 [17:42<4:14:59, 34.77s/it]\u001b[A\n",
      "Iteration:   6%|▋         | 30/469 [18:17<4:15:04, 34.86s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 31/469 [18:54<4:17:14, 35.24s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 32/469 [19:33<4:25:27, 36.45s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 33/469 [20:22<4:52:05, 40.20s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 34/469 [21:13<5:16:26, 43.65s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 35/469 [21:49<4:57:19, 41.10s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 36/469 [22:25<4:47:12, 39.80s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 37/469 [23:03<4:41:22, 39.08s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 38/469 [23:38<4:33:19, 38.05s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 39/469 [24:15<4:28:37, 37.48s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 40/469 [24:53<4:29:03, 37.63s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 41/469 [25:29<4:26:16, 37.33s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 42/469 [26:05<4:22:23, 36.87s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 43/469 [26:40<4:17:39, 36.29s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 44/469 [27:17<4:18:04, 36.43s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 45/469 [27:51<4:13:18, 35.85s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 46/469 [28:29<4:16:22, 36.37s/it]\u001b[A\n",
      "Iteration:  10%|█         | 47/469 [29:03<4:11:00, 35.69s/it]\u001b[A\n",
      "Iteration:  10%|█         | 48/469 [29:41<4:15:47, 36.45s/it]\u001b[A\n",
      "Iteration:  10%|█         | 49/469 [30:22<4:23:52, 37.70s/it]\u001b[A\n",
      "Iteration:  11%|█         | 50/469 [30:58<4:20:29, 37.30s/it]\u001b[A\n",
      "Iteration:  11%|█         | 51/469 [31:32<4:13:00, 36.32s/it]\u001b[A\n",
      "Iteration:  11%|█         | 52/469 [32:09<4:13:34, 36.49s/it]\u001b[A\n",
      "Iteration:  11%|█▏        | 53/469 [32:44<4:10:20, 36.11s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 54/469 [33:20<4:08:57, 35.99s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 55/469 [33:56<4:08:02, 35.95s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 56/469 [34:30<4:03:32, 35.38s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 57/469 [35:04<4:01:23, 35.15s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 58/469 [35:38<3:58:09, 34.77s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 59/469 [36:15<4:00:55, 35.26s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 60/469 [36:50<4:00:18, 35.25s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 61/469 [37:25<3:59:48, 35.27s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 62/469 [38:01<4:01:04, 35.54s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 63/469 [38:38<4:02:30, 35.84s/it]\u001b[A\n",
      "Iteration:  14%|█▎        | 64/469 [39:13<3:59:32, 35.49s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 65/469 [39:48<3:58:37, 35.44s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 66/469 [40:25<4:01:53, 36.01s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 67/469 [41:03<4:04:47, 36.54s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 68/469 [41:37<3:59:51, 35.89s/it]\u001b[A\n",
      "Iteration:  15%|█▍        | 69/469 [42:15<4:01:46, 36.27s/it]\u001b[A\n",
      "Iteration:  15%|█▍        | 70/469 [42:49<3:58:20, 35.84s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 71/469 [43:24<3:55:50, 35.55s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 72/469 [44:00<3:54:59, 35.52s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 73/469 [44:34<3:52:54, 35.29s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 74/469 [45:12<3:57:38, 36.10s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 75/469 [45:48<3:55:45, 35.90s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 76/469 [46:26<3:58:46, 36.45s/it]\u001b[A\n",
      "Iteration:  16%|█▋        | 77/469 [47:01<3:55:39, 36.07s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 78/469 [47:37<3:56:03, 36.22s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 79/469 [48:15<3:57:28, 36.53s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 80/469 [48:53<4:01:10, 37.20s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 81/469 [49:33<4:04:29, 37.81s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 82/469 [50:09<4:01:37, 37.46s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 83/469 [50:47<4:01:56, 37.61s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 84/469 [51:25<4:02:10, 37.74s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  18%|█▊        | 85/469 [52:02<3:58:50, 37.32s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 86/469 [52:40<4:01:00, 37.76s/it]\u001b[A\n",
      "Iteration:  19%|█▊        | 87/469 [53:19<4:02:45, 38.13s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 88/469 [54:00<4:06:07, 38.76s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 89/469 [54:40<4:09:15, 39.36s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 90/469 [55:20<4:09:41, 39.53s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 91/469 [55:57<4:03:43, 38.69s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 92/469 [56:36<4:04:22, 38.89s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 93/469 [57:14<4:02:08, 38.64s/it]\u001b[A\n",
      "Iteration:  20%|██        | 94/469 [57:51<3:57:45, 38.04s/it]\u001b[A\n",
      "Iteration:  20%|██        | 95/469 [58:32<4:02:24, 38.89s/it]\u001b[A\n",
      "Iteration:  20%|██        | 96/469 [59:15<4:09:02, 40.06s/it]\u001b[A\n",
      "Iteration:  21%|██        | 97/469 [59:56<4:10:00, 40.32s/it]\u001b[A\n",
      "Iteration:  21%|██        | 98/469 [1:00:37<4:10:27, 40.51s/it]\u001b[A\n",
      "Iteration:  21%|██        | 99/469 [1:01:15<4:05:09, 39.76s/it]\u001b[A\n",
      "Iteration:  21%|██▏       | 100/469 [1:01:52<3:59:06, 38.88s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 101/469 [1:02:30<3:57:37, 38.74s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 102/469 [1:03:09<3:57:34, 38.84s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 103/469 [1:03:50<4:00:24, 39.41s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 104/469 [1:04:30<4:02:04, 39.79s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 105/469 [1:05:15<4:09:18, 41.09s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 106/469 [1:05:56<4:09:49, 41.29s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 107/469 [1:06:40<4:12:54, 41.92s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 108/469 [1:07:19<4:07:38, 41.16s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 109/469 [1:07:59<4:03:58, 40.66s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 110/469 [1:08:42<4:08:37, 41.55s/it]\u001b[A\n",
      "Iteration:  24%|██▎       | 111/469 [1:09:24<4:08:31, 41.65s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 112/469 [1:10:03<4:03:43, 40.96s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 113/469 [1:10:46<4:05:02, 41.30s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 114/469 [1:11:24<3:59:03, 40.40s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 115/469 [1:12:00<3:51:33, 39.25s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 116/469 [1:12:44<3:58:55, 40.61s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 117/469 [1:13:25<3:59:12, 40.77s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 118/469 [1:14:10<4:05:31, 41.97s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 119/469 [1:14:49<3:59:35, 41.07s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 120/469 [1:15:26<3:51:23, 39.78s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 121/469 [1:16:04<3:47:07, 39.16s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 122/469 [1:16:43<3:47:25, 39.33s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 123/469 [1:17:30<4:00:15, 41.66s/it]\u001b[A\n",
      "Iteration:  26%|██▋       | 124/469 [1:18:14<4:03:26, 42.34s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 125/469 [1:19:05<4:17:52, 44.98s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 126/469 [1:19:52<4:19:21, 45.37s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 127/469 [1:20:27<4:02:05, 42.47s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 128/469 [1:21:04<3:51:25, 40.72s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 129/469 [1:21:39<3:41:42, 39.13s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 130/469 [1:22:16<3:36:08, 38.26s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 131/469 [1:22:52<3:31:43, 37.58s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 132/469 [1:23:27<3:27:52, 37.01s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 133/469 [1:24:08<3:33:37, 38.15s/it]\u001b[A\n",
      "Iteration:  29%|██▊       | 134/469 [1:24:44<3:29:04, 37.45s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 135/469 [1:25:20<3:26:29, 37.10s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 136/469 [1:25:58<3:26:15, 37.16s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 137/469 [1:26:32<3:21:35, 36.43s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 138/469 [1:27:12<3:26:25, 37.42s/it]\u001b[A\n",
      "Iteration:  30%|██▉       | 139/469 [1:27:51<3:27:56, 37.81s/it]\u001b[A\n",
      "Iteration:  30%|██▉       | 140/469 [1:28:26<3:23:29, 37.11s/it]\u001b[A\n",
      "Iteration:  30%|███       | 141/469 [1:29:01<3:19:05, 36.42s/it]\u001b[A\n",
      "Iteration:  30%|███       | 142/469 [1:29:38<3:19:49, 36.67s/it]\u001b[A\n",
      "Iteration:  30%|███       | 143/469 [1:30:14<3:18:22, 36.51s/it]\u001b[A\n",
      "Iteration:  31%|███       | 144/469 [1:30:49<3:14:52, 35.98s/it]\u001b[A\n",
      "Iteration:  31%|███       | 145/469 [1:31:28<3:18:38, 36.78s/it]\u001b[A\n",
      "Iteration:  31%|███       | 146/469 [1:32:07<3:22:25, 37.60s/it]\u001b[A\n",
      "Iteration:  31%|███▏      | 147/469 [1:32:42<3:17:38, 36.83s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 148/469 [1:33:18<3:14:35, 36.37s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 149/469 [1:33:57<3:19:17, 37.37s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 150/469 [1:34:34<3:16:46, 37.01s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 151/469 [1:35:10<3:15:31, 36.89s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 152/469 [1:35:48<3:15:40, 37.04s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 153/469 [1:36:29<3:22:00, 38.36s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 154/469 [1:37:13<3:30:13, 40.04s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 155/469 [1:37:51<3:26:49, 39.52s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 156/469 [1:38:31<3:27:10, 39.71s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 157/469 [1:39:12<3:27:19, 39.87s/it]\u001b[A\n",
      "Iteration:  34%|███▎      | 158/469 [1:39:53<3:28:51, 40.29s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 159/469 [1:40:35<3:30:42, 40.78s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 160/469 [1:41:10<3:21:51, 39.20s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 161/469 [1:41:46<3:15:29, 38.08s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 162/469 [1:42:30<3:24:44, 40.02s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 163/469 [1:43:19<3:37:20, 42.62s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 164/469 [1:43:58<3:31:35, 41.63s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 165/469 [1:44:42<3:34:11, 42.28s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 166/469 [1:45:21<3:28:39, 41.32s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 167/469 [1:46:07<3:34:52, 42.69s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 168/469 [1:46:46<3:28:36, 41.58s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 169/469 [1:47:24<3:22:08, 40.43s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 170/469 [1:48:04<3:21:45, 40.49s/it]\u001b[A\n",
      "Iteration:  36%|███▋      | 171/469 [1:48:50<3:28:55, 42.07s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 172/469 [1:49:35<3:31:52, 42.80s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 173/469 [1:50:23<3:38:34, 44.31s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 174/469 [1:51:06<3:36:02, 43.94s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 175/469 [1:51:54<3:42:23, 45.39s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 176/469 [1:52:37<3:37:39, 44.57s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 177/469 [1:53:22<3:37:58, 44.79s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 178/469 [1:53:59<3:24:47, 42.23s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 179/469 [1:54:42<3:25:58, 42.62s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 180/469 [1:55:26<3:26:28, 42.87s/it]\u001b[A\n",
      "Iteration:  39%|███▊      | 181/469 [1:56:04<3:19:39, 41.59s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 182/469 [1:56:51<3:25:45, 43.02s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 183/469 [1:57:34<3:25:04, 43.02s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 184/469 [1:58:11<3:16:39, 41.40s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 185/469 [1:58:49<3:11:17, 40.41s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 186/469 [1:59:27<3:06:35, 39.56s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 187/469 [2:00:03<3:00:29, 38.40s/it]\u001b[A\n",
      "Iteration:  40%|████      | 188/469 [2:00:39<2:56:56, 37.78s/it]\u001b[A\n",
      "Iteration:  40%|████      | 189/469 [2:01:16<2:55:22, 37.58s/it]\u001b[A\n",
      "Iteration:  41%|████      | 190/469 [2:01:53<2:53:19, 37.28s/it]\u001b[A\n",
      "Iteration:  41%|████      | 191/469 [2:02:30<2:52:41, 37.27s/it]\u001b[A\n",
      "Iteration:  41%|████      | 192/469 [2:03:08<2:52:40, 37.40s/it]\u001b[A\n",
      "Iteration:  41%|████      | 193/469 [2:03:45<2:51:43, 37.33s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 194/469 [2:04:20<2:47:48, 36.61s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 195/469 [2:04:58<2:49:42, 37.16s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 196/469 [2:05:38<2:52:58, 38.02s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 197/469 [2:06:31<3:12:57, 42.57s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 198/469 [2:07:16<3:15:30, 43.28s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 199/469 [2:07:54<3:07:06, 41.58s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 200/469 [2:08:29<2:57:34, 39.61s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 201/469 [2:09:06<2:53:41, 38.89s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 202/469 [2:09:45<2:52:29, 38.76s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 203/469 [2:10:23<2:50:48, 38.53s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 204/469 [2:11:02<2:51:51, 38.91s/it]\u001b[A\n",
      "Iteration:  44%|████▎     | 205/469 [2:11:46<2:57:57, 40.44s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  44%|████▍     | 206/469 [2:12:27<2:57:24, 40.47s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 207/469 [2:13:09<2:59:17, 41.06s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 208/469 [2:13:50<2:58:41, 41.08s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 209/469 [2:14:34<3:00:53, 41.75s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 210/469 [2:15:19<3:04:07, 42.66s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 211/469 [2:16:14<3:19:33, 46.41s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 212/469 [2:16:57<3:15:18, 45.60s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 213/469 [2:17:35<3:04:20, 43.20s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 214/469 [2:18:16<3:00:48, 42.54s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 215/469 [2:18:53<2:53:18, 40.94s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 216/469 [2:19:39<2:58:55, 42.43s/it]\u001b[A\n",
      "Iteration:  46%|████▋     | 217/469 [2:20:16<2:51:14, 40.77s/it]\u001b[A\n",
      "Iteration:  46%|████▋     | 218/469 [2:20:53<2:46:06, 39.71s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 219/469 [2:21:32<2:44:04, 39.38s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 220/469 [2:22:11<2:43:08, 39.31s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 221/469 [2:22:50<2:41:44, 39.13s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 222/469 [2:23:30<2:42:53, 39.57s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 223/469 [2:24:12<2:44:16, 40.07s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 224/469 [2:24:53<2:45:08, 40.44s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 225/469 [2:25:30<2:40:33, 39.48s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 226/469 [2:26:07<2:36:57, 38.76s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 227/469 [2:26:45<2:35:04, 38.45s/it]\u001b[A\n",
      "Iteration:  49%|████▊     | 228/469 [2:27:23<2:33:57, 38.33s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 229/469 [2:28:53<3:35:45, 53.94s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 230/469 [2:30:44<4:43:00, 71.05s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 231/469 [2:32:30<5:23:17, 81.50s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 232/469 [2:34:23<5:58:47, 90.83s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 233/469 [2:36:12<6:19:16, 96.42s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 234/469 [2:38:08<6:39:54, 102.10s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 235/469 [2:40:09<7:00:20, 107.78s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 236/469 [2:41:58<7:00:29, 108.28s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 237/469 [2:43:48<7:00:44, 108.81s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 238/469 [2:45:52<7:15:57, 113.24s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 239/469 [2:47:35<7:03:11, 110.40s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 240/469 [2:49:25<7:00:49, 110.26s/it]\u001b[A\n",
      "Iteration:  51%|█████▏    | 241/469 [2:51:14<6:56:44, 109.67s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 242/469 [2:53:10<7:02:55, 111.79s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 243/469 [2:55:03<7:02:21, 112.13s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 244/469 [2:57:05<7:10:55, 114.91s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 245/469 [2:59:16<7:27:25, 119.85s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 246/469 [3:01:19<7:28:50, 120.76s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 247/469 [3:03:18<7:25:04, 120.29s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 248/469 [3:05:20<7:25:15, 120.88s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 249/469 [3:07:12<7:13:10, 118.14s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 250/469 [3:09:07<7:07:08, 117.03s/it]\u001b[A\n",
      "Iteration:  54%|█████▎    | 251/469 [3:11:04<7:05:17, 117.05s/it]\u001b[A\n",
      "Iteration:  54%|█████▎    | 252/469 [3:13:03<7:05:21, 117.61s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 253/469 [3:14:49<6:51:41, 114.36s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 254/469 [3:16:58<7:04:32, 118.48s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 255/469 [3:18:48<6:54:12, 116.13s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 256/469 [3:20:44<6:51:52, 116.02s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 257/469 [3:22:32<6:41:38, 113.67s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 258/469 [3:24:24<6:38:04, 113.20s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 259/469 [3:26:17<6:35:28, 112.99s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 260/469 [3:28:16<6:40:36, 115.01s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 261/469 [3:30:11<6:38:18, 114.90s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 262/469 [3:31:59<6:29:24, 112.87s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 263/469 [3:33:59<6:34:26, 114.89s/it]\u001b[A\n",
      "Iteration:  56%|█████▋    | 264/469 [3:35:56<6:34:30, 115.47s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 265/469 [3:37:39<6:20:21, 111.87s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 266/469 [3:38:19<5:05:21, 90.25s/it] \u001b[A\n",
      "Iteration:  57%|█████▋    | 267/469 [3:38:56<4:09:41, 74.16s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 268/469 [3:39:33<3:32:01, 63.29s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 269/469 [3:40:11<3:04:54, 55.47s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 270/469 [3:40:48<2:45:23, 49.87s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 271/469 [3:41:26<2:33:02, 46.38s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 272/469 [3:42:02<2:22:11, 43.31s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 273/469 [3:42:37<2:13:45, 40.95s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 274/469 [3:43:15<2:09:39, 39.90s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 275/469 [3:43:53<2:07:25, 39.41s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 276/469 [3:44:30<2:04:29, 38.70s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 277/469 [3:45:06<2:01:01, 37.82s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 278/469 [3:45:43<2:00:03, 37.71s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 279/469 [3:46:19<1:57:29, 37.10s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 280/469 [3:46:56<1:56:29, 36.98s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 281/469 [3:47:32<1:55:06, 36.73s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 282/469 [3:48:09<1:54:59, 36.90s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 283/469 [3:48:45<1:53:36, 36.65s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 284/469 [3:49:23<1:53:46, 36.90s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 285/469 [3:50:00<1:53:17, 36.94s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 286/469 [3:50:37<1:52:51, 37.00s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 287/469 [3:51:14<1:52:42, 37.15s/it]\u001b[A\n",
      "Iteration:  61%|██████▏   | 288/469 [3:51:53<1:53:34, 37.65s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 289/469 [3:52:31<1:52:55, 37.64s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 290/469 [3:53:09<1:52:52, 37.84s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 291/469 [3:53:46<1:51:31, 37.59s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 292/469 [3:54:24<1:50:50, 37.57s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 293/469 [3:55:01<1:50:13, 37.58s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 294/469 [3:55:39<1:49:47, 37.64s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 295/469 [3:56:18<1:50:34, 38.13s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 296/469 [3:56:56<1:49:52, 38.11s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 297/469 [3:57:35<1:49:32, 38.21s/it]\u001b[A\n",
      "Iteration:  64%|██████▎   | 298/469 [3:58:13<1:48:55, 38.22s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 299/469 [3:58:50<1:47:08, 37.82s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 300/469 [3:59:28<1:46:31, 37.82s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 301/469 [4:00:06<1:46:33, 38.05s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 302/469 [4:00:44<1:45:47, 38.01s/it]\u001b[A\n",
      "Iteration:  65%|██████▍   | 303/469 [4:01:21<1:44:20, 37.71s/it]\u001b[A\n",
      "Iteration:  65%|██████▍   | 304/469 [4:01:59<1:43:39, 37.70s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 305/469 [4:02:36<1:42:08, 37.37s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 306/469 [4:03:13<1:41:21, 37.31s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 307/469 [4:03:49<1:39:46, 36.95s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 308/469 [4:04:25<1:38:34, 36.74s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 309/469 [4:05:02<1:38:05, 36.78s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 310/469 [4:05:39<1:37:17, 36.71s/it]\u001b[A\n",
      "Iteration:  66%|██████▋   | 311/469 [4:06:17<1:37:42, 37.11s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 312/469 [4:06:53<1:36:14, 36.78s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 313/469 [4:07:28<1:34:37, 36.40s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 314/469 [4:08:05<1:34:26, 36.56s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 315/469 [4:08:41<1:33:25, 36.40s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 316/469 [4:09:18<1:33:09, 36.53s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 317/469 [4:09:55<1:32:41, 36.59s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 318/469 [4:10:32<1:33:02, 36.97s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 319/469 [4:11:09<1:32:07, 36.85s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 320/469 [4:11:46<1:31:49, 36.97s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 321/469 [4:12:25<1:32:31, 37.51s/it]\u001b[A\n",
      "Iteration:  69%|██████▊   | 322/469 [4:13:05<1:33:21, 38.10s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 323/469 [4:13:42<1:32:19, 37.94s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 324/469 [4:14:19<1:31:15, 37.76s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 325/469 [4:14:58<1:31:24, 38.08s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  70%|██████▉   | 326/469 [4:15:36<1:30:37, 38.03s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 327/469 [4:16:14<1:29:59, 38.03s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 328/469 [4:16:52<1:29:19, 38.01s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 329/469 [4:17:30<1:28:37, 37.98s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 330/469 [4:18:08<1:28:03, 38.01s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 331/469 [4:18:46<1:27:29, 38.04s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 332/469 [4:19:27<1:28:27, 38.74s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 333/469 [4:20:04<1:26:34, 38.19s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 334/469 [4:20:42<1:26:02, 38.24s/it]\u001b[A\n",
      "Iteration:  71%|███████▏  | 335/469 [4:21:19<1:24:49, 37.98s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 336/469 [4:21:56<1:23:30, 37.67s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 337/469 [4:22:33<1:22:11, 37.36s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 338/469 [4:23:11<1:22:22, 37.73s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 339/469 [4:23:49<1:21:40, 37.70s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 340/469 [4:24:26<1:20:39, 37.52s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 341/469 [4:25:04<1:20:15, 37.62s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 342/469 [4:25:41<1:19:22, 37.50s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 343/469 [4:26:19<1:19:00, 37.63s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 344/469 [4:26:58<1:19:16, 38.05s/it]\u001b[A\n",
      "Iteration:  74%|███████▎  | 345/469 [4:27:37<1:19:08, 38.29s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 346/469 [4:28:15<1:18:07, 38.11s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 347/469 [4:28:53<1:17:17, 38.01s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 348/469 [4:29:30<1:16:25, 37.89s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 349/469 [4:30:07<1:15:03, 37.53s/it]\u001b[A\n",
      "Iteration:  75%|███████▍  | 350/469 [4:30:44<1:14:06, 37.37s/it]\u001b[A\n",
      "Iteration:  75%|███████▍  | 351/469 [4:31:21<1:13:27, 37.35s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 352/469 [4:31:59<1:13:09, 37.51s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 353/469 [4:32:35<1:11:31, 36.99s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 354/469 [4:33:13<1:11:33, 37.34s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 355/469 [4:33:50<1:10:55, 37.33s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 356/469 [4:34:28<1:10:34, 37.47s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 357/469 [4:35:07<1:10:55, 38.00s/it]\u001b[A\n",
      "Iteration:  76%|███████▋  | 358/469 [4:35:44<1:09:42, 37.68s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 359/469 [4:36:22<1:09:05, 37.69s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 360/469 [4:36:58<1:07:47, 37.31s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 361/469 [4:37:37<1:07:49, 37.68s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 362/469 [4:38:15<1:07:29, 37.85s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 363/469 [4:38:52<1:06:25, 37.60s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 364/469 [4:39:30<1:05:58, 37.70s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 365/469 [4:40:07<1:05:01, 37.51s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 366/469 [4:40:46<1:04:48, 37.75s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 367/469 [4:41:23<1:04:11, 37.76s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 368/469 [4:42:01<1:03:33, 37.76s/it]\u001b[A\n",
      "Iteration:  79%|███████▊  | 369/469 [4:42:37<1:02:05, 37.26s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 370/469 [4:43:17<1:02:37, 37.96s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 371/469 [4:43:54<1:01:31, 37.67s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 372/469 [4:44:30<1:00:05, 37.17s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 373/469 [4:45:07<59:34, 37.24s/it]  \u001b[A\n",
      "Iteration:  80%|███████▉  | 374/469 [4:45:46<59:39, 37.68s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 375/469 [4:46:24<59:20, 37.88s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 376/469 [4:47:02<58:47, 37.93s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 377/469 [4:47:41<58:34, 38.20s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 378/469 [4:48:19<57:51, 38.14s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 379/469 [4:48:58<57:46, 38.52s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 380/469 [4:49:37<57:15, 38.60s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 381/469 [4:50:13<55:24, 37.78s/it]\u001b[A\n",
      "Iteration:  81%|████████▏ | 382/469 [4:50:50<54:30, 37.59s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 383/469 [4:51:27<53:42, 37.47s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 384/469 [4:52:05<53:16, 37.61s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 385/469 [4:52:43<52:31, 37.52s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 386/469 [4:53:20<51:58, 37.57s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 387/469 [4:53:59<51:53, 37.97s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 388/469 [4:54:35<50:14, 37.22s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 389/469 [4:55:12<49:42, 37.28s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 390/469 [4:55:50<49:07, 37.31s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 391/469 [4:56:27<48:24, 37.24s/it]\u001b[A\n",
      "Iteration:  84%|████████▎ | 392/469 [4:57:03<47:33, 37.06s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 393/469 [4:57:41<47:16, 37.32s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 394/469 [4:58:19<46:53, 37.52s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 395/469 [4:58:56<45:54, 37.22s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 396/469 [4:59:32<45:07, 37.09s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 397/469 [5:00:10<44:30, 37.09s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 398/469 [5:00:46<43:42, 36.94s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 399/469 [5:01:23<42:54, 36.78s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 400/469 [5:02:01<42:45, 37.17s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 401/469 [5:02:37<41:51, 36.93s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 402/469 [5:03:15<41:31, 37.18s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 403/469 [5:03:53<41:17, 37.55s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 404/469 [5:04:32<41:09, 38.00s/it]\u001b[A\n",
      "Iteration:  86%|████████▋ | 405/469 [5:05:10<40:27, 37.93s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 406/469 [5:05:47<39:34, 37.70s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 407/469 [5:06:27<39:29, 38.21s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 408/469 [5:07:07<39:37, 38.97s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 409/469 [5:07:45<38:41, 38.69s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 410/469 [5:08:26<38:41, 39.35s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 411/469 [5:09:20<42:13, 43.68s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 412/469 [5:10:50<54:42, 57.59s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 413/469 [5:12:28<1:04:55, 69.57s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 414/469 [5:14:06<1:11:42, 78.23s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 415/469 [5:15:35<1:13:22, 81.53s/it]\u001b[A\n",
      "Iteration:  89%|████████▊ | 416/469 [5:17:12<1:16:02, 86.08s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 417/469 [5:18:46<1:16:45, 88.57s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 418/469 [5:20:17<1:15:49, 89.21s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 419/469 [5:21:46<1:14:11, 89.04s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 420/469 [5:23:22<1:14:32, 91.27s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 421/469 [5:24:53<1:12:57, 91.20s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 422/469 [5:26:29<1:12:30, 92.57s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 423/469 [5:27:54<1:09:13, 90.29s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 424/469 [5:29:27<1:08:25, 91.24s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 425/469 [5:31:07<1:08:39, 93.62s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 426/469 [5:32:36<1:06:07, 92.26s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 427/469 [5:34:11<1:05:15, 93.23s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 428/469 [5:35:43<1:03:28, 92.89s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 429/469 [5:37:18<1:02:15, 93.40s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 430/469 [5:38:47<59:55, 92.19s/it]  \u001b[A\n",
      "Iteration:  92%|█████████▏| 431/469 [5:40:12<56:55, 89.88s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 432/469 [5:41:44<55:46, 90.46s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 433/469 [5:43:23<55:51, 93.08s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 434/469 [5:44:53<53:46, 92.18s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 435/469 [5:46:25<52:12, 92.15s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 436/469 [5:47:59<50:56, 92.62s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 437/469 [5:49:36<50:05, 93.92s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 438/469 [5:51:05<47:46, 92.47s/it]\u001b[A\n",
      "Iteration:  94%|█████████▎| 439/469 [5:52:38<46:19, 92.64s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 440/469 [5:54:05<43:57, 90.94s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 441/469 [5:55:37<42:39, 91.39s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 442/469 [5:57:07<40:51, 90.81s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 443/469 [5:58:44<40:13, 92.83s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 444/469 [6:00:14<38:21, 92.08s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 445/469 [6:01:46<36:44, 91.85s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 446/469 [6:03:17<35:09, 91.73s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 447/469 [6:04:53<34:06, 93.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  96%|█████████▌| 448/469 [6:06:21<31:58, 91.37s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 449/469 [6:07:54<30:36, 91.83s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 450/469 [6:09:29<29:27, 93.02s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 451/469 [6:10:59<27:34, 91.89s/it]\u001b[A\n",
      "Iteration:  96%|█████████▋| 452/469 [6:12:35<26:22, 93.11s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 453/469 [6:14:16<25:27, 95.48s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 454/469 [6:15:50<23:49, 95.27s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 455/469 [6:17:20<21:50, 93.58s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 456/469 [6:18:52<20:09, 93.04s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 457/469 [6:20:26<18:39, 93.32s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 458/469 [6:22:01<17:11, 93.75s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 459/469 [6:23:27<15:14, 91.44s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 460/469 [6:25:16<14:30, 96.77s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 461/469 [6:26:49<12:46, 95.76s/it]\u001b[A\n",
      "Iteration:  99%|█████████▊| 462/469 [6:28:26<11:11, 95.93s/it]\u001b[A\n",
      "Iteration:  99%|█████████▊| 463/469 [6:29:53<09:20, 93.50s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 464/469 [6:31:22<07:39, 91.92s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 465/469 [6:32:51<06:04, 91.21s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 466/469 [6:34:25<04:36, 92.05s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 467/469 [6:36:02<03:07, 93.55s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 468/469 [6:37:36<01:33, 93.51s/it]\u001b[A\n",
      "Epoch:  33%|███▎      | 1/3 [6:38:49<13:17:39, 23929.53s/it]t]\u001b[A\n",
      "Iteration:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/469 [01:28<11:29:28, 88.39s/it]\u001b[A\n",
      "Iteration:   0%|          | 2/469 [03:06<11:50:55, 91.34s/it]\u001b[A\n",
      "Iteration:   1%|          | 3/469 [04:38<11:50:34, 91.49s/it]\u001b[A\n",
      "Iteration:   1%|          | 4/469 [06:10<11:50:17, 91.65s/it]\u001b[A\n",
      "Iteration:   1%|          | 5/469 [07:42<11:48:42, 91.64s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 6/469 [09:27<12:19:30, 95.83s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 7/469 [10:50<11:48:35, 92.03s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 8/469 [12:24<11:50:20, 92.45s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 9/469 [14:04<12:05:53, 94.68s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 10/469 [15:33<11:52:24, 93.13s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 11/469 [17:03<11:43:21, 92.14s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 12/469 [18:45<12:03:48, 95.03s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 13/469 [20:20<12:01:45, 94.97s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 14/469 [21:58<12:08:02, 96.01s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 15/469 [23:35<12:07:58, 96.21s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 16/469 [25:04<11:50:37, 94.12s/it]\u001b[A\n",
      "Iteration:   4%|▎         | 17/469 [26:31<11:33:03, 92.00s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 18/469 [27:59<11:21:23, 90.65s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 19/469 [29:32<11:25:11, 91.36s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 20/469 [31:13<11:46:19, 94.39s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 21/469 [32:41<11:30:56, 92.54s/it]\u001b[A\n",
      "Iteration:   5%|▍         | 22/469 [34:08<11:16:09, 90.76s/it]\u001b[A\n",
      "Iteration:   5%|▍         | 23/469 [35:39<11:14:47, 90.78s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 24/469 [37:09<11:13:00, 90.74s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 25/469 [38:36<11:01:41, 89.42s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 26/469 [40:02<10:53:44, 88.54s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 27/469 [41:34<10:58:41, 89.41s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 28/469 [43:08<11:08:31, 90.96s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 29/469 [44:39<11:06:49, 90.93s/it]\u001b[A\n",
      "Iteration:   6%|▋         | 30/469 [46:09<11:03:46, 90.72s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 31/469 [47:40<11:02:03, 90.69s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 32/469 [49:14<11:09:08, 91.87s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 33/469 [50:49<11:13:14, 92.65s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 34/469 [52:13<10:53:49, 90.18s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 35/469 [53:46<10:57:16, 90.87s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 36/469 [55:16<10:55:17, 90.80s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 37/469 [56:45<10:49:17, 90.18s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 38/469 [58:15<10:47:22, 90.12s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 39/469 [59:41<10:37:12, 88.91s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 40/469 [1:01:10<10:35:06, 88.83s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 41/469 [1:02:42<10:40:12, 89.75s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 42/469 [1:04:15<10:46:22, 90.83s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 43/469 [1:05:48<10:48:25, 91.33s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 44/469 [1:07:17<10:42:47, 90.75s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 45/469 [1:08:54<10:53:29, 92.48s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 46/469 [1:10:29<10:57:43, 93.29s/it]\u001b[A\n",
      "Iteration:  10%|█         | 47/469 [1:12:10<11:12:10, 95.57s/it]\u001b[A\n",
      "Iteration:  10%|█         | 48/469 [1:13:42<11:03:24, 94.55s/it]\u001b[A\n",
      "Iteration:  10%|█         | 49/469 [1:15:16<11:00:16, 94.33s/it]\u001b[A\n",
      "Iteration:  11%|█         | 50/469 [1:16:57<11:13:48, 96.49s/it]\u001b[A\n",
      "Iteration:  11%|█         | 51/469 [1:18:25<10:54:16, 93.92s/it]\u001b[A\n",
      "Iteration:  11%|█         | 52/469 [1:19:58<10:51:06, 93.69s/it]\u001b[A\n",
      "Iteration:  11%|█▏        | 53/469 [1:21:33<10:51:41, 93.99s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 54/469 [1:23:10<10:55:56, 94.83s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 55/469 [1:24:37<10:38:29, 92.54s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 56/469 [1:26:06<10:30:04, 91.54s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 57/469 [1:27:41<10:34:47, 92.44s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 58/469 [1:29:16<10:38:21, 93.19s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 59/469 [1:30:41<10:20:29, 90.80s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 60/469 [1:32:23<10:42:01, 94.19s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 61/469 [1:34:01<10:48:43, 95.40s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 62/469 [1:35:45<11:04:19, 97.94s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 63/469 [1:37:26<11:07:56, 98.71s/it]\u001b[A\n",
      "Iteration:  14%|█▎        | 64/469 [1:39:04<11:05:01, 98.52s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 65/469 [1:40:38<10:54:09, 97.15s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 66/469 [1:42:18<10:59:23, 98.17s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 67/469 [1:43:58<11:00:49, 98.63s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 68/469 [1:45:35<10:55:48, 98.13s/it]\u001b[A\n",
      "Iteration:  15%|█▍        | 69/469 [1:47:14<10:55:54, 98.39s/it]\u001b[A\n",
      "Iteration:  15%|█▍        | 70/469 [1:48:57<11:03:17, 99.74s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 71/469 [1:50:39<11:06:49, 100.53s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 72/469 [1:53:15<12:56:07, 117.30s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 73/469 [1:53:56<10:21:43, 94.20s/it] \u001b[A\n",
      "Iteration:  16%|█▌        | 74/469 [1:54:35<8:31:05, 77.63s/it] \u001b[A\n",
      "Iteration:  16%|█▌        | 75/469 [1:55:13<7:11:45, 65.75s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 76/469 [1:55:52<6:17:44, 57.67s/it]\u001b[A\n",
      "Iteration:  16%|█▋        | 77/469 [1:56:29<5:38:03, 51.74s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 78/469 [1:57:08<5:10:21, 47.63s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 79/469 [1:57:46<4:51:08, 44.79s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 80/469 [1:58:23<4:36:35, 42.66s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 81/469 [1:59:02<4:27:05, 41.30s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 82/469 [1:59:41<4:22:05, 40.63s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 83/469 [2:00:18<4:16:05, 39.81s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 84/469 [2:00:56<4:11:39, 39.22s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 85/469 [2:01:34<4:08:50, 38.88s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 86/469 [2:02:13<4:07:16, 38.74s/it]\u001b[A\n",
      "Iteration:  19%|█▊        | 87/469 [2:02:52<4:07:14, 38.83s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 88/469 [2:03:30<4:04:51, 38.56s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 89/469 [2:04:09<4:04:48, 38.66s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 90/469 [2:04:47<4:02:57, 38.46s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 91/469 [2:05:25<4:01:18, 38.30s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 92/469 [2:06:04<4:02:20, 38.57s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 93/469 [2:06:42<4:01:07, 38.48s/it]\u001b[A\n",
      "Iteration:  20%|██        | 94/469 [2:07:20<3:58:57, 38.23s/it]\u001b[A\n",
      "Iteration:  20%|██        | 95/469 [2:08:00<4:01:46, 38.79s/it]\u001b[A\n",
      "Iteration:  20%|██        | 96/469 [2:08:39<4:01:21, 38.83s/it]\u001b[A\n",
      "Iteration:  21%|██        | 97/469 [2:09:16<3:58:41, 38.50s/it]\u001b[A\n",
      "Iteration:  21%|██        | 98/469 [2:09:55<3:58:45, 38.61s/it]\u001b[A\n",
      "Iteration:  21%|██        | 99/469 [2:10:34<3:57:23, 38.49s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  21%|██▏       | 100/469 [2:11:13<3:57:42, 38.65s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 101/469 [2:11:50<3:54:46, 38.28s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 102/469 [2:12:29<3:55:22, 38.48s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 103/469 [2:13:06<3:52:34, 38.13s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 104/469 [2:13:44<3:51:11, 38.00s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 105/469 [2:14:23<3:51:59, 38.24s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 106/469 [2:15:01<3:50:32, 38.10s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 107/469 [2:15:39<3:49:43, 38.08s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 108/469 [2:16:17<3:50:34, 38.32s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 109/469 [2:16:55<3:48:39, 38.11s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 110/469 [2:17:33<3:47:11, 37.97s/it]\u001b[A\n",
      "Iteration:  24%|██▎       | 111/469 [2:18:12<3:48:05, 38.23s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 112/469 [2:18:50<3:48:19, 38.37s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 113/469 [2:19:28<3:45:59, 38.09s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 114/469 [2:20:07<3:47:06, 38.39s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 115/469 [2:20:45<3:45:42, 38.25s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 116/469 [2:21:24<3:46:16, 38.46s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 117/469 [2:22:02<3:44:50, 38.33s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 118/469 [2:22:42<3:47:04, 38.82s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 119/469 [2:23:20<3:45:16, 38.62s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 120/469 [2:23:57<3:41:44, 38.12s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 121/469 [2:24:37<3:44:19, 38.68s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 122/469 [2:25:15<3:42:26, 38.46s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 123/469 [2:25:53<3:41:53, 38.48s/it]\u001b[A\n",
      "Iteration:  26%|██▋       | 124/469 [2:26:32<3:41:25, 38.51s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 125/469 [2:27:10<3:39:30, 38.29s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 126/469 [2:27:48<3:38:31, 38.22s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 127/469 [2:28:27<3:40:42, 38.72s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 128/469 [2:29:06<3:39:37, 38.64s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 129/469 [2:29:44<3:37:32, 38.39s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 130/469 [2:30:23<3:38:01, 38.59s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 131/469 [2:31:01<3:36:12, 38.38s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 132/469 [2:31:38<3:33:36, 38.03s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 133/469 [2:32:16<3:33:51, 38.19s/it]\u001b[A\n",
      "Iteration:  29%|██▊       | 134/469 [2:32:55<3:33:30, 38.24s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 135/469 [2:33:33<3:31:57, 38.08s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 136/469 [2:34:10<3:30:13, 37.88s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 137/469 [2:34:48<3:29:56, 37.94s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 138/469 [2:35:26<3:29:08, 37.91s/it]\u001b[A\n",
      "Iteration:  30%|██▉       | 139/469 [2:36:05<3:30:17, 38.24s/it]\u001b[A\n",
      "Iteration:  30%|██▉       | 140/469 [2:36:44<3:31:55, 38.65s/it]\u001b[A\n",
      "Iteration:  30%|███       | 141/469 [2:37:22<3:28:58, 38.23s/it]\u001b[A\n",
      "Iteration:  30%|███       | 142/469 [2:38:00<3:28:00, 38.17s/it]\u001b[A\n",
      "Iteration:  30%|███       | 143/469 [2:38:40<3:31:28, 38.92s/it]\u001b[A\n",
      "Iteration:  31%|███       | 144/469 [2:39:19<3:29:57, 38.76s/it]\u001b[A\n",
      "Iteration:  31%|███       | 145/469 [2:39:56<3:27:35, 38.44s/it]\u001b[A\n",
      "Iteration:  31%|███       | 146/469 [2:40:34<3:26:06, 38.29s/it]\u001b[A\n",
      "Iteration:  31%|███▏      | 147/469 [2:41:15<3:29:32, 39.05s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 148/469 [2:41:53<3:26:12, 38.54s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 149/469 [2:42:30<3:24:27, 38.34s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 150/469 [2:43:09<3:23:26, 38.27s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 151/469 [2:43:45<3:20:05, 37.75s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 152/469 [2:44:23<3:19:30, 37.76s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 153/469 [2:45:03<3:21:53, 38.33s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 154/469 [2:45:41<3:20:50, 38.26s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 155/469 [2:46:20<3:21:22, 38.48s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 156/469 [2:46:59<3:22:09, 38.75s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 157/469 [2:47:38<3:21:24, 38.73s/it]\u001b[A\n",
      "Iteration:  34%|███▎      | 158/469 [2:48:16<3:19:28, 38.48s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 159/469 [2:48:53<3:17:35, 38.24s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 160/469 [2:49:32<3:17:44, 38.40s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 161/469 [2:50:11<3:17:24, 38.46s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 162/469 [2:50:49<3:16:29, 38.40s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 163/469 [2:51:28<3:16:43, 38.57s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 164/469 [2:52:06<3:14:53, 38.34s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 165/469 [2:52:43<3:13:26, 38.18s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 166/469 [2:53:22<3:13:05, 38.24s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 167/469 [2:54:00<3:12:02, 38.15s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 168/469 [2:54:39<3:12:25, 38.36s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 169/469 [2:55:17<3:11:28, 38.29s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 170/469 [2:55:56<3:11:39, 38.46s/it]\u001b[A\n",
      "Iteration:  36%|███▋      | 171/469 [2:56:34<3:10:22, 38.33s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 172/469 [2:57:12<3:09:19, 38.25s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 173/469 [2:57:49<3:07:37, 38.03s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 174/469 [2:58:26<3:05:48, 37.79s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 175/469 [2:59:04<3:04:12, 37.59s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 176/469 [2:59:42<3:05:08, 37.91s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 177/469 [3:00:21<3:05:11, 38.05s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 178/469 [3:00:59<3:04:25, 38.03s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 179/469 [3:01:38<3:05:57, 38.47s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 180/469 [3:02:15<3:03:41, 38.14s/it]\u001b[A\n",
      "Iteration:  39%|███▊      | 181/469 [3:02:52<3:01:24, 37.80s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 182/469 [3:03:30<3:00:16, 37.69s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 183/469 [3:04:08<2:59:35, 37.68s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 184/469 [3:04:46<2:59:21, 37.76s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 185/469 [3:05:22<2:56:53, 37.37s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 186/469 [3:06:01<2:58:06, 37.76s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 187/469 [3:06:39<2:57:45, 37.82s/it]\u001b[A\n",
      "Iteration:  40%|████      | 188/469 [3:07:16<2:56:59, 37.79s/it]\u001b[A\n",
      "Iteration:  40%|████      | 189/469 [3:07:54<2:56:27, 37.81s/it]\u001b[A\n",
      "Iteration:  41%|████      | 190/469 [3:08:32<2:55:38, 37.77s/it]\u001b[A\n",
      "Iteration:  41%|████      | 191/469 [3:09:11<2:56:30, 38.10s/it]\u001b[A\n",
      "Iteration:  41%|████      | 192/469 [3:09:49<2:55:30, 38.02s/it]\u001b[A\n",
      "Iteration:  41%|████      | 193/469 [3:10:27<2:55:09, 38.08s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 194/469 [3:11:04<2:53:31, 37.86s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 195/469 [3:11:42<2:52:23, 37.75s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 196/469 [3:12:22<2:55:36, 38.59s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 197/469 [3:13:26<3:29:02, 46.11s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 198/469 [3:14:08<3:22:45, 44.89s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 199/469 [3:14:46<3:13:07, 42.92s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 200/469 [3:15:24<3:04:54, 41.24s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 201/469 [3:16:02<3:00:33, 40.42s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 202/469 [3:16:39<2:55:39, 39.47s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 203/469 [3:17:16<2:51:16, 38.63s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 204/469 [3:17:54<2:50:19, 38.56s/it]\u001b[A\n",
      "Iteration:  44%|████▎     | 205/469 [3:18:31<2:46:26, 37.83s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 206/469 [3:19:08<2:44:56, 37.63s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 207/469 [3:19:45<2:44:30, 37.67s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 208/469 [3:20:25<2:45:58, 38.15s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 209/469 [3:21:04<2:46:15, 38.37s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 210/469 [3:21:43<2:46:31, 38.58s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 211/469 [3:22:22<2:46:56, 38.82s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 212/469 [3:23:00<2:45:20, 38.60s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 213/469 [3:23:38<2:43:19, 38.28s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 214/469 [3:24:18<2:44:46, 38.77s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 215/469 [3:24:55<2:42:42, 38.43s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 216/469 [3:25:31<2:39:16, 37.77s/it]\u001b[A\n",
      "Iteration:  46%|████▋     | 217/469 [3:26:10<2:40:10, 38.14s/it]\u001b[A\n",
      "Iteration:  46%|████▋     | 218/469 [3:26:48<2:38:25, 37.87s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 219/469 [3:27:25<2:37:08, 37.72s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  47%|████▋     | 220/469 [3:28:03<2:36:26, 37.69s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 221/469 [3:28:43<2:38:39, 38.38s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 222/469 [3:29:21<2:37:21, 38.22s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 223/469 [3:29:57<2:34:39, 37.72s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 224/469 [3:30:36<2:35:41, 38.13s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 225/469 [3:31:14<2:34:16, 37.94s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 226/469 [3:31:52<2:33:40, 37.94s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 227/469 [3:32:31<2:34:25, 38.29s/it]\u001b[A\n",
      "Iteration:  49%|████▊     | 228/469 [3:33:08<2:32:45, 38.03s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 229/469 [3:33:45<2:30:45, 37.69s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 230/469 [3:34:24<2:31:18, 37.99s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 231/469 [3:35:03<2:32:25, 38.43s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 232/469 [3:35:41<2:30:43, 38.16s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 233/469 [3:36:20<2:31:03, 38.40s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 234/469 [3:37:00<2:32:18, 38.89s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 235/469 [3:37:37<2:29:27, 38.32s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 236/469 [3:38:14<2:28:09, 38.15s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 237/469 [3:38:52<2:26:52, 37.99s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 238/469 [3:39:29<2:25:37, 37.83s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 239/469 [3:40:07<2:24:20, 37.65s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 240/469 [3:40:47<2:26:09, 38.29s/it]\u001b[A\n",
      "Iteration:  51%|█████▏    | 241/469 [3:41:25<2:25:18, 38.24s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 242/469 [3:42:03<2:24:27, 38.18s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 243/469 [3:42:41<2:23:54, 38.20s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 244/469 [3:43:19<2:22:48, 38.08s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 245/469 [3:43:57<2:21:56, 38.02s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 246/469 [3:44:34<2:20:12, 37.72s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 247/469 [3:45:13<2:20:49, 38.06s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 248/469 [3:45:50<2:19:16, 37.81s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 249/469 [3:46:29<2:19:59, 38.18s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 250/469 [3:47:08<2:20:08, 38.40s/it]\u001b[A\n",
      "Iteration:  54%|█████▎    | 251/469 [3:47:44<2:17:37, 37.88s/it]\u001b[A\n",
      "Iteration:  54%|█████▎    | 252/469 [3:48:23<2:17:30, 38.02s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 253/469 [3:49:01<2:17:31, 38.20s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 254/469 [3:49:40<2:17:01, 38.24s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 255/469 [3:50:18<2:16:10, 38.18s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 256/469 [3:50:57<2:16:16, 38.39s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 257/469 [3:51:35<2:15:12, 38.27s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 258/469 [3:52:12<2:13:26, 37.94s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 259/469 [3:52:51<2:13:46, 38.22s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 260/469 [3:53:29<2:12:50, 38.14s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 261/469 [3:54:06<2:11:24, 37.91s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 262/469 [3:54:44<2:10:26, 37.81s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 263/469 [3:55:23<2:11:05, 38.18s/it]\u001b[A\n",
      "Iteration:  56%|█████▋    | 264/469 [3:55:59<2:08:53, 37.73s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 265/469 [3:56:38<2:09:02, 37.95s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 266/469 [3:57:16<2:08:59, 38.12s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 267/469 [3:57:53<2:07:20, 37.82s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 268/469 [3:58:32<2:07:26, 38.04s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 269/469 [3:59:10<2:06:48, 38.04s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 270/469 [3:59:48<2:05:51, 37.95s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 271/469 [4:00:27<2:06:14, 38.25s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 272/469 [4:01:04<2:04:40, 37.97s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 273/469 [4:01:44<2:05:37, 38.46s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 274/469 [4:02:21<2:03:54, 38.13s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 275/469 [4:02:59<2:03:00, 38.04s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 276/469 [4:03:38<2:03:22, 38.36s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 277/469 [4:04:16<2:02:40, 38.34s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 278/469 [4:04:53<2:00:49, 37.96s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 279/469 [4:05:31<2:00:21, 38.01s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 280/469 [4:06:09<1:59:10, 37.83s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 281/469 [4:06:46<1:58:24, 37.79s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 282/469 [4:07:25<1:58:02, 37.87s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 283/469 [4:08:04<1:58:36, 38.26s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 284/469 [4:08:42<1:57:39, 38.16s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 285/469 [4:09:19<1:56:37, 38.03s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 286/469 [4:09:57<1:55:46, 37.96s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 287/469 [4:10:35<1:54:39, 37.80s/it]\u001b[A\n",
      "Iteration:  61%|██████▏   | 288/469 [4:11:12<1:53:34, 37.65s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 289/469 [4:11:50<1:53:36, 37.87s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 290/469 [4:12:29<1:53:24, 38.01s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 291/469 [4:13:07<1:53:01, 38.10s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 292/469 [4:13:46<1:52:59, 38.30s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 293/469 [4:14:23<1:51:40, 38.07s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 294/469 [4:15:00<1:50:14, 37.80s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 295/469 [4:15:38<1:49:23, 37.72s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 296/469 [4:16:16<1:48:49, 37.74s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 297/469 [4:16:55<1:49:10, 38.09s/it]\u001b[A\n",
      "Iteration:  64%|██████▎   | 298/469 [4:17:32<1:48:16, 37.99s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 299/469 [4:18:10<1:47:42, 38.01s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 300/469 [4:18:47<1:46:10, 37.70s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 301/469 [4:19:25<1:45:55, 37.83s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 302/469 [4:20:04<1:45:40, 37.96s/it]\u001b[A\n",
      "Iteration:  65%|██████▍   | 303/469 [4:20:41<1:44:24, 37.74s/it]\u001b[A\n",
      "Iteration:  65%|██████▍   | 304/469 [4:21:18<1:42:55, 37.43s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 305/469 [4:21:57<1:43:29, 37.86s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 306/469 [4:22:34<1:42:15, 37.64s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 307/469 [4:23:11<1:41:14, 37.49s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 308/469 [4:23:49<1:40:55, 37.61s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 309/469 [4:24:27<1:41:05, 37.91s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 310/469 [4:25:04<1:39:37, 37.60s/it]\u001b[A\n",
      "Iteration:  66%|██████▋   | 311/469 [4:25:41<1:38:43, 37.49s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 312/469 [4:26:21<1:39:28, 38.02s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 313/469 [4:26:58<1:38:00, 37.69s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 314/469 [4:27:36<1:37:39, 37.81s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 315/469 [4:28:15<1:37:54, 38.14s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 316/469 [4:28:54<1:37:53, 38.39s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 317/469 [4:29:32<1:36:55, 38.26s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 318/469 [4:30:10<1:36:42, 38.43s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 319/469 [4:30:49<1:35:57, 38.38s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 320/469 [4:31:27<1:35:34, 38.48s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 321/469 [4:32:05<1:34:10, 38.18s/it]\u001b[A\n",
      "Iteration:  69%|██████▊   | 322/469 [4:32:44<1:34:02, 38.38s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 323/469 [4:33:22<1:33:11, 38.30s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 324/469 [4:34:00<1:32:17, 38.19s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 325/469 [4:34:39<1:32:38, 38.60s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 326/469 [4:35:18<1:31:50, 38.53s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 327/469 [4:35:55<1:30:09, 38.10s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 328/469 [4:36:34<1:30:05, 38.34s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 329/469 [4:37:12<1:29:15, 38.25s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 330/469 [4:37:50<1:28:22, 38.15s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 331/469 [4:38:29<1:28:48, 38.62s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 332/469 [4:39:08<1:28:05, 38.58s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 333/469 [4:39:47<1:27:36, 38.65s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 334/469 [4:40:25<1:26:47, 38.57s/it]\u001b[A\n",
      "Iteration:  71%|███████▏  | 335/469 [4:41:05<1:26:52, 38.90s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 336/469 [4:41:43<1:25:35, 38.61s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 337/469 [4:42:21<1:24:33, 38.44s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 338/469 [4:42:58<1:23:22, 38.19s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 339/469 [4:43:36<1:22:42, 38.17s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  72%|███████▏  | 340/469 [4:44:14<1:21:28, 37.89s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 341/469 [4:44:52<1:20:53, 37.91s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 342/469 [4:45:29<1:20:15, 37.92s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 343/469 [4:46:06<1:18:42, 37.48s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 344/469 [4:46:45<1:18:48, 37.83s/it]\u001b[A\n",
      "Iteration:  74%|███████▎  | 345/469 [4:47:22<1:17:59, 37.74s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 346/469 [4:47:59<1:16:40, 37.40s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 347/469 [4:48:37<1:16:21, 37.55s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 348/469 [4:49:15<1:16:30, 37.94s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 349/469 [4:49:53<1:15:52, 37.94s/it]\u001b[A\n",
      "Iteration:  75%|███████▍  | 350/469 [4:50:32<1:15:29, 38.06s/it]\u001b[A\n",
      "Iteration:  75%|███████▍  | 351/469 [4:51:11<1:15:24, 38.34s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 352/469 [4:51:48<1:14:15, 38.08s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 353/469 [4:52:26<1:13:10, 37.85s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 354/469 [4:53:04<1:12:49, 37.99s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 355/469 [4:53:40<1:11:17, 37.53s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 356/469 [4:54:18<1:10:51, 37.62s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 357/469 [4:54:55<1:09:52, 37.43s/it]\u001b[A\n",
      "Iteration:  76%|███████▋  | 358/469 [4:55:33<1:09:13, 37.42s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 359/469 [4:56:09<1:08:14, 37.22s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 360/469 [4:56:47<1:07:41, 37.26s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 361/469 [4:57:25<1:07:49, 37.68s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 362/469 [4:58:03<1:07:02, 37.59s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 363/469 [4:58:42<1:07:07, 37.99s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 364/469 [4:59:21<1:07:01, 38.30s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 365/469 [4:59:59<1:06:13, 38.20s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 366/469 [5:00:37<1:05:32, 38.18s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 367/469 [5:01:16<1:05:29, 38.53s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 368/469 [5:01:55<1:04:52, 38.54s/it]\u001b[A\n",
      "Iteration:  79%|███████▊  | 369/469 [5:02:33<1:03:55, 38.35s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 370/469 [5:03:11<1:03:28, 38.47s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 371/469 [5:03:49<1:02:17, 38.13s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 372/469 [5:04:28<1:02:00, 38.36s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 373/469 [5:05:05<1:00:48, 38.01s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 374/469 [5:05:43<1:00:04, 37.94s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 375/469 [5:06:21<59:28, 37.96s/it]  \u001b[A\n",
      "Iteration:  80%|████████  | 376/469 [5:06:57<57:58, 37.41s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 377/469 [5:07:35<57:46, 37.68s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 378/469 [5:08:14<57:38, 38.00s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 379/469 [5:08:52<57:02, 38.03s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 380/469 [5:09:30<56:17, 37.95s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 381/469 [5:10:07<55:29, 37.84s/it]\u001b[A\n",
      "Iteration:  81%|████████▏ | 382/469 [5:10:46<55:05, 38.00s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 383/469 [5:11:23<54:14, 37.84s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 384/469 [5:12:00<53:28, 37.74s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 385/469 [5:12:38<52:35, 37.56s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 386/469 [5:13:15<51:56, 37.54s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 387/469 [5:13:59<53:50, 39.40s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 388/469 [5:14:42<54:40, 40.50s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 389/469 [5:15:26<55:23, 41.54s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 390/469 [5:16:08<54:46, 41.60s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 391/469 [5:16:46<52:40, 40.52s/it]\u001b[A\n",
      "Iteration:  84%|████████▎ | 392/469 [5:17:24<51:05, 39.82s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 393/469 [5:18:03<50:03, 39.52s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 394/469 [5:18:42<49:10, 39.34s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 395/469 [5:19:20<48:04, 38.98s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 396/469 [5:20:00<47:45, 39.25s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 397/469 [5:20:37<46:21, 38.63s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 398/469 [5:21:16<45:46, 38.68s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 399/469 [5:21:55<45:14, 38.77s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 400/469 [5:22:32<44:08, 38.38s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 401/469 [5:23:10<43:25, 38.32s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 402/469 [5:23:48<42:37, 38.17s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 403/469 [5:24:27<42:16, 38.44s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 404/469 [5:25:06<41:43, 38.51s/it]\u001b[A\n",
      "Iteration:  86%|████████▋ | 405/469 [5:25:44<40:53, 38.33s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 406/469 [5:26:24<40:48, 38.87s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 407/469 [5:27:01<39:31, 38.26s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 408/469 [5:27:40<39:05, 38.46s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 409/469 [5:28:19<38:39, 38.65s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 410/469 [5:28:57<37:59, 38.63s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 411/469 [5:29:34<36:55, 38.20s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 412/469 [5:30:14<36:34, 38.51s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 413/469 [5:30:51<35:45, 38.31s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 414/469 [5:31:29<34:46, 37.94s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 415/469 [5:32:07<34:20, 38.15s/it]\u001b[A\n",
      "Iteration:  89%|████████▊ | 416/469 [5:32:45<33:34, 38.00s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 417/469 [5:33:23<33:03, 38.15s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 418/469 [5:34:00<32:07, 37.79s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 419/469 [5:34:39<31:44, 38.09s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 420/469 [5:35:16<30:50, 37.77s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 421/469 [5:35:53<29:54, 37.39s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 422/469 [5:36:31<29:24, 37.55s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 423/469 [5:37:08<28:40, 37.41s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 424/469 [5:37:45<28:07, 37.50s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 425/469 [5:38:22<27:19, 37.26s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 426/469 [5:38:58<26:30, 36.99s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 427/469 [5:39:34<25:41, 36.69s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 428/469 [5:40:13<25:22, 37.14s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 429/469 [5:40:51<24:59, 37.48s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 430/469 [5:41:30<24:42, 38.01s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 431/469 [5:42:08<24:00, 37.91s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 432/469 [5:42:47<23:32, 38.19s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 433/469 [5:43:25<22:52, 38.12s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 434/469 [5:44:01<21:54, 37.55s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 435/469 [5:44:40<21:32, 38.03s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 436/469 [5:45:16<20:34, 37.40s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 437/469 [5:45:53<19:52, 37.26s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 438/469 [5:46:32<19:36, 37.97s/it]\u001b[A\n",
      "Iteration:  94%|█████████▎| 439/469 [5:47:10<18:52, 37.75s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 440/469 [5:47:48<18:16, 37.80s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 441/469 [5:48:25<17:38, 37.80s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 442/469 [5:49:04<17:03, 37.92s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 443/469 [5:49:42<16:27, 37.99s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 444/469 [5:50:21<15:56, 38.24s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 445/469 [5:51:00<15:22, 38.46s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 446/469 [5:51:37<14:38, 38.19s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 447/469 [5:52:15<14:00, 38.19s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 448/469 [5:52:53<13:17, 37.99s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 449/469 [5:53:31<12:38, 37.90s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 450/469 [5:54:08<11:58, 37.79s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 451/469 [5:54:47<11:25, 38.10s/it]\u001b[A\n",
      "Iteration:  96%|█████████▋| 452/469 [5:55:24<10:45, 37.96s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 453/469 [5:56:02<10:03, 37.69s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 454/469 [5:56:39<09:22, 37.53s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 455/469 [5:57:18<08:51, 37.95s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 456/469 [5:57:56<08:14, 38.00s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 457/469 [5:58:33<07:34, 37.91s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 458/469 [5:59:13<07:01, 38.28s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 459/469 [5:59:51<06:23, 38.35s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 460/469 [6:00:29<05:43, 38.12s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 461/469 [6:01:08<05:06, 38.36s/it]\u001b[A\n",
      "Iteration:  99%|█████████▊| 462/469 [6:01:44<04:24, 37.83s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  99%|█████████▊| 463/469 [6:02:22<03:47, 37.84s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 464/469 [6:03:00<03:08, 37.80s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 465/469 [6:03:43<02:38, 39.57s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 466/469 [6:04:27<02:01, 40.66s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 467/469 [6:05:10<01:22, 41.43s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 468/469 [6:05:50<00:40, 40.88s/it]\u001b[A\n",
      "Epoch:  67%|██████▋   | 2/3 [12:45:08<6:29:04, 23344.43s/it]t]\u001b[A\n",
      "Iteration:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/469 [00:37<4:50:32, 37.25s/it]\u001b[A\n",
      "Iteration:   0%|          | 2/469 [01:16<4:53:28, 37.70s/it]\u001b[A\n",
      "Iteration:   1%|          | 3/469 [01:54<4:53:57, 37.85s/it]\u001b[A\n",
      "Iteration:   1%|          | 4/469 [02:32<4:54:54, 38.05s/it]\u001b[A\n",
      "Iteration:   1%|          | 5/469 [03:10<4:53:37, 37.97s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 6/469 [03:48<4:54:09, 38.12s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 7/469 [04:27<4:53:31, 38.12s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 8/469 [05:05<4:53:33, 38.21s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 9/469 [05:44<4:53:57, 38.34s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 10/469 [06:22<4:52:59, 38.30s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 11/469 [07:01<4:53:09, 38.41s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 12/469 [07:38<4:51:30, 38.27s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 13/469 [08:17<4:52:13, 38.45s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 14/469 [08:54<4:47:48, 37.95s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 15/469 [09:32<4:47:42, 38.02s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 16/469 [10:09<4:44:20, 37.66s/it]\u001b[A\n",
      "Iteration:   4%|▎         | 17/469 [10:45<4:39:44, 37.13s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 18/469 [11:22<4:38:54, 37.10s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 19/469 [12:00<4:39:00, 37.20s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 20/469 [12:38<4:42:11, 37.71s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 21/469 [13:16<4:41:11, 37.66s/it]\u001b[A\n",
      "Iteration:   5%|▍         | 22/469 [13:54<4:42:06, 37.87s/it]\u001b[A\n",
      "Iteration:   5%|▍         | 23/469 [14:30<4:37:15, 37.30s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 24/469 [15:06<4:33:37, 36.89s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 25/469 [15:43<4:33:36, 36.98s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 26/469 [16:20<4:33:08, 36.99s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 27/469 [16:58<4:33:21, 37.11s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 28/469 [17:35<4:33:28, 37.21s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 29/469 [18:12<4:30:54, 36.94s/it]\u001b[A\n",
      "Iteration:   6%|▋         | 30/469 [18:48<4:29:45, 36.87s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 31/469 [19:25<4:28:24, 36.77s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 32/469 [20:02<4:29:51, 37.05s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 33/469 [20:40<4:29:56, 37.15s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 34/469 [21:16<4:27:41, 36.92s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 35/469 [21:53<4:25:47, 36.75s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 36/469 [22:29<4:25:23, 36.77s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 37/469 [23:07<4:26:56, 37.07s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 38/469 [23:45<4:28:49, 37.42s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 39/469 [24:23<4:28:14, 37.43s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 40/469 [25:01<4:30:05, 37.78s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 41/469 [25:41<4:32:27, 38.19s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 42/469 [26:18<4:30:43, 38.04s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 43/469 [26:56<4:28:31, 37.82s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 44/469 [27:34<4:28:15, 37.87s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 45/469 [28:12<4:28:45, 38.03s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 46/469 [28:49<4:24:54, 37.58s/it]\u001b[A\n",
      "Iteration:  10%|█         | 47/469 [29:27<4:26:44, 37.92s/it]\u001b[A\n",
      "Iteration:  10%|█         | 48/469 [30:06<4:27:00, 38.05s/it]\u001b[A\n",
      "Iteration:  10%|█         | 49/469 [30:42<4:23:47, 37.69s/it]\u001b[A\n",
      "Iteration:  11%|█         | 50/469 [31:20<4:23:49, 37.78s/it]\u001b[A\n",
      "Iteration:  11%|█         | 51/469 [31:59<4:24:30, 37.97s/it]\u001b[A\n",
      "Iteration:  11%|█         | 52/469 [32:36<4:22:55, 37.83s/it]\u001b[A\n",
      "Iteration:  11%|█▏        | 53/469 [33:13<4:19:05, 37.37s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 54/469 [33:51<4:19:57, 37.58s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 55/469 [34:29<4:19:44, 37.64s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 56/469 [35:09<4:25:47, 38.61s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 57/469 [35:47<4:23:27, 38.37s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 58/469 [36:26<4:23:31, 38.47s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 59/469 [37:04<4:22:09, 38.37s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 60/469 [37:41<4:19:32, 38.07s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 61/469 [38:21<4:21:51, 38.51s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 62/469 [38:58<4:19:06, 38.20s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 63/469 [39:38<4:20:13, 38.46s/it]\u001b[A\n",
      "Iteration:  14%|█▎        | 64/469 [40:16<4:19:56, 38.51s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 65/469 [40:53<4:16:15, 38.06s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 66/469 [41:30<4:14:06, 37.83s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 67/469 [42:09<4:15:40, 38.16s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 68/469 [42:47<4:14:32, 38.09s/it]\u001b[A\n",
      "Iteration:  15%|█▍        | 69/469 [43:23<4:09:49, 37.47s/it]\u001b[A\n",
      "Iteration:  15%|█▍        | 70/469 [44:02<4:11:10, 37.77s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 71/469 [44:41<4:12:29, 38.06s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 72/469 [45:19<4:11:55, 38.07s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 73/469 [45:57<4:12:41, 38.29s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 74/469 [46:36<4:11:52, 38.26s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 75/469 [47:13<4:10:11, 38.10s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 76/469 [47:52<4:09:58, 38.16s/it]\u001b[A\n",
      "Iteration:  16%|█▋        | 77/469 [48:32<4:12:54, 38.71s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 78/469 [49:10<4:11:11, 38.55s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 79/469 [49:48<4:10:03, 38.47s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 80/469 [50:28<4:11:19, 38.76s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 81/469 [51:05<4:08:11, 38.38s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 82/469 [51:42<4:05:35, 38.08s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 83/469 [52:20<4:04:18, 37.98s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 84/469 [52:58<4:04:08, 38.05s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 85/469 [53:36<4:01:56, 37.80s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 86/469 [54:14<4:02:12, 37.94s/it]\u001b[A\n",
      "Iteration:  19%|█▊        | 87/469 [54:52<4:02:33, 38.10s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 88/469 [55:29<3:59:45, 37.76s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 89/469 [56:07<3:59:57, 37.89s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 90/469 [56:45<3:59:32, 37.92s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 91/469 [57:22<3:55:54, 37.45s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 92/469 [57:59<3:55:23, 37.46s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 93/469 [58:37<3:54:52, 37.48s/it]\u001b[A\n",
      "Iteration:  20%|██        | 94/469 [59:13<3:51:59, 37.12s/it]\u001b[A\n",
      "Iteration:  20%|██        | 95/469 [59:49<3:49:41, 36.85s/it]\u001b[A\n",
      "Iteration:  20%|██        | 96/469 [1:00:26<3:48:50, 36.81s/it]\u001b[A\n",
      "Iteration:  21%|██        | 97/469 [1:01:03<3:48:10, 36.80s/it]\u001b[A\n",
      "Iteration:  21%|██        | 98/469 [1:01:39<3:46:47, 36.68s/it]\u001b[A\n",
      "Iteration:  21%|██        | 99/469 [1:02:16<3:46:14, 36.69s/it]\u001b[A\n",
      "Iteration:  21%|██▏       | 100/469 [1:02:56<3:51:01, 37.56s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 101/469 [1:03:34<3:51:18, 37.71s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 102/469 [1:04:11<3:50:52, 37.74s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 103/469 [1:04:49<3:50:46, 37.83s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 104/469 [1:05:26<3:48:38, 37.59s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 105/469 [1:06:04<3:47:42, 37.53s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 106/469 [1:06:41<3:45:28, 37.27s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 107/469 [1:07:19<3:46:37, 37.56s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 108/469 [1:07:56<3:46:06, 37.58s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 109/469 [1:08:34<3:45:18, 37.55s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 110/469 [1:09:11<3:44:07, 37.46s/it]\u001b[A\n",
      "Iteration:  24%|██▎       | 111/469 [1:09:48<3:42:21, 37.27s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 112/469 [1:10:25<3:41:30, 37.23s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 113/469 [1:11:02<3:40:07, 37.10s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 114/469 [1:11:39<3:39:28, 37.09s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 115/469 [1:12:15<3:37:23, 36.85s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 116/469 [1:12:52<3:37:20, 36.94s/it]\u001b[A\n",
      "Iteration:  25%|██▍       | 117/469 [1:13:29<3:35:24, 36.72s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  25%|██▌       | 118/469 [1:14:06<3:36:41, 37.04s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 119/469 [1:14:42<3:34:18, 36.74s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 120/469 [1:15:20<3:35:30, 37.05s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 121/469 [1:15:57<3:34:11, 36.93s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 122/469 [1:16:34<3:34:25, 37.08s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 123/469 [1:17:11<3:32:21, 36.83s/it]\u001b[A\n",
      "Iteration:  26%|██▋       | 124/469 [1:17:48<3:33:40, 37.16s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 125/469 [1:18:26<3:33:23, 37.22s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 126/469 [1:19:03<3:32:25, 37.16s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 127/469 [1:19:41<3:34:14, 37.59s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 128/469 [1:20:19<3:33:02, 37.49s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 129/469 [1:20:57<3:34:16, 37.81s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 130/469 [1:21:35<3:34:15, 37.92s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 131/469 [1:22:13<3:33:43, 37.94s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 132/469 [1:22:51<3:33:11, 37.96s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 133/469 [1:23:29<3:31:10, 37.71s/it]\u001b[A\n",
      "Iteration:  29%|██▊       | 134/469 [1:24:07<3:32:25, 38.05s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 135/469 [1:24:44<3:30:08, 37.75s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 136/469 [1:25:22<3:29:17, 37.71s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 137/469 [1:26:00<3:29:38, 37.89s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 138/469 [1:26:37<3:27:34, 37.63s/it]\u001b[A\n",
      "Iteration:  30%|██▉       | 139/469 [1:27:16<3:27:56, 37.81s/it]\u001b[A\n",
      "Iteration:  30%|██▉       | 140/469 [1:27:54<3:29:04, 38.13s/it]\u001b[A\n",
      "Iteration:  30%|███       | 141/469 [1:28:32<3:27:56, 38.04s/it]\u001b[A\n",
      "Iteration:  30%|███       | 142/469 [1:29:09<3:25:49, 37.77s/it]\u001b[A\n",
      "Iteration:  30%|███       | 143/469 [1:29:48<3:27:15, 38.15s/it]\u001b[A\n",
      "Iteration:  31%|███       | 144/469 [1:30:26<3:26:01, 38.04s/it]\u001b[A\n",
      "Iteration:  31%|███       | 145/469 [1:31:03<3:24:05, 37.80s/it]\u001b[A\n",
      "Iteration:  31%|███       | 146/469 [1:31:42<3:24:32, 37.99s/it]\u001b[A\n",
      "Iteration:  31%|███▏      | 147/469 [1:32:19<3:22:56, 37.81s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 148/469 [1:32:57<3:22:30, 37.85s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 149/469 [1:33:35<3:21:20, 37.75s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 150/469 [1:34:14<3:22:19, 38.05s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 151/469 [1:34:53<3:23:13, 38.34s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 152/469 [1:35:30<3:21:50, 38.20s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 153/469 [1:36:10<3:22:50, 38.52s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 154/469 [1:36:47<3:20:10, 38.13s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 155/469 [1:37:25<3:18:45, 37.98s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 156/469 [1:38:05<3:21:31, 38.63s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 157/469 [1:38:43<3:19:44, 38.41s/it]\u001b[A\n",
      "Iteration:  34%|███▎      | 158/469 [1:39:20<3:17:57, 38.19s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 159/469 [1:39:59<3:18:45, 38.47s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 160/469 [1:40:37<3:17:17, 38.31s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 161/469 [1:41:14<3:14:22, 37.86s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 162/469 [1:41:53<3:14:51, 38.08s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 163/469 [1:42:31<3:15:15, 38.28s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 164/469 [1:43:09<3:13:20, 38.03s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 165/469 [1:43:47<3:13:14, 38.14s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 166/469 [1:44:24<3:11:04, 37.84s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 167/469 [1:45:02<3:10:37, 37.87s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 168/469 [1:45:39<3:08:47, 37.63s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 169/469 [1:46:20<3:13:08, 38.63s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 170/469 [1:46:59<3:11:46, 38.48s/it]\u001b[A\n",
      "Iteration:  36%|███▋      | 171/469 [1:47:37<3:11:00, 38.46s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 172/469 [1:48:16<3:11:18, 38.65s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 173/469 [1:48:53<3:07:52, 38.08s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 174/469 [1:49:30<3:05:31, 37.73s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 175/469 [1:50:08<3:05:09, 37.79s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 176/469 [1:50:47<3:06:21, 38.16s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 177/469 [1:51:25<3:05:12, 38.06s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 178/469 [1:52:02<3:04:03, 37.95s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 179/469 [1:52:40<3:03:53, 38.05s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 180/469 [1:53:17<3:00:34, 37.49s/it]\u001b[A\n",
      "Iteration:  39%|███▊      | 181/469 [1:53:54<2:59:51, 37.47s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 182/469 [1:54:32<3:00:21, 37.71s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 183/469 [1:55:09<2:58:54, 37.53s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 184/469 [1:55:48<2:59:01, 37.69s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 185/469 [1:56:26<2:59:22, 37.90s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 186/469 [1:57:04<2:59:07, 37.98s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 187/469 [1:57:42<2:57:49, 37.84s/it]\u001b[A\n",
      "Iteration:  40%|████      | 188/469 [1:58:19<2:56:38, 37.72s/it]\u001b[A\n",
      "Iteration:  40%|████      | 189/469 [1:58:57<2:56:31, 37.83s/it]\u001b[A\n",
      "Iteration:  41%|████      | 190/469 [1:59:35<2:55:25, 37.73s/it]\u001b[A\n",
      "Iteration:  41%|████      | 191/469 [2:00:12<2:53:48, 37.51s/it]\u001b[A\n",
      "Iteration:  41%|████      | 192/469 [2:00:49<2:53:05, 37.49s/it]\u001b[A\n",
      "Iteration:  41%|████      | 193/469 [2:01:26<2:51:23, 37.26s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 194/469 [2:02:03<2:50:18, 37.16s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 195/469 [2:02:42<2:51:57, 37.65s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 196/469 [2:03:18<2:49:59, 37.36s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 197/469 [2:03:55<2:48:25, 37.15s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 198/469 [2:04:31<2:47:04, 36.99s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 199/469 [2:05:11<2:50:24, 37.87s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 200/469 [2:05:49<2:49:00, 37.70s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 201/469 [2:06:27<2:48:41, 37.77s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 202/469 [2:07:05<2:48:38, 37.90s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 203/469 [2:07:42<2:47:41, 37.83s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 204/469 [2:08:21<2:48:25, 38.13s/it]\u001b[A\n",
      "Iteration:  44%|████▎     | 205/469 [2:08:59<2:46:59, 37.95s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 206/469 [2:09:37<2:46:15, 37.93s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 207/469 [2:10:15<2:45:34, 37.92s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 208/469 [2:10:53<2:44:57, 37.92s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 209/469 [2:11:30<2:44:14, 37.90s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 210/469 [2:12:08<2:43:49, 37.95s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 211/469 [2:12:47<2:43:24, 38.00s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 212/469 [2:13:25<2:42:52, 38.02s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 213/469 [2:14:03<2:42:20, 38.05s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 214/469 [2:14:40<2:40:01, 37.65s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 215/469 [2:15:18<2:41:03, 38.04s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 216/469 [2:15:57<2:41:15, 38.24s/it]\u001b[A\n",
      "Iteration:  46%|████▋     | 217/469 [2:16:35<2:40:38, 38.25s/it]\u001b[A\n",
      "Iteration:  46%|████▋     | 218/469 [2:17:13<2:38:47, 37.96s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 219/469 [2:17:50<2:37:33, 37.81s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 220/469 [2:18:28<2:37:31, 37.96s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 221/469 [2:19:07<2:37:11, 38.03s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 222/469 [2:19:45<2:36:37, 38.05s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 223/469 [2:20:22<2:35:28, 37.92s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 224/469 [2:20:59<2:33:12, 37.52s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 225/469 [2:21:37<2:33:41, 37.79s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 226/469 [2:22:15<2:33:00, 37.78s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 227/469 [2:22:54<2:33:09, 37.97s/it]\u001b[A\n",
      "Iteration:  49%|████▊     | 228/469 [2:23:31<2:32:12, 37.90s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 229/469 [2:24:08<2:30:29, 37.62s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 230/469 [2:24:44<2:28:06, 37.18s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 231/469 [2:25:23<2:28:53, 37.54s/it]\u001b[A\n",
      "Iteration:  49%|████▉     | 232/469 [2:26:01<2:28:29, 37.59s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 233/469 [2:26:39<2:28:47, 37.83s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 234/469 [2:27:16<2:27:22, 37.63s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 235/469 [2:27:55<2:28:34, 38.10s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 236/469 [2:28:32<2:26:42, 37.78s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 237/469 [2:29:09<2:25:13, 37.56s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  51%|█████     | 238/469 [2:29:47<2:25:08, 37.70s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 239/469 [2:30:25<2:24:25, 37.68s/it]\u001b[A\n",
      "Iteration:  51%|█████     | 240/469 [2:31:02<2:23:21, 37.56s/it]\u001b[A\n",
      "Iteration:  51%|█████▏    | 241/469 [2:31:40<2:23:26, 37.75s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 242/469 [2:32:19<2:23:12, 37.85s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 243/469 [2:32:57<2:23:23, 38.07s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 244/469 [2:33:34<2:21:51, 37.83s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 245/469 [2:34:13<2:21:40, 37.95s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 246/469 [2:34:51<2:21:30, 38.07s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 247/469 [2:35:29<2:20:19, 37.93s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 248/469 [2:36:08<2:21:51, 38.51s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 249/469 [2:36:46<2:20:00, 38.19s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 250/469 [2:37:24<2:19:45, 38.29s/it]\u001b[A\n",
      "Iteration:  54%|█████▎    | 251/469 [2:38:03<2:19:54, 38.51s/it]\u001b[A\n",
      "Iteration:  54%|█████▎    | 252/469 [2:38:43<2:19:57, 38.70s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 253/469 [2:39:21<2:18:34, 38.49s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 254/469 [2:40:00<2:19:21, 38.89s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 255/469 [2:40:39<2:18:40, 38.88s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 256/469 [2:41:17<2:16:25, 38.43s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 257/469 [2:41:56<2:17:11, 38.83s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 258/469 [2:42:33<2:14:41, 38.30s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 259/469 [2:43:11<2:13:34, 38.17s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 260/469 [2:43:49<2:12:08, 37.93s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 261/469 [2:44:26<2:10:46, 37.72s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 262/469 [2:45:04<2:10:38, 37.87s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 263/469 [2:45:41<2:09:24, 37.69s/it]\u001b[A\n",
      "Iteration:  56%|█████▋    | 264/469 [2:46:20<2:09:44, 37.97s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 265/469 [2:46:56<2:07:12, 37.42s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 266/469 [2:47:34<2:06:41, 37.45s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 267/469 [2:48:11<2:06:25, 37.55s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 268/469 [2:48:48<2:05:09, 37.36s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 269/469 [2:49:24<2:02:55, 36.88s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 270/469 [2:50:01<2:01:58, 36.78s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 271/469 [2:50:38<2:01:53, 36.93s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 272/469 [2:51:13<1:59:10, 36.30s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 273/469 [2:51:49<1:58:37, 36.32s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 274/469 [2:52:26<1:58:22, 36.42s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 275/469 [2:53:03<1:58:16, 36.58s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 276/469 [2:53:39<1:57:44, 36.60s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 277/469 [2:54:18<1:59:20, 37.29s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 278/469 [2:54:56<1:58:35, 37.26s/it]\u001b[A\n",
      "Iteration:  59%|█████▉    | 279/469 [2:55:33<1:58:34, 37.44s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 280/469 [2:56:10<1:57:31, 37.31s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 281/469 [2:56:49<1:58:25, 37.79s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 282/469 [2:57:27<1:57:24, 37.67s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 283/469 [2:58:04<1:56:36, 37.62s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 284/469 [2:58:42<1:56:31, 37.79s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 285/469 [2:59:19<1:54:56, 37.48s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 286/469 [2:59:57<1:54:12, 37.45s/it]\u001b[A\n",
      "Iteration:  61%|██████    | 287/469 [3:00:34<1:54:00, 37.58s/it]\u001b[A\n",
      "Iteration:  61%|██████▏   | 288/469 [3:01:11<1:52:29, 37.29s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 289/469 [3:01:48<1:51:11, 37.06s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 290/469 [3:02:25<1:50:51, 37.16s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 291/469 [3:03:03<1:51:22, 37.54s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 292/469 [3:03:40<1:49:52, 37.24s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 293/469 [3:04:17<1:49:07, 37.20s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 294/469 [3:04:54<1:48:21, 37.15s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 295/469 [3:05:32<1:48:03, 37.26s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 296/469 [3:06:09<1:47:59, 37.45s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 297/469 [3:06:49<1:48:45, 37.94s/it]\u001b[A\n",
      "Iteration:  64%|██████▎   | 298/469 [3:07:26<1:48:05, 37.93s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 299/469 [3:08:06<1:48:45, 38.38s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 300/469 [3:08:45<1:48:44, 38.61s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 301/469 [3:09:23<1:47:12, 38.29s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 302/469 [3:10:01<1:47:06, 38.48s/it]\u001b[A\n",
      "Iteration:  65%|██████▍   | 303/469 [3:10:40<1:46:05, 38.35s/it]\u001b[A\n",
      "Iteration:  65%|██████▍   | 304/469 [3:11:17<1:44:56, 38.16s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 305/469 [3:11:55<1:44:05, 38.08s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 306/469 [3:12:32<1:42:49, 37.85s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 307/469 [3:13:11<1:42:48, 38.08s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 308/469 [3:13:48<1:40:58, 37.63s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 309/469 [3:14:26<1:41:07, 37.92s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 310/469 [3:15:05<1:41:15, 38.21s/it]\u001b[A\n",
      "Iteration:  66%|██████▋   | 311/469 [3:15:41<1:39:04, 37.62s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 312/469 [3:16:18<1:37:54, 37.42s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 313/469 [3:16:55<1:37:01, 37.32s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 314/469 [3:17:33<1:36:44, 37.45s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 315/469 [3:18:10<1:35:18, 37.13s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 316/469 [3:18:46<1:34:23, 37.02s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 317/469 [3:19:22<1:32:37, 36.56s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 318/469 [3:19:59<1:32:27, 36.74s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 319/469 [3:20:36<1:31:49, 36.73s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 320/469 [3:21:13<1:31:37, 36.90s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 321/469 [3:21:51<1:31:38, 37.15s/it]\u001b[A\n",
      "Iteration:  69%|██████▊   | 322/469 [3:22:29<1:31:31, 37.36s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 323/469 [3:23:07<1:31:48, 37.73s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 324/469 [3:23:45<1:30:56, 37.63s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 325/469 [3:24:22<1:30:11, 37.58s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 326/469 [3:24:59<1:29:14, 37.45s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 327/469 [3:25:36<1:28:27, 37.38s/it]\u001b[A\n",
      "Iteration:  70%|██████▉   | 328/469 [3:26:13<1:27:21, 37.17s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 329/469 [3:26:49<1:25:52, 36.80s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 330/469 [3:27:27<1:25:57, 37.11s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 331/469 [3:28:04<1:25:44, 37.28s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 332/469 [3:28:41<1:24:28, 37.00s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 333/469 [3:29:17<1:23:26, 36.81s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 334/469 [3:29:54<1:22:30, 36.67s/it]\u001b[A\n",
      "Iteration:  71%|███████▏  | 335/469 [3:30:30<1:21:50, 36.65s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 336/469 [3:31:06<1:20:59, 36.54s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 337/469 [3:31:44<1:21:20, 36.97s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 338/469 [3:32:22<1:21:18, 37.24s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 339/469 [3:32:59<1:20:36, 37.20s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 340/469 [3:33:38<1:21:10, 37.76s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 341/469 [3:34:16<1:20:41, 37.82s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 342/469 [3:34:55<1:20:32, 38.05s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 343/469 [3:35:34<1:20:24, 38.29s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 344/469 [3:36:12<1:19:22, 38.10s/it]\u001b[A\n",
      "Iteration:  74%|███████▎  | 345/469 [3:36:50<1:19:05, 38.27s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 346/469 [3:37:27<1:17:45, 37.93s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 347/469 [3:38:07<1:17:56, 38.33s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 348/469 [3:38:43<1:16:26, 37.90s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 349/469 [3:39:20<1:15:16, 37.64s/it]\u001b[A\n",
      "Iteration:  75%|███████▍  | 350/469 [3:39:59<1:15:10, 37.90s/it]\u001b[A\n",
      "Iteration:  75%|███████▍  | 351/469 [3:40:36<1:13:53, 37.57s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 352/469 [3:41:14<1:13:23, 37.63s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 353/469 [3:41:52<1:13:08, 37.83s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 354/469 [3:42:30<1:12:23, 37.77s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 355/469 [3:43:07<1:11:42, 37.74s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 356/469 [3:43:43<1:09:43, 37.02s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 357/469 [3:44:20<1:09:29, 37.23s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  76%|███████▋  | 358/469 [3:44:56<1:08:06, 36.82s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 359/469 [3:45:33<1:07:43, 36.94s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 360/469 [3:46:10<1:07:02, 36.90s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 361/469 [3:46:47<1:06:12, 36.78s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 362/469 [3:47:24<1:05:39, 36.81s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 363/469 [3:48:02<1:05:59, 37.36s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 364/469 [3:48:39<1:05:19, 37.33s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 365/469 [3:49:17<1:04:47, 37.38s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 366/469 [3:49:54<1:04:02, 37.31s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 367/469 [3:50:32<1:03:43, 37.48s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 368/469 [3:51:09<1:02:59, 37.42s/it]\u001b[A\n",
      "Iteration:  79%|███████▊  | 369/469 [3:51:45<1:01:45, 37.06s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 370/469 [3:52:24<1:02:06, 37.64s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 371/469 [3:53:01<1:00:58, 37.33s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 372/469 [3:53:38<1:00:07, 37.19s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 373/469 [3:54:16<1:00:08, 37.59s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 374/469 [3:54:55<59:46, 37.75s/it]  \u001b[A\n",
      "Iteration:  80%|███████▉  | 375/469 [3:55:31<58:44, 37.49s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 376/469 [3:56:09<57:57, 37.40s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 377/469 [3:56:47<57:59, 37.82s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 378/469 [3:57:24<56:59, 37.58s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 379/469 [3:58:04<57:03, 38.04s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 380/469 [3:58:42<56:43, 38.24s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 381/469 [3:59:19<55:36, 37.91s/it]\u001b[A\n",
      "Iteration:  81%|████████▏ | 382/469 [3:59:57<54:37, 37.67s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 383/469 [4:00:37<55:03, 38.41s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 384/469 [4:01:13<53:32, 37.79s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 385/469 [4:01:52<53:13, 38.02s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 386/469 [4:02:30<52:50, 38.20s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 387/469 [4:03:07<51:40, 37.81s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 388/469 [4:03:44<50:45, 37.60s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 389/469 [4:04:21<49:56, 37.46s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 390/469 [4:04:58<49:03, 37.26s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 391/469 [4:05:35<48:15, 37.12s/it]\u001b[A\n",
      "Iteration:  84%|████████▎ | 392/469 [4:06:12<47:40, 37.15s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 393/469 [4:06:49<47:06, 37.19s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 394/469 [4:07:25<45:58, 36.78s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 395/469 [4:08:04<46:03, 37.35s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 396/469 [4:08:42<45:46, 37.62s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 397/469 [4:09:18<44:37, 37.18s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 398/469 [4:09:55<43:56, 37.13s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 399/469 [4:10:33<43:21, 37.16s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 400/469 [4:11:11<43:10, 37.55s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 401/469 [4:11:48<42:29, 37.50s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 402/469 [4:12:27<42:19, 37.90s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 403/469 [4:13:06<42:01, 38.21s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 404/469 [4:13:43<41:00, 37.85s/it]\u001b[A\n",
      "Iteration:  86%|████████▋ | 405/469 [4:14:21<40:20, 37.82s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 406/469 [4:14:58<39:34, 37.69s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 407/469 [4:15:36<38:47, 37.55s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 408/469 [4:16:13<38:17, 37.66s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 409/469 [4:16:52<37:47, 37.79s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 410/469 [4:17:29<37:11, 37.82s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 411/469 [4:18:08<36:46, 38.04s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 412/469 [4:18:45<35:55, 37.82s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 413/469 [4:19:23<35:23, 37.92s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 414/469 [4:20:02<34:59, 38.17s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 415/469 [4:20:40<34:11, 37.99s/it]\u001b[A\n",
      "Iteration:  89%|████████▊ | 416/469 [4:21:20<34:01, 38.52s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 417/469 [4:21:58<33:27, 38.60s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 418/469 [4:22:36<32:32, 38.29s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 419/469 [4:23:15<32:00, 38.41s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 420/469 [4:23:52<31:12, 38.21s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 421/469 [4:24:31<30:34, 38.23s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 422/469 [4:25:09<29:55, 38.20s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 423/469 [4:25:48<29:25, 38.39s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 424/469 [4:26:24<28:23, 37.85s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 425/469 [4:27:01<27:38, 37.70s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 426/469 [4:27:40<27:17, 38.08s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 427/469 [4:28:18<26:32, 37.91s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 428/469 [4:28:55<25:48, 37.77s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 429/469 [4:29:33<25:10, 37.77s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 430/469 [4:30:10<24:26, 37.61s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 431/469 [4:30:48<23:52, 37.70s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 432/469 [4:31:25<23:02, 37.38s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 433/469 [4:32:03<22:28, 37.45s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 434/469 [4:32:41<21:56, 37.61s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 435/469 [4:33:18<21:17, 37.58s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 436/469 [4:33:57<20:49, 37.85s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 437/469 [4:34:34<20:07, 37.74s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 438/469 [4:35:12<19:34, 37.88s/it]\u001b[A\n",
      "Iteration:  94%|█████████▎| 439/469 [4:35:50<18:59, 37.97s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 440/469 [4:36:26<18:00, 37.25s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 441/469 [4:37:03<17:19, 37.14s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 442/469 [4:37:42<16:54, 37.58s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 443/469 [4:38:18<16:10, 37.32s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 444/469 [4:38:55<15:31, 37.26s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 445/469 [4:39:32<14:51, 37.13s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 446/469 [4:40:10<14:19, 37.39s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 447/469 [4:40:46<13:34, 37.03s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 448/469 [4:41:24<12:58, 37.08s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 449/469 [4:42:03<12:33, 37.67s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 450/469 [4:42:40<11:51, 37.46s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 451/469 [4:43:16<11:08, 37.15s/it]\u001b[A\n",
      "Iteration:  96%|█████████▋| 452/469 [4:43:54<10:33, 37.27s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 453/469 [4:44:30<09:54, 37.17s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 454/469 [4:45:07<09:12, 36.86s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 455/469 [4:45:43<08:33, 36.65s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 456/469 [4:46:20<07:57, 36.74s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 457/469 [4:46:57<07:22, 36.90s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 458/469 [4:47:33<06:43, 36.64s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 459/469 [4:48:13<06:17, 37.76s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 460/469 [4:48:51<05:39, 37.67s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 461/469 [4:49:29<05:01, 37.68s/it]\u001b[A\n",
      "Iteration:  99%|█████████▊| 462/469 [4:50:08<04:26, 38.14s/it]\u001b[A\n",
      "Iteration:  99%|█████████▊| 463/469 [4:50:45<03:46, 37.83s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 464/469 [4:51:22<03:08, 37.66s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 465/469 [4:52:00<02:30, 37.63s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 466/469 [4:52:37<01:52, 37.66s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 467/469 [4:53:13<01:14, 37.13s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 468/469 [4:53:50<00:37, 37.05s/it]\u001b[A\n",
      "Epoch: 100%|██████████| 3/3 [17:39:27<00:00, 21638.81s/it]  t]\u001b[A\n",
      "02/19/2019 10:09:42 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz from cache at /home/user/.pytorch_pretrained_bert/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9\n",
      "02/19/2019 10:09:42 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/user/.pytorch_pretrained_bert/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9 to temp dir /tmp/tmpkff4kdb7\n",
      "02/19/2019 10:09:52 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/19/2019 10:11:25 - INFO - __main__ -   ***** Running evaluation *****\n",
      "02/19/2019 10:11:25 - INFO - __main__ -     Num examples = 8836\n",
      "02/19/2019 10:11:25 - INFO - __main__ -     Batch size = 8\n",
      "Evaluating: 100%|██████████| 1105/1105 [1:16:50<00:00,  3.65s/it]\n",
      "02/19/2019 11:28:16 - INFO - __main__ -   ***** Eval results *****\n",
      "02/19/2019 11:28:16 - INFO - __main__ -     eval_accuracy = 0.9826137415150702\n",
      "02/19/2019 11:28:16 - INFO - __main__ -     eval_loss = 0.04928599846258557\n",
      "02/19/2019 11:28:16 - INFO - __main__ -     global_step = 1407\n",
      "02/19/2019 11:28:16 - INFO - __main__ -     loss = 0.041945654755907016\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, warmup_linear\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            label: (Optional) [string]. The labels of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "\n",
    "class DataProcessor(object):\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\", encoding='utf-8') as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                lines.append(line)\n",
    "            return lines\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train.tsv\")))\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        labels_list = []\n",
    "        cNames = [''] * len(categories)\n",
    "        for k,v in categories.items():\n",
    "            labels_list.append(k)\n",
    "        return labels_list\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[1]\n",
    "            text_b = None\n",
    "            label = line[0]\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "    label_map = {label : i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "        # Account for [CLS] and [SEP] with \"- 2\"\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids: 0   0   0   0  0     0 0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "        segment_ids = [0] * len(tokens)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = [0] * len(categories)\n",
    "        exLabels = example.label.split(\",\")\n",
    "        for i in range(len(exLabels)):\n",
    "            label_id[label_map[exLabels[i]]] = 1\n",
    "            \n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id))\n",
    "    return features\n",
    "\n",
    "def accuracy(y_pred, y_true, thresh:float=0.5):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    y_pred = y_pred.sigmoid()\n",
    "    return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
    "\n",
    "max_bert_seq_length = 512\n",
    "class Args(object):\n",
    "    def __init__(self, bert_model):\n",
    "        self.bert_model = bert_model\n",
    "    \n",
    "\n",
    "args = Args(\"bert-base-multilingual-cased\")\n",
    "args.data_dir = bertDataPath\n",
    "args.bert_model = \"bert-base-multilingual-cased\"\n",
    "args.output_dir = outDataPath\n",
    "args.max_seq_length = min(max_bert_seq_length, maxSeqLength)\n",
    "args.do_train = True\n",
    "args.do_eval = True\n",
    "args.do_lower_case = False\n",
    "args.train_batch_size = 32\n",
    "args.eval_batch_size = 8\n",
    "args.learning_rate = 5e-5\n",
    "args.num_train_epochs = 3\n",
    "args.warmup_proportion = 0.1\n",
    "args.no_cuda = True\n",
    "args.local_rank = -1\n",
    "args.seed = 42\n",
    "args.gradient_accumulation_steps = 1\n",
    "\n",
    "device = 'cpu'\n",
    "n_gpu = torch.cuda.device_count()\n",
    "args.train_batch_size = args.train_batch_size // args.gradient_accumulation_steps\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if not args.do_train and not args.do_eval:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train:\n",
    "    raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "processor = DataProcessor()\n",
    "num_labels = len(categories)\n",
    "label_list = processor.get_labels()\n",
    "tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=args.do_lower_case)\n",
    "train_examples = None\n",
    "num_train_optimization_steps = None    \n",
    "if args.do_train:\n",
    "    train_examples = processor.get_train_examples(args.data_dir)\n",
    "    num_train_optimization_steps = int(\n",
    "        len(train_examples) / args.train_batch_size / args.gradient_accumulation_steps) * args.num_train_epochs\n",
    "model = BertForMultiLabelSequenceClassification.from_pretrained(args.bert_model,\n",
    "    cache_dir=PYTORCH_PRETRAINED_BERT_CACHE / 'distributed_{}'.format(args.local_rank),\n",
    "    num_labels = num_labels)\n",
    "model.to(device)\n",
    "\n",
    "#namedParams = [p for p in model.named_parameters()]\n",
    "#print (\"!!! model.named_parameters():\")\n",
    "#print (namedParams)\n",
    "#param_optimizer = list(model.named_parameters())\n",
    "param_optimizer = [p for p in model.named_parameters()]\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "    lr=args.learning_rate,\n",
    "    warmup=args.warmup_proportion,\n",
    "    t_total=num_train_optimization_steps)\n",
    "\n",
    "global_step = 0\n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0\n",
    "\n",
    "if args.do_train:\n",
    "    train_features = convert_examples_to_features(\n",
    "        train_examples, label_list, args.max_seq_length, tokenizer)\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "    logger.info(\"  Batch size = %d\", args.train_batch_size)\n",
    "    logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.float)\n",
    "    train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "    model.train()\n",
    "    for _ in trange(int(args.num_train_epochs), desc=\"Epoch\"):\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids = batch\n",
    "            loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            if n_gpu > 1:\n",
    "                loss = loss.mean() # mean() to average on multi-gpu.\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "# Save a trained model\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "output_model_file = os.path.join(args.output_dir, \"pytorch_model.bin\")\n",
    "if args.do_train:\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)\n",
    "\n",
    "# Load a trained model that you have fine-tuned\n",
    "model_state_dict = torch.load(output_model_file)\n",
    "model = BertForMultiLabelSequenceClassification.from_pretrained(args.bert_model, state_dict=model_state_dict, num_labels=num_labels)\n",
    "model.to(device)\n",
    "\n",
    "if args.do_eval and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
    "    eval_examples = processor.get_dev_examples(args.data_dir)\n",
    "    eval_features = convert_examples_to_features(\n",
    "        eval_examples, label_list, args.max_seq_length, tokenizer)\n",
    "    logger.info(\"***** Running evaluation *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.float)\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    \n",
    "    # Run prediction for full data\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    allLabs = None\n",
    "    res = None\n",
    "    initRes = True\n",
    "    for input_ids, input_mask, segment_ids, label_ids in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            logits = model(input_ids, segment_ids, input_mask)\n",
    "        preds = logits.sigmoid().to('cpu').numpy()\n",
    "        labs = label_ids.to('cpu').numpy()\n",
    "        if initRes == True:\n",
    "            res = preds\n",
    "            allLabs = labs\n",
    "            initRes = False\n",
    "        else:\n",
    "            res = numpy.concatenate((res, preds))\n",
    "            allLabs = numpy.concatenate((allLabs, labs))\n",
    "\n",
    "        tmp_eval_accuracy = accuracy(logits, label_ids)\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_examples += input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
    "    loss = tr_loss/nb_tr_steps if args.do_train else None\n",
    "    result = {'eval_loss': eval_loss,\n",
    "        'eval_accuracy': eval_accuracy,\n",
    "        'global_step': global_step,\n",
    "        'loss': loss}\n",
    "    \n",
    "    output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "    writer.close()\n",
    "\n",
    "    output_pred_file = os.path.join(args.output_dir, \"predictions.txt\")\n",
    "    with open(output_pred_file, \"w\") as writer:\n",
    "        for i in range(len(res)):\n",
    "            line = \"\"\n",
    "            for j in range(len(allLabs[i])):\n",
    "                if allLabs[i][j] == 1:\n",
    "                    if line != '':\n",
    "                        line = line + \",\"\n",
    "                    line = line + str(j)\n",
    "            for j in range(len(res[i])):\n",
    "                line = line + \"\\t\"\n",
    "                line = line + str(res[i][j])\n",
    "            line = line + \"\\n\"\n",
    "            writer.write(line)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate metrics.\n",
      "Len of test_labels: 8836, results: 8836\n",
      "Labels actual: 11060, predicted: 10100, correctly: 7872, incorrectly: 2228, not predicted: 3188\n",
      "Exact Match Ratio:  60.33%\n",
      "Accuracy:  70.95%\n",
      "Precision:  75.42%\n",
      "Recall:  77.08%\n",
      "F1-Measure:  76.25%\n",
      "Hamming Loss:  1.53%\n",
      "Macro-Averaged Precision:  58.39%\n",
      "Macro-Averaged Recall:  73.61%\n",
      "Macro-Averaged F1-Measure:  62.65%\n",
      "Micro-Averaged Precision:  71.18%\n",
      "Micro-Averaged Recall:  77.94%\n",
      "Micro-Averaged F1-Measure:  74.40%\n",
      "One Error: 19.56%\n",
      "Coverage: 1.00\n",
      "Ranking Loss: 0.78\n"
     ]
    }
   ],
   "source": [
    "print (\"Calculate metrics.\")\n",
    "rankThreshold = 0.3\n",
    "diffThreshold = 10\n",
    "test_labels = allLabs\n",
    "\n",
    "print(\"Len of test_labels: %d, results: %d\"%(len(test_labels), len(res)))\n",
    "\n",
    "def rankIndicator(labels, predictions, index):\n",
    "    global rankThreshold\n",
    "    actual = labels[index] == 1\n",
    "    predicted = predictions[index] >= rankThreshold\n",
    "    notActual = 0\n",
    "    if actual == True and predicted == False:        \n",
    "        for i in range(len(predictions)):\n",
    "            if i == index:\n",
    "                continue\n",
    "            if labels[i] == 0:\n",
    "                notActual += 1\n",
    "            if labels[i] == 0 and ((predictions[index] / predictions[i]) < diffThreshold):\n",
    "                return True, False\n",
    "        if notActual > 0:\n",
    "            return True, True\n",
    "    return actual, predicted\n",
    "    \n",
    "def getPrediction(entry):\n",
    "    return entry[1]\n",
    "\n",
    "# General results   \n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "qTags = 0\n",
    "qPreds = 0\n",
    "for i in range(len(test_labels)):\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if predicted:\n",
    "            qPreds += 1\n",
    "            if actual:\n",
    "                qTags += 1\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if actual:\n",
    "                qTags += 1\n",
    "                fn += 1\n",
    "print (\"Labels actual: %d, predicted: %d, correctly: %d, incorrectly: %d, not predicted: %d\"%(qTags, qPreds, tp, fp, fn))\n",
    "\n",
    "#Exact Match Ratio\n",
    "wrongPreds = 0\n",
    "for i in range(len(test_labels)):\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if (actual and not predicted) or (predicted and not actual):\n",
    "            wrongPreds += 1\n",
    "            break;\n",
    "emr = (len(test_labels) - wrongPreds)/len(test_labels)           \n",
    "print (\"Exact Match Ratio:  %.2f%%\" % ((len(test_labels) - wrongPreds)/len(test_labels) * 100))\n",
    "\n",
    "#Accuracy\n",
    "accuracy = 0.\n",
    "for i in range(len(test_labels)):\n",
    "    labels = sum(test_labels[i])\n",
    "    tp = 0\n",
    "    tfp = 0\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if actual and predicted:\n",
    "            tp += 1\n",
    "        if predicted and not actual:\n",
    "            tfp += 1\n",
    "    accuracy += tp / (labels + tfp)\n",
    "modelAccuracy = accuracy / len(test_labels)\n",
    "print (\"Accuracy:  %.2f%%\" % (accuracy / len(test_labels) * 100))  \n",
    "\n",
    "#Precision\n",
    "precision = 0.\n",
    "for i in range(len(test_labels)):\n",
    "    labels = sum(test_labels[i])\n",
    "    tp = 0\n",
    "    tfp = 0\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if actual and predicted:\n",
    "            tp += 1\n",
    "    precision += tp / labels\n",
    "modelPrecision = precision / len(test_labels)\n",
    "print (\"Precision:  %.2f%%\" % (precision / len(test_labels) * 100))  \n",
    "\n",
    "#Recall\n",
    "recall = 0.\n",
    "for i in range(len(test_labels)):\n",
    "    labels = sum(test_labels[i])\n",
    "    tp = 0\n",
    "    tfp = 0\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if actual and predicted:\n",
    "            tp += 1\n",
    "        if predicted:\n",
    "            tfp += 1\n",
    "    if tfp > 0:\n",
    "        recall += tp / tfp\n",
    "modelRecall = recall / len(test_labels)      \n",
    "print (\"Recall:  %.2f%%\" % (recall / len(test_labels) * 100))  \n",
    "\n",
    "#F1-Measure\n",
    "modelF1 = 2 * (modelPrecision * modelRecall / (modelPrecision + modelRecall))\n",
    "print (\"F1-Measure:  %.2f%%\" % (2 * (modelPrecision * modelRecall / (modelPrecision + modelRecall)) * 100))\n",
    "\n",
    "#Hamming Loss\n",
    "hl = 0.\n",
    "for i in range(len(test_labels)):\n",
    "    labels = sum(test_labels[i])\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if (actual and not predicted) or (predicted and not actual):\n",
    "            hl += 1\n",
    "modelHl = hl / (len(test_labels) * len(categories))           \n",
    "print (\"Hamming Loss:  %.2f%%\" % (hl * 100 / (len(test_labels) * len(categories)))) \n",
    "\n",
    "#Macro-Averaged Precision\n",
    "precision = 0\n",
    "for i in range(len(categories)):\n",
    "    tp = 0\n",
    "    tact = 0\n",
    "    for j in range(len(test_labels)):\n",
    "        actual, predicted = rankIndicator(test_labels[j], res[j], i) \n",
    "        if not actual:\n",
    "            continue\n",
    "        tact += 1\n",
    "        if predicted:\n",
    "            tp += 1\n",
    "    precision += tp / tact\n",
    "modelMacroPrecision = precision / len(categories) \n",
    "print (\"Macro-Averaged Precision:  %.2f%%\" % (precision / len(categories) * 100))  \n",
    "\n",
    "#Macro-Averaged Recall\n",
    "recall = 0\n",
    "for i in range(len(categories)):\n",
    "    tp = 0\n",
    "    tact = 0\n",
    "    for j in range(len(test_labels)):\n",
    "        actual, predicted = rankIndicator(test_labels[j], res[j], i)\n",
    "        if predicted:\n",
    "            tact += 1\n",
    "            if actual:\n",
    "                tp += 1\n",
    "    if tact > 0:                \n",
    "        recall += tp / tact\n",
    "    #else:\n",
    "    #    print (\"Macro-Recall: category %d isn't predicted\"%(i))\n",
    "modelMacroRecall = recall / len(categories)\n",
    "print (\"Macro-Averaged Recall:  %.2f%%\" % (recall / len(categories) * 100))  \n",
    "\n",
    "#Macro-Averaged F1-Measure\n",
    "f1 = 0\n",
    "for i in range(len(categories)):\n",
    "    tp = 0\n",
    "    tact = 0\n",
    "    labs = 0\n",
    "    for j in range(len(test_labels)):\n",
    "        actual, predicted = rankIndicator(test_labels[j], res[j], i)\n",
    "        if actual:\n",
    "            labs += 1\n",
    "        if predicted:\n",
    "            tact += 1\n",
    "            if actual:\n",
    "                tp += 1\n",
    "    f1 += 2 * tp / (tact + labs)\n",
    "modelMacroF1 = f1 / len(categories)\n",
    "print (\"Macro-Averaged F1-Measure:  %.2f%%\" % (f1 / len(categories) * 100))  \n",
    "\n",
    "#Micro-Averaged Precision\n",
    "precision = 0\n",
    "tp = 0\n",
    "tact = 0\n",
    "for i in range(len(categories)):\n",
    "    for j in range(len(test_labels)):\n",
    "        actual, predicted = rankIndicator(test_labels[j], res[j], i) \n",
    "        if not actual:\n",
    "            continue\n",
    "        tact += 1\n",
    "        if predicted:\n",
    "            tp += 1\n",
    "precision += tp / tact\n",
    "modelMicroPrecision = precision\n",
    "print (\"Micro-Averaged Precision:  %.2f%%\" % (precision * 100))  \n",
    "\n",
    "#Micro-Averaged Recall\n",
    "recall = 0\n",
    "tp = 0\n",
    "tact = 0\n",
    "for i in range(len(categories)):\n",
    "    for j in range(len(test_labels)):\n",
    "        actual, predicted = rankIndicator(test_labels[j], res[j], i)\n",
    "        if predicted:\n",
    "            tact += 1\n",
    "            if actual:\n",
    "                tp += 1\n",
    "recall += tp / tact\n",
    "modelMicroRecall = recall\n",
    "print (\"Micro-Averaged Recall:  %.2f%%\" % (recall * 100))  \n",
    "\n",
    "#Micro-Averaged F1-Measure\n",
    "f1 = 0\n",
    "tp = 0\n",
    "tact = 0\n",
    "labs = 0\n",
    "for i in range(len(categories)):\n",
    "    for j in range(len(test_labels)):\n",
    "        actual, predicted = rankIndicator(test_labels[j], res[j], i)\n",
    "        if actual:\n",
    "            labs += 1\n",
    "        if predicted:\n",
    "            tact += 1\n",
    "            if actual:\n",
    "                tp += 1\n",
    "f1 += 2 * tp / (tact + labs)\n",
    "modelMicroF1 = f1\n",
    "print (\"Micro-Averaged F1-Measure:  %.2f%%\" % (f1 * 100))  \n",
    "\n",
    "#One error\n",
    "o_err = 0\n",
    "for i in range(len(test_labels)):\n",
    "    list = [(0,0) for i in range(len(categories))]\n",
    "    for j in range(len(categories)):\n",
    "        list[j] = (test_labels[i][j], res[i][j])\n",
    "    list.sort(key=getPrediction, reverse=True)\n",
    "    if list[0][0] == 0:\n",
    "        o_err += 1\n",
    "print (\"One Error: %.2f%%\" % (o_err / len(test_labels) * 100))\n",
    "\n",
    "#Coverage\n",
    "stepsDown = 0\n",
    "for i in range(len(test_labels)):\n",
    "    bound = sum(test_labels[i]) - 1\n",
    "    list = [(0,0,0) for i in range(len(categories))]\n",
    "    for j in range(len(categories)):\n",
    "        list[j] = (test_labels[i][j], res[i][j], j)\n",
    "    list.sort(key=getPrediction, reverse=True)\n",
    "    eSteps = 0\n",
    "    for j in range(len(categories)):\n",
    "        if test_labels[i][j] == 0:\n",
    "            continue\n",
    "        for k in range(len(list)):\n",
    "            if list[k][2] == j:\n",
    "                eSteps = max(eSteps, k)\n",
    "    stepsDown += max(0, eSteps - bound)\n",
    "print (\"Coverage: %.2f\" % (stepsDown / len(test_labels))) \n",
    "\n",
    "#Ranking Loss\n",
    "rl = 0\n",
    "for i in range(len(test_labels)):\n",
    "    mult = sum(test_labels[i])\n",
    "    list = [(0,0) for i in range(len(categories))]\n",
    "    wrongOrder = 0\n",
    "    for j in range(len(categories)):\n",
    "        list[j] = (test_labels[i][j], res[i][j])\n",
    "    list.sort(key=getPrediction, reverse=True)\n",
    "    for j in range(len(list)):\n",
    "        if list[j][0] == 1:\n",
    "            mult -= 1\n",
    "            if mult == 0:\n",
    "                break\n",
    "            continue\n",
    "        wrongOrder += mult\n",
    "    rl += wrongOrder / sum(test_labels[i])\n",
    "print (\"Ranking Loss: %.2f\" % (rl / len(test_labels)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model info saved.\n",
      "Name: BERT-PYTORCH-2019-Feb-19-160136, data set: /home/user/MLClassificationData/test/rtanews/source, documents: 8836, categories: 40, actual labels: 11060\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "modelName = \"BERT-PYTORCH-%s\"%(datetime.datetime.now().strftime(\"%Y-%b-%d-%H%M%S\"))\n",
    "DocInfo = namedtuple('DocInfo', 'name actLabs predLabs dtype')\n",
    "CategoryInfo = namedtuple('CategoryInfo', 'name actLabs predLabs wrongLabs notPredLabs qtyDocs qtyPredDocs precision recall f1')\n",
    "ModelInfo = namedtuple('ModelInfo', 'name dataSet cats qtyDocs qtyPredDocs qtyPartDocs qtyWrongDocs actLabs predLabs wrongLabs notPredLabs emr accuracy precision recall f1 hl macroPrecision macroRecall macroF1 microPrecision microRecall microF1 catagories docs')\n",
    "\n",
    "cNames = [''] * len(categories)\n",
    "for k,v in categories.items():\n",
    "    cNames[v] = k\n",
    "mCorrDocs = 0\n",
    "mPartDocs = 0\n",
    "mWrongDocs = 0\n",
    "cqTags = [0] * len(categories)\n",
    "cqPreds = [0] * len(categories)\n",
    "ctp = [0] * len(categories)\n",
    "cfp = [0] * len(categories)\n",
    "cfn = [0] * len(categories)\n",
    "cDocs = [0] * len(categories)\n",
    "cpDocs = [0] * len(categories)\n",
    "\n",
    "docsInfo = []\n",
    "\n",
    "for i in range(len(res)):\n",
    "    qTags = 0\n",
    "    qPreds = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    dtype = 0\n",
    "    actLabs = []\n",
    "    predLabs = []\n",
    "    for j in range(len(categories)):\n",
    "        actual, predicted = rankIndicator(test_labels[i], res[i], j)\n",
    "        if actual:\n",
    "            cDocs[j] += 1\n",
    "            actLabs.append(cNames[j])\n",
    "        if predicted:\n",
    "            qPreds += 1\n",
    "            cqPreds[j] += 1\n",
    "            predLabs.append(cNames[j])\n",
    "            if actual:\n",
    "                qTags += 1\n",
    "                tp += 1\n",
    "                cqTags[j] += 1\n",
    "                ctp[j] += 1\n",
    "                cpDocs[j] += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "                cfp[j] += 1\n",
    "        else:\n",
    "            if actual:\n",
    "                qTags += 1\n",
    "                fn += 1\n",
    "                cqTags[j] += 1\n",
    "                cfn[j] += 1\n",
    "    if tp == qTags:\n",
    "        if qPreds == tp:\n",
    "            dtype = 2\n",
    "        else:\n",
    "            dtype = 3\n",
    "        mCorrDocs += 1\n",
    "    elif tp > 0:\n",
    "        dtype = 1\n",
    "        mPartDocs += 1\n",
    "    else:\n",
    "        mWrongDocs += 1\n",
    "    docInfo = DocInfo(testDocs[i].name, actLabs, predLabs, dtype)\n",
    "    docsInfo.append(docInfo)\n",
    "\n",
    "categoriesInfo = []\n",
    "for i in range(len(categories)):\n",
    "    cPrec = ctp[i] / cqTags[i]\n",
    "    cRec = 0\n",
    "    if (ctp[i] + cfp[i]) > 0:\n",
    "        cRec = ctp[i] / (ctp[i] + cfp[i])\n",
    "    cF1 = 2 * ctp[i] / (ctp[i] + cfp[i] + cqTags[i])\n",
    "    catInfo = CategoryInfo(cNames[i], cqTags[i], ctp[i], cfp[i], cfn[i], cDocs[i], cpDocs[i], cPrec, cRec, cF1)\n",
    "    categoriesInfo.append(catInfo);\n",
    "\n",
    "sourceRoot = testRoot\n",
    "modelInfo = ModelInfo(modelName,sourceRoot,len(categories),len(res), mCorrDocs, mPartDocs, mWrongDocs, \n",
    "                      sum(cqTags),sum(ctp),sum(cfp),sum(cfn),emr,modelAccuracy,\n",
    "                      modelPrecision,modelRecall,modelF1,modelHl,modelMacroPrecision,modelMacroRecall,\n",
    "                      modelMacroF1,modelMicroPrecision,modelMicroRecall,modelMicroF1,categoriesInfo,docsInfo)\n",
    "with open(modelInfoPath + modelName, 'wb') as f:\n",
    "    pickle.dump(modelInfo, f)\n",
    "print (\"Model info saved.\");\n",
    "print (\"Name: %s, data set: %s, documents: %d, categories: %d, actual labels: %d\"%(modelInfo.name, modelInfo.dataSet, modelInfo.qtyDocs, modelInfo.cats, modelInfo.actLabs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
