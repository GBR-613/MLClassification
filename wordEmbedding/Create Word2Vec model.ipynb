{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2947557 lines from file /home/user/MLClassificationData/w2v/target/wiki_ar.txt\n",
      "At all: got 2947557 lines in 3 min:7 sec\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "\n",
    "TaggedDocument = gensim.models.doc2vec.TaggedDocument\n",
    "homePath = str(Path.home()) + \"/MLClassificationData\"\n",
    "dataPath = homePath + \"/w2v/target\"\n",
    "modelPath = homePath + \"/w2v/models/\"\n",
    "vecPath = homePath + \"/w2v/vectors/\"\n",
    "n_dim = 100\n",
    "sentences = []\n",
    "cuDir = os.getcwd()\n",
    "\n",
    "def prepareData(path, sentences):\n",
    "    os.chdir(path);\n",
    "    for ff in glob.glob(\"*\"):\n",
    "        if os.path.isdir(ff):\n",
    "            dPath = path + \"/\" + ff\n",
    "            prepareData(dPath)\n",
    "            continue\n",
    "        fPath = path + \"/\" + ff\n",
    "        count = 0\n",
    "        with open(fPath, 'r', encoding='UTF-8') as f:\n",
    "            for line in f:\n",
    "                if len(line.strip()) == 0:\n",
    "                    continue\n",
    "                count += 1\n",
    "                label = '%s_%s'%(ff, count)\n",
    "                sentences.append(TaggedDocument(line.strip().split(), [label]))\n",
    "                if len(sentences)%100 == 0:\n",
    "                    print(\"Load %d lines\"%(len(sentences)), end='\\r')\n",
    "        f.close()\n",
    "        print (\"Got %d lines from file %s\"%(count, fPath))\n",
    "\n",
    "def showTime(ds,de):\n",
    "    result = ''\n",
    "    seconds = (de-ds).total_seconds()\n",
    "    hh = int(seconds/(60*24));\n",
    "    if hh > 0:\n",
    "        result = \"%d h:\"%(hh);\n",
    "    seconds -= hh*60*24\n",
    "    mm = int(seconds/60);\n",
    "    if mm > 0:\n",
    "        result += \"%d min:\"%(mm)\n",
    "    ss = seconds - mm*60;\n",
    "    result += \"%d sec\"%(ss)\n",
    "    return result\n",
    "\n",
    "ds = datetime.datetime.now()                                 \n",
    "prepareData(dataPath, sentences)\n",
    "de = datetime.datetime.now()\n",
    "print (\"At all: got %d lines in %s\"%(len(sentences), showTime(ds,de)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and train Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build vocabulary...\n",
      "Vocabulary is built in 1 min:51 sec\n",
      "Train model...\n",
      "W2V model is completed in 9 h:6 min:42 sec\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "    \n",
    "    def on_epoch_begin(self, model):\n",
    "        print (\"Epoch %d\"%(self.epoch), end='\\r')\n",
    "    \n",
    "    def on_epoch_end(self, model):\n",
    "        self.epoch += 1\n",
    "\n",
    "logger = EpochLogger()        \n",
    "w2v = Word2Vec(size=n_dim, window=10, min_count=3, workers=10)\n",
    "ds = datetime.datetime.now()   \n",
    "print (\"Build vocabulary...\")\n",
    "w2v.build_vocab([x[0] for x in sentences])\n",
    "de = datetime.datetime.now()\n",
    "print (\"Vocabulary is built in %s\"%(showTime(ds,de)))\n",
    "print (\"Train model...\")\n",
    "ds = datetime.datetime.now()  \n",
    "w2v.train([x[0] for x in sentences], epochs=100, total_examples=len(sentences), callbacks=[logger])\n",
    "de = datetime.datetime.now()\n",
    "print (\"W2V model is completed in %s\"%(showTime(ds,de)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check quality of the Word2Vec model\n",
    "This can be done, for example, by using __most_similar()__ method.    \n",
    "Most (if not all) of the words in its output should have direct connection with the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/sen1/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('اموال', 0.7828260660171509),\n",
       " ('لمال', 0.6755176782608032),\n",
       " ('قرض', 0.6673386096954346),\n",
       " ('مدخراة', 0.648013710975647),\n",
       " ('ينفق', 0.6403728723526001),\n",
       " ('مبلغ', 0.6283261775970459),\n",
       " ('مدخرات', 0.6184841394424438),\n",
       " ('اموالا', 0.6087712049484253),\n",
       " ('ادخار', 0.6072934865951538),\n",
       " ('ثروة', 0.5970333218574524)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('مال')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Word2Vec model in binary format.\n",
    "Model saved in binary format can be reloaded in the future using **gensim.models.Word2Vec.load()**.    \n",
    "Then it can be used for\n",
    "- word embedding\n",
    "- creating file of vectors\n",
    "- re-train by additional corpora.  \n",
    "\n",
    "_Note: though the gensim interface allows to re-train the existing model, it is not recommended.    \n",
    "The practice would be, when new data arrives, to shuffle it with the \"old\" data and retrain a fresh model with all the data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2V model is saved in the binary format in 1 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelPath = homePath + \"/w2v/models/\"\n",
    "modelName = \"model-%s\"%(datetime.datetime.now().strftime(\"%Y-%b-%d-%H%M%S\"))\n",
    "ds = datetime.datetime.now() \n",
    "w2v.save(modelPath + modelName)\n",
    "de = datetime.datetime.now()\n",
    "print (\"W2V model is saved in binary format in %s\\n\"%(showTime(ds,de)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Word2Vec model in text format (file of vectors)\n",
    "Model saved in text format can be reloaded in the future using **gensim.models.KeyedVectors.load_word2vec_format()**.    \n",
    "Then it can be used for word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2V model is saved in the text format in 39 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vecPath = homePath + \"/w2v/vectors/\"\n",
    "ds = datetime.datetime.now() \n",
    "w2v.wv.save_word2vec_format(vecPath + modelName + \".vec\", binary=False)\n",
    "de = datetime.datetime.now() \n",
    "print (\"W2V model is saved in the text format in %s\\n\"%(showTime(ds,de)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
